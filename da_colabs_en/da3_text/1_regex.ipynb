{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**NOTE: This notebook is written for the Google Colab platform. However it can also be run (possibly with minor modifications) as a standard Jupyter notebook.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "# !{sys.executable} -m pip install git+https://github.com/michalgregor/class_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "import re\n",
    "import string\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Downloading Data -- { display-mode: \"form\" }\n",
    "# also create a directory for storing any outputs\n",
    "import os\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "phone_number_samples = [\n",
    "    (\"0903445772\", (None, 903445772)),\n",
    "    (\"(541) 754-3010\", (None, 5417543010)),\n",
    "    (\"554$117$22A\", None),\n",
    "    (\"die Kartoffel\", None),\n",
    "    (\"+1-541-754-3010\", (1, 5417543010)),\n",
    "    (\"001-541-754-3010\", (1, 5417543010)),\n",
    "    (\"+49-89-636-48018\", (49, 8963648018)),\n",
    "    (\"+421 903 445 231\", (421, 903445231)),\n",
    "    (\"4422-5588\", (None, 44225588)),\n",
    "    (\"41 510 4405\", (None, 415104405)),\n",
    "    (\"33 2187945\", (None, 332187945)),\n",
    "    (\"+31 33 2187945\", (31, 332187945)),\n",
    "    (\"(33) 445-88-76\", (None, 334458876)),\n",
    "    (\"+65-2234-1487\", (65, 22341487)),\n",
    "    (\"+65-XXXX-YYYY\", None)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Regular Expressions\n",
    "\n",
    "When processing text, we often need to search for matches to some keyword or pattern. We also often need to do search and replace. While it is easy to search for one specific keyword, in order to make more flexible searches that involve patterns, we need some way to express what we are looking for. One way to do this is using regular expressions, which we are going to illustrate in this notebook. Also, in the interest of brevity, we will skip a more formal introduction and jump straight to practical examples.\n",
    "\n",
    "Also, we will not cover all the regular expression syntax in full – you can find more information e.g. in: [Regular Expression HOWTO](https://docs.python.org/3/howto/regex.html) or in [re — Regular expression operations](https://docs.python.org/3/library/re.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/rhzKDrUiJVk\" frameborder=\"0\"\n",
       "allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\"\n",
       "allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title [A YouTube Video](https://youtu.be/rhzKDrUiJVk) { display-mode: \"form\" }\n",
    "display(HTML(\"\"\"\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/rhzKDrUiJVk\" frameborder=\"0\"\n",
    "allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\"\n",
    "allowfullscreen></iframe>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Simple Matches\n",
    "\n",
    "#### Explicit Match: `keyword`\n",
    "\n",
    "As our first step, let us show how to create our very first regular expression in Python. To keep things simple, we are going to perform an explicit match, which is the same as doing a very simple keyword search. We are going to be looking for the word \"the\" in a text (which is also specified below). Our regular expression will simply be the word we are looking for: `the`, and we are going to compile it using Python's `re.compile`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"The classic universal approximation theorem concerns \" +\n",
    "        \"the capacity of feedforward neural networks.\")\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(\"the\")\n",
    "list(expr.finditer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "As we can see, our search using `expr.finditer` yielded an interator which we transformed into a list. It contains the total of two matches. Each match indicates the matched text and its span in the original text.\n",
    "\n",
    "#### Alternation: `alternative1|alternative2`\n",
    "\n",
    "One thing that we can note in our first example is that the first \"the\" in our text did not get matched because it was actually a \"The\" and regular expressions are case-sensitive (although this can be changed using optional parameters). If we want to match both \"the\" and \"The\", we could therefore use the alternation operator \"I\" and write an expression that allows two alternative matches: one for \"the\" and the other for \"The\", i.e. `the|The`. We will now be able to match all three definite articles \"the\" in the text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"The classic universal approximation theorem concerns \" +\n",
    "        \"the capacity of feedforward neural networks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(\"the|The\")\n",
    "list(expr.finditer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "We can also combine a standard match with an alternative match, so we could say that there is an alternative between \"t\" and \"T\" and the rest of the match needs to equal \"he\" exactly. The alternative between \"t\" and \"T\" will need to be enclosed in a parenthesis: `(t|T)he`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"The classic universal approximation theorem concerns \" +\n",
    "        \"the capacity of feedforward neural networks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(\"(t|T)he\")\n",
    "list(expr.finditer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### Character Classes: `[cbaA]`, `[0-9a-zA-Z]`\n",
    "\n",
    "Yet another way to achieve the same would be to specify a character class for the first letter. By enclosing a number of characters in square brackets that any of them is allowed as a match, i.e. in our case: `[tT]he`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"The classic universal approximation theorem concerns \" +\n",
    "        \"the capacity of feedforward neural networks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(\"[tT]he\")\n",
    "list(expr.finditer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "While this might seem as a futile exercise in providing many syntactic ways to express the same concept, character classes are actually more flexible than that. For one thing, we can use them to specify ranges of characters. E.g. to cover the entire alphabet we would write `[a-zA-Z]`, which matches all small and capital letters. And we could do the same for numerals: `[0-9]`.\n",
    "\n",
    "If, for instance, we wanted to match all 2-letter combinations starting with \"n\", we would write `n[a-zA-Z]`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"The classic universal approximation theorem concerns \" +\n",
    "        \"the capacity of feedforward neural networks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(\"n[a-zA-Z]\")\n",
    "list(expr.finditer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### Negative Character Classes: `[^cbaA]`\n",
    "\n",
    "If we want a character class that matches anything except a given set of characters, we start the class using the `^` operator. E.g. `[^e]` would match anything except \"e\". So if we write `n[^e]` this will exclude the \"ne\" matches we got before, but it will include a \"n \" match, because we are now matching whitespace as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"The classic universal approximation theorem concerns \" +\n",
    "        \"the capacity of feedforward neural networks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(\"n[^e]\")\n",
    "list(expr.finditer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### Matching Whitespace: `\\s`\n",
    "\n",
    "Actually, since we are on the subject of whitespace, to match any whitespace character, we can use `\\s`. So to further exclude the \"n \" entry and any entries with whitespace, we might write `n[^e\\s]`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"The classic universal approximation theorem concerns \" +\n",
    "        \"the capacity of feedforward neural networks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(\"n[^e\\s]\")\n",
    "list(expr.finditer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### Matching Any Character: `.`\n",
    "\n",
    "There is also notation for matching any character at all: `.`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"The classic universal approximation theorem concerns \" +\n",
    "        \"the capacity of feedforward neural networks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(\"ne.\")\n",
    "list(expr.finditer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### Escaping Meta Characters: `\\.\\^\\+` and Using Raw Strings\n",
    "\n",
    "With all these special characters it should be obvious by now that if we need to match any of them, we will need to escape them somehow. Escaping is done using backslashes `\\`. So if we want to match e.g. a literal \".\", the regular expression for that would be `\\.`. Now, if we write that in Python, it is not really going to work, because `\\` are already used in Python strings to express special characters such as a newline character `\\n`.\n",
    "\n",
    "So in order to get an actual backslash into a Python string, we would need to write two backslashes. For the purposes of the regular expression, these two would then act as a single backslash. If we need to chain more backslashes, this will quickly get confusing. Luckily, if we prepend a string with `r` in Python, e.g. `r\"\\.\"`, that indicates a special raw string. When using a raw string, there is no need for double backslashes, we can write our regular expression directly.\n",
    "\n",
    "The list of metacharacters that need to be escaped when used in the literal sense is: `. ^ $ * + ? { } [ ] \\ | ( )`.\n",
    "\n",
    "So if we want to search for any two characters followed by a dot, we can write: `r\"..\\.\"`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"The classic universal approximation theorem concerns \" +\n",
    "        \"the capacity of feedforward neural networks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(r\"..\\.\")\n",
    "list(expr.finditer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Repetition: `+*{n}?`\n",
    "\n",
    "To make things more interesting still, we can specify whether patterns are allowed to repeat and even how many times. Let us consider a few examples of that.\n",
    "\n",
    "#### An Exact Number of Repetitions: `expr{n}`\n",
    "\n",
    "By appending `{n}` to an expression (or a subexpression, enclosed in parentheses as necessary) we specify that we expect it to be repeated exactly `n` times. So to specify that we are interested in a sequence of any 4 characters except \"e\" and whitespace, we could write `[^e\\s]{4}`.\n",
    "\n",
    "#### Any Number of Repetitions: `expr*`\n",
    "\n",
    "If we want to allow any number of repetitions, we use operator star `*`.\n",
    "\n",
    "#### One Time or More: `expr+`\n",
    "\n",
    "To express that the expression has to occur at least once, but may occur more than once, we use operator `+`.\n",
    "\n",
    "#### An Optional Expression: `expr?`\n",
    "\n",
    "To express that an expression is optional (it may or may not occur), we can use operator `?`.\n",
    "\n",
    "#### Example: Matching All Whole Words\n",
    "\n",
    "Let's suppose that we want to match all words, i.e. any contiguous collection of letters separated from its context by whitespace.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The classic universal approximation theorem.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(r\"\\s[a-zA-Z]+\\s\")\n",
    "list(expr.finditer(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "Well, that did not quite work, did it? This is what often happens when writing regular expression: we forget about some cases that we want the expression to cover. Let's fix this.\n",
    "\n",
    "#### Exclude the Spaces; Lookbehind, Lookahead: `(?<=...)`, `(?=...)`\n",
    "\n",
    "Let's first exclude the spaces from the matches. We need to do this, otherwise the patterns for the neighbouring words will overlap and search will not pick up all of them.\n",
    "\n",
    "* **Lookbehind:**  To match a pattern at the beginning of our expression but not include it in the match, we can use lookbehind: `(?<=...)`, where we replace `...` with our pattern.\n",
    "\n",
    "\n",
    "* **Lookahead:**  Similarly, if we want to match a pattern at the end of our expression but not include it in the match, we can use lookahead: `(?=...)`.\n",
    "\n",
    "\n",
    "So, for our example, we can write: `(?<=\\s)[a-zA-Z]+(?=\\s)` to exclude the spaces from the matches. This way we should also already be able to pick up one more word.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The classic universal approximation theorem.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(r\"(?<=\\s)[a-zA-Z]+(?=\\s)\")\n",
    "list(expr.finditer(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### Use the Boundary Meta\n",
    "\n",
    "That is a bit better, but we are still missing the first and the last word: because these are not surrounded by spaces. We could handle that using special metacharacters for end (`$`) and start (`^`) of string and also explicitly add all punctuation. However, the expression would get rather complex. Thankfully, we can do the same using the **boundary metacharacter**  `\\b`, which matches word boundaries:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The classic universal approximation theorem.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(r\"\\b[a-zA-Z]+\\b\")\n",
    "list(expr.finditer(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### Start and End of String `^$`\n",
    "\n",
    "We have mentioned that there are metacharacters for the start (`^`) and the end (`$`) of string. So let us try to use this to match the very first word in the string. We will simply use `^` followed by the pattern, i.e.: `^[a-zA-Z]+`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The classic universal approximation theorem.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(r\"^[a-zA-Z]+\")\n",
    "list(expr.finditer(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### Matching Punctuation\n",
    "\n",
    "When matching punctuation, we can use the `string.punctuation` string, which contains all basic ASCII punctuation marks. Naturally, some of those punctuation marks happen to be regular expression metacharacters, so we need to escape them. Fortunately, this can be done automatically using `re.escape`. So let us form a character class that matches any punctuation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The classic? Universal; approximation. Theorem!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = string.punctuation\n",
    "punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_class = \"[\" + re.escape(punct) + \"]\"\n",
    "punct_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(punct_class)\n",
    "list(expr.finditer(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Capturing Groups\n",
    "\n",
    "The matches that we get using regular expressions can also be structured: instead of getting just the full text of the match, we can also get its component parts, provided we enclose them in capturing groups. We create these using parentheses. E.g. if we want to match any two words following a \"the\" and extract each of them separately, we can write: `[Tt]he ([a-zA-Z]+) ([a-zA-Z]+)`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The classic universal approximation theorem.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(r\"[Tt]he ([a-zA-Z]+) ([a-zA-Z]+)\")\n",
    "match = expr.search(sentence)\n",
    "match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "Having retrieved our match, we can now use `match.group(n)` to refer to its various capturing groups. Group 0 will always refer to the entire match.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match.group(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "Groups 1 and 2 will correspond to the first and the second word in our case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(match.group(1))\n",
    "print(match.group(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### Non-Capturing Groups\n",
    "\n",
    "The fact that parentheses serve two purposes: to enclose subexpressions and to denote capturing groups, can sometimes have annoying consequences. If, for instance, we wrote our regular expression as `(T|t)he ([a-zA-Z]+) ([a-zA-Z]+)`, group 1 would now correspond to the first set of parentheses, which encloses the alternative between `T` and `t`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The classic universal approximation theorem.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(r\"(T|t)he ([a-zA-Z]+) ([a-zA-Z]+)\")\n",
    "match = expr.search(sentence)\n",
    "match.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "This is often not the behaviour we want. In such cases, we can explicitly make a group non-capturing using `(?:...)`. So our regular expression would, in this case, be `(?:T|t)he ([a-zA-Z]+) ([a-zA-Z]+)`. Now group 1 will correspond to the word \"classic\" because \"T\" is no longer being captured.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(r\"(?:T|t)he ([a-zA-Z]+) ([a-zA-Z]+)\")\n",
    "match = expr.search(sentence)\n",
    "match.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Search and Replace\n",
    "\n",
    "Instead of matching and search, regular expressions are also often used to perform search and replace. Let us suppose that we want to replace every definite article in our sentence with string `\"XX\"`. In Python we can use `expr.subn(repl, string)` to replace all occurences of the expression in `string` with `repl`. Function `subn` returns the resulting string and the number of replacements made. We are just going to display the string.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"The classic universal approximation theorem concerns \" +\n",
    "        \"the capacity of feedforward neural networks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(r\"\\b[tT]he\\b\")\n",
    "print(expr.subn(\"XX\", text)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### Using Captured Groups in the Replacement String\n",
    "\n",
    "Let us suppose that we want to something a bit more complex: e.g. swap the first and the last word beginning with a \"c\". We can definitely already match words beginning with \"c\", but in order to swap them, we need to capture the first \"c\" word, the last \"c\" word, the text in between, and to insert them back in reverse order. Fortunately, in the replacement string, we can refer back to any captured group `n` using `\\n`. So all we need to write is: `\\b(c[a-zA-Z]+)\\b` for the first \"c\" word, `(.*)` for the text in between and `\\b(c[a-zA-Z]+)\\b` for the last \"c\" word. The replacement string will be simply `\\3\\2\\1`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"The classic universal approximation theorem concerns \" +\n",
    "        \"the capacity of feedforward neural networks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(r\"\\b(c[a-zA-Z]+)\\b(.*)\\b(c[a-zA-Z]+)\")\n",
    "print(expr.subn(r\"\\3\\2\\1\", text)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Non-recursive vs. Recursive Patterns\n",
    "\n",
    "#### Example: Remove HTML Tags\n",
    "\n",
    "As our further example, we will try to remove any HTML tags from text. This should be relatively straightforward: we simply need to match anything in between `<` and `>`.  Actually, since regular expressions are greedy, they will try to consume as many characters as possible. This is why we need to be very carefuly when specifying the expression. Let's see what would happen, if we specified our regular expression as `<.*>`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "text above\n",
    "<div>\n",
    "div 1 content\n",
    "<span>inner span</span>\n",
    "</div><div>\n",
    "div 2 content\n",
    "<span>inner span</span>\n",
    "</div>\n",
    "text below\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(r\"<.*>\")\n",
    "print(expr.subn(\"\", text)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "As you can see, this regular expression did not remove just the tags: it also removed the contents of the inner `<span>` tag; something we did not intend. The correct expression would be `<[^>]*>`. This does not allow matching beyond the next closing angle bracket `>`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = re.compile(r\"<[^>]*>\")\n",
    "print(expr.subn(\"\", text)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### Regular Expressions Cannot Express Recursive Patterns\n",
    "\n",
    "Another idea we might have would be to remove HTML tags including their contents. However, this cannot be done using regular expressions alone: they are not expressive enough to properly track the opening and closing of tags, because they cannot handle recursive patterns.\n",
    "\n",
    "To properly handle patterns of this kind, we need more expressive languages and parsers: often based on **context-free grammars** .\n",
    "\n",
    "---\n",
    "### Task: Matching Phone Numbers\n",
    "\n",
    "**Given the samples below, write function `match_number(sample)` that will match phone numbers using regular expressions. If the `sample` string is not a valid phone number, return `None`. If it is, return a pair of integers representing the country code (if not present, `None` instead) and the phone number itself.** \n",
    "\n",
    "Samples of numbers with formats from [[apache.org](https://stdcxx.apache.org/doc/stdlibug/26-1.html),[wikipedia.org](https://en.wikipedia.org/wiki/National_conventions_for_writing_telephone_numbers)]:\n",
    "\n",
    "* 754-3010: US, Local\n",
    "* (541) 754-3010: US, Domestic\n",
    "* +1-541-754-3010: US, International\n",
    "* 001-541-754-3010: US, International\n",
    "* +49-89-636-48018: German, International\n",
    "* +421 903 445 231: Slovak, International\n",
    "* 0903 445 231: Slovak, Domestic mobile\n",
    "* 41 510 4405: Slovak, Domestic landline\n",
    "* 4422-5588: Iceland, Domestic\n",
    "* 33 2187945: Netherlands, Domestic\n",
    "* +31 33 2187945: Netherlands, International\n",
    "* (33) 445-88-76: Poland, Domestic\n",
    "* +65-XXXX-YYYY: Singapore, International\n",
    "---\n",
    "Notes:\n",
    "\n",
    "* Use `fullmatch` instead of `match` or `search` to ensure that the full string and not just part of it matches the expression.\n",
    "* Once you match the number, you will probably need to remove characters such as `'(', ')', '-'` before you can convert the string to an integer using `int`. To replace characters you can use e.g. `.replace` or `str.maketrans` and `.translate`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "expr = re.compile( # ---\n",
    "\n",
    "def match_number(sample):\n",
    "    \n",
    "    \n",
    "    # ---\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### Testing\n",
    "\n",
    "Now we apply the function to some samples and check the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = 0\n",
    "\n",
    "for sample, ret in phone_number_samples:\n",
    "    try:\n",
    "        retm = match_number(sample)\n",
    "        \n",
    "        if ret != retm:\n",
    "            print(\"Incorrect response for sample '{}'.'\".format(sample))\n",
    "            print(\"  - Expected: '{}'\".format(ret))\n",
    "            print(\"  - Got: '{}'\".format(retm))\n",
    "        else:\n",
    "            num_correct += 1\n",
    "    except:\n",
    "        print(\"Exception raised for sample '{}'.\".format(sample))\n",
    "        raise\n",
    "\n",
    "print(\"{} correct out of {} samples\".format(num_correct, len(phone_number_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a351393365bb1b108989afa08de3243f72f5e58927baf5d192f3cca79a41cbc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
