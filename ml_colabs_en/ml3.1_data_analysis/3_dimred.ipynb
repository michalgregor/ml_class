{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4g3wFGqWktH",
    "tags": [
     "en"
    ]
   },
   "source": [
    "**NOTE: This notebook is written for the Google Colab platform. However it can also be run (possibly with minor modifications) as a standard Jupyter notebook.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 776
    },
    "colab_type": "code",
    "id": "v3edtGynYnV2",
    "outputId": "e408772e-a5c8-4ff2-9b42-dedb4ce69d79"
   },
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install datasets\n",
    "!{sys.executable} -m pip install umap-learn\n",
    "!{sys.executable} -m pip install git+https://github.com/michalgregor/class_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKGimae0aMhb"
   },
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from datasets import load_dataset\n",
    "from class_utils import imscatter\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CJ4ficzmWktv",
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "The goal of dimensionality reduction methods is to reduce the dimensionality o input data, while preserving as much useful information as possible. Dimensionality reduction can be applied with different purposes, e.g.:\n",
    "\n",
    "* to decrease computational expenses related to processing high-dimensional data;\n",
    "* visualization of high-dimensional data;\n",
    "* ...\n",
    "We will now illustrate how dimensionality reduction can be used for the purpose of data visualization.\n",
    "\n",
    "### Loading the Data\n",
    "\n",
    "In this example, we will be using the [Fashion MNIST](https://huggingface.co/datasets/fashion_mnist) dataset, which contains low-resolution ($28 \\times 28$ pixel) images of different kinds of footwear, clothes, etc.\n",
    "\n",
    "The images are from the following classes:\n",
    "\n",
    "label id | label       |  | label id | label     \n",
    "-------- | ----------- | - | -------- | ----------\n",
    "**0**    | T-shirt/top |  | **5**    | Sandal    \n",
    "**1**    | Trouser     |  | **6**    | Shirt     \n",
    "**2**    | Pullover    |  | **7**    | Sneaker   \n",
    "**3**    | Dress       |  | **8**    | Bag       \n",
    "**4**    | Coat        |  | **9**    | Ankle boot\n",
    "It is very easy to load the data in Python, because the `datasets` package from HugginFace includes a built-in function, which does so. We merely call the `load_dataset` function, specifying `\"fashion_mnist\"` as the dataset. With default parameters, we would get a dataset split into two parts: the train fold and the test fold. Since we are only going to be doing visualization and not supervised learning, there is going to be no need for a test set, so we specify `split='train+test'` – this way, the dataset is not going to be split.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"fashion_mnist\", split='train+test')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CJ4ficzmWktv",
    "tags": [
     "en"
    ]
   },
   "source": [
    "One rather covenient feature of datasets loading using `load_dataset` is that they come with a `.info` attribute, which holds metadata about the dataset. One can, for instance, display a short description of the dataset, or get the label names:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.info.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset.info.features['label'].names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray([np.asarray(img) for img in dataset['image']])\n",
    "Y = np.asarray(dataset['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nRN68VtvWkul",
    "tags": [
     "en"
    ]
   },
   "source": [
    "To get some idea of what our data looks like, we will now display a few randomly selected samples:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "colab_type": "code",
    "id": "e4TYSHU0WN_0",
    "outputId": "c965fa27-7f0a-4760-ff47-977fdfb236e2"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 5)\n",
    "fig.set_size_inches([7, 7])\n",
    "\n",
    "for ax_row in axes:\n",
    "    for ax in ax_row:\n",
    "        ind = np.random.randint(0, X.shape[0])\n",
    "        ax.imshow(X[ind], cmap='Greys')\n",
    "        ax.set_title(class_names[Y[ind]])\n",
    "        ax.axis('off')\n",
    "    \n",
    "plt.subplots_adjust(hspace=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gm_KpQHvWku9",
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Preprocessing\n",
    "\n",
    "Note that normally we would **standardize**  the data (rescale each column so that its mean is at zero and the standard deviation is 1) before applying PCA or UMAP. This is so that the methods do not consider certain columns more important just because their scale is larger. In this case, however, our data consists of images so each dimension (each pixel) already has the same scale.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE DO NOT NEED THIS BECAUSE WE HAVE AN IMAGE DATASET\n",
    "\n",
    "# input_preproc = make_pipeline(\n",
    "#     SimpleImputer(),\n",
    "#     StandardScaler()\n",
    "# )\n",
    "\n",
    "# X_preproc = input_preproc.fit_transform(X.reshape(X.shape[0], -1))\n",
    "# X_preproc = X_preproc.reshape(X.shape)\n",
    "# X = X_preproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gm_KpQHvWku9",
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Dimensionality Reduction using PCA and Visualization\n",
    "\n",
    "Given that the images are $28 \\times 28$ pixels, we are dealing with a 784-dimensional space. If we want to visualize its structure, we will need to reduce our data into 2-dimensional space. Naturally, we will loose a lot of information that way, but hopefully we will still be able to learn something about the structure of the space this way.\n",
    "\n",
    "The first method that we are going ot test is called PCA. It is a very fast method, but it can only make use of linear relationships in the data – not of non-linear ones. However, for some datasets this is sufficient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KTrJbWS8kjRx"
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "points_pca = pca.fit_transform(X.reshape((X.shape[0], -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hOyCrwr3WkvT",
    "tags": [
     "en"
    ]
   },
   "source": [
    "We will shuffle the points before we visualize them – the data is sorted by class in the original dataset. If we want to see whether PCA can separate the classes, shuffling the data first is going to be good idea: otherwise a later class could completely cover the points of an earlier class, thereby giving us a false impression of good separation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ken-umFpSmU"
   },
   "outputs": [],
   "source": [
    "perm_ind = np.random.permutation(points_pca.shape[0])\n",
    "xx = points_pca[perm_ind]\n",
    "yy = Y[perm_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x5L6HqS6Wkvw",
    "tags": [
     "en"
    ]
   },
   "source": [
    "Finally, we only need to visualize all the resulting points and colour them by class. As we can see, the classes do not seem to be clearly separated from each other after doing PCA. Some classes actually appear to be separated (such as bag and trouser), but the figure is rather unreadable as a whole. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "colab_type": "code",
    "id": "SdF3dz90kjXy",
    "outputId": "5a24ee2a-e55e-4f07-8397-26f4c3ecb5ba"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 7])\n",
    "plt.scatter(xx[:, 0], xx[:, 1], c=yy,\n",
    "            cmap=plt.cm.get_cmap('jet', len(class_names)),\n",
    "            rasterized=True)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_ticks(range(len(class_names)))\n",
    "cbar.set_ticklabels(class_names)\n",
    "plt.xlabel(\"dim 1\")\n",
    "plt.ylabel(\"dim 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V6MG8_TlWkwR",
    "tags": [
     "en"
    ]
   },
   "source": [
    "The figure would be still less informative if we didn't colour the points by class:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "3yZIc--fkjVE",
    "outputId": "d963f46f-d485-4544-c5ad-f7b5886bdac1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 7])\n",
    "plt.scatter(xx[:, 0], xx[:, 1], rasterized=True)\n",
    "plt.xlabel(\"dim 1\")\n",
    "plt.ylabel(\"dim 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oObTSh_sWkw4",
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### Note: Rasterizing Parts of the Image\n",
    "\n",
    "Note that we have used parameter `rasterized=True` when plotting the points. This parameter indicates that the corresponding part of the image should be rasterized (instead of being kept in vector form). This is very useful when plotting a huge number of points: if we saved all of them in vector format, it would be very expensive to display the image.\n",
    "\n",
    "We could, of course, simply save the entire figure in a raster format (such as jpeg or png) – but that would rasterize all parts of the image, including axes and such. On the whole, it is better to avoid rasterizing everything: especially if the figure is to be published.\n",
    "\n",
    "When part of the figure is too complex to be presented in vector format, rastering it and keeping the rest of the figure in vector format is a good compromise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "59n7k1-yWkxC",
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Dimensionality Reduction using UMAP and Visualization\n",
    "\n",
    "Dimensionality reduction using UMAP will be much more time-consuming than it was using PCA. On the other hand, we can expect hte results to be a lot better, because UMAP can take advantage of non-linear as well as linear relationships in the data.\n",
    "\n",
    "To apply UMAP instead of PCA, we literally only need to replace \"PCA\" with \"UMAP\", because both method have the unified interface used in the `scikit-learn` package. If we want to get a bit more information about what UMAP is doing, we can add the argument `verbose=True`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "colab_type": "code",
    "id": "J5BdkFX-kjOW",
    "outputId": "6e566188-5b6b-4148-8533-10c5d062ed63"
   },
   "outputs": [],
   "source": [
    "um = umap.UMAP(verbose=True)\n",
    "points_umap = um.fit_transform(X.reshape((X.shape[0], -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RaxP2n4JrgN2"
   },
   "outputs": [],
   "source": [
    "perm_ind = np.random.permutation(points_umap.shape[0])\n",
    "xx = points_umap[perm_ind]\n",
    "yy = Y[perm_ind]\n",
    "xt = X[perm_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "colab_type": "code",
    "id": "YLxu5YV8rWUA",
    "outputId": "6a558f7a-00da-4624-c894-44204e503510"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 7])\n",
    "cmap = plt.cm.get_cmap('jet', len(class_names))\n",
    "plt.scatter(xx[:, 0], xx[:, 1], c=yy,\n",
    "            cmap=cmap,\n",
    "            rasterized=True)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_ticks(range(len(class_names)))\n",
    "cbar.set_ticklabels(class_names)\n",
    "plt.xlabel(\"dim 1\")\n",
    "plt.ylabel(\"dim 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ew_i9XkCWkx6",
    "tags": [
     "en"
    ]
   },
   "source": [
    "From this image, we can already learn a lot more about the structure of the dataset. We can see that the samples are divided into 4 major groups. One of them contains trousers, another one contains handbags, the third one contains a mixture of different kinds of footwear and the last one a mixture of t-shirts, dresses, coats and such.\n",
    "\n",
    "We can also see that while t-shirts and coats are quite intermixes, shoes have rather more structure within their cluster.\n",
    "\n",
    "### More Advanced Visualization\n",
    "\n",
    "Our UMAP-based visualization shows us that, for some reason, there is a contiguous path from the handbag cluster into the t-shirt cluster. It would be interesting to find out what kinds of samples we would find where the two clusters connect. To find out, let's plot a subset of the data, but instead of plotting just the points, let's visualize the actual images at the corresponding positions. That will provide us with a fuller idea of what the structure of the data is in the area of interest.\n",
    "\n",
    "We will use an auxiliary function with an interface similar to `scatter`, which will plot images instead of points, though.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "i8-vL_Y8riPu",
    "outputId": "499711d3-1ef6-418b-c1ce-064691493c21"
   },
   "outputs": [],
   "source": [
    "num2show = 800\n",
    "\n",
    "plt.figure(figsize=[15, 10])\n",
    "imscatter(xx[:num2show, 0], xx[:num2show, 1],\n",
    "          xt[:num2show], cmap='Greys', zoom=1.2,\n",
    "          frame_c=yy[:num2show], frame_cmap=cmap,\n",
    "          frame_linewidth=2)\n",
    "plt.xlabel(\"dim 1\")\n",
    "plt.ylabel(\"dim 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Si_itgtWkyW",
    "tags": [
     "en"
    ]
   },
   "source": [
    "The figure should show how the images of handbags gradually change shape so that at the low resolution and grayscale coloring some of them could plausibly be mistaken for t-shirts.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "1_dimred.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a351393365bb1b108989afa08de3243f72f5e58927baf5d192f3cca79a41cbc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
