{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**NOTE: This notebook is written for the Google Colab platform. However it can also be run (possibly with minor modifications) as a standard Jupyter notebook.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install git+https://github.com/michalgregor/class_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from IPython.display import HTML\n",
    "from IPython.utils.capture import capture_output\n",
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Downloading Data -- { display-mode: \"form\" }\n",
    "from class_utils.download import download_file_maybe_extract\n",
    "download_file_maybe_extract(\"https://www.dropbox.com/s/u8u7vcwy3sosbar/titanic.zip?dl=1\", directory=\"data/titanic\")\n",
    "\n",
    "# also create a directory for storing any outputs\n",
    "import os\n",
    "os.makedirs(\"output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Auxiliary Functions -- { display-mode: \"form\" }\n",
    "\n",
    "# fix the seed of the random generator\n",
    "# np.random.seed(4)\n",
    "\n",
    "# GP-based Bayes opti\n",
    "def random_point(lbound=0, ubound=5):\n",
    "    return np.random.uniform(0, 5)\n",
    "    \n",
    "def next_point(gp, ybest, acquisition_func):\n",
    "    x = random_point()\n",
    "    \n",
    "    best_score = np.inf\n",
    "    num_restarts = 10\n",
    "    \n",
    "    for i in range(num_restarts):\n",
    "        res = minimize(lambda xx: -acquisition_func(gp,\n",
    "                           xx.reshape([-1, 1]), ybest).item(),\n",
    "                       random_point(),\n",
    "                       method='L-BFGS-B',\n",
    "                       bounds=[[0, 5]])\n",
    "\n",
    "        if res.fun < best_score:\n",
    "            best_score = res.fun\n",
    "            x = res.x\n",
    "\n",
    "    return x\n",
    "\n",
    "# plotting\n",
    "def plot_distro(\n",
    "    x, gp, intervals=True, ax=None,\n",
    "    xlabel=\"x\", ylabel=\"y\", return_preds=False\n",
    "):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    y_mean, y_std = gp.predict(x.reshape((-1, 1)), return_std=True) \n",
    "    y_mean, y_std = y_mean.reshape(-1), y_std.reshape(-1)\n",
    "    \n",
    "    ax.plot(x, y_mean, 'k', lw=3, zorder=9)\n",
    "    \n",
    "    if intervals:\n",
    "        ax.fill_between(x, y_mean - 3*y_std, y_mean + 3*y_std,\n",
    "                         alpha=0.2, color='b')\n",
    "    \n",
    "    ax.set_xlim(np.min(x), np.max(x))\n",
    "    ax.set_ylim(-5, 5)\n",
    "    ax.grid(ls='--')\n",
    "    \n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "\n",
    "    if return_preds:\n",
    "        return y_mean, y_std\n",
    "    \n",
    "def plot_distro_func_data(\n",
    "    x, gp=None, X=None, Y=None, func=None,\n",
    "    intervals=True, ax=None, return_preds=False\n",
    "):\n",
    "    preds = None\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    if not gp is None:\n",
    "        preds = plot_distro(\n",
    "            x, gp, intervals=intervals, ax=ax, return_preds=return_preds\n",
    "        )\n",
    "        \n",
    "    if not func is None:\n",
    "        ax.plot(x, func(x), '--', linewidth=3)\n",
    "    \n",
    "    if not X is None and not Y is None:\n",
    "        ax.scatter(X, Y, c='r', s=50, zorder=10, edgecolors=(0, 0, 0))\n",
    "    \n",
    "    return preds\n",
    "\n",
    "def bayes_opti_anim(fig, gp, x, func, acquisition_func,\n",
    "                      X=None, Y=None, num_opti_steps=10, ax=None,\n",
    "                      save_figures=True, save_plain=True,\n",
    "                      save_plain_nofunc=True, save_nofunc=True):\n",
    "    with capture_output() as io:\n",
    "        if ax is None:\n",
    "            ax = fig.gca()\n",
    "            \n",
    "        ax.clear()\n",
    "        plot_distro_func_data(x, gp, func=func, ax=ax)\n",
    "        plt.show()\n",
    "        if save_figures:\n",
    "            fig.savefig(\"output/gp_opti_init.svg\",\n",
    "                        bbox_inches=\"tight\", pad_inches=0)\n",
    "        yield\n",
    "\n",
    "        if X is None: X = []\n",
    "        if Y is None: Y = []\n",
    "\n",
    "        x0 = random_point()\n",
    "        xbest = x0\n",
    "        ybest = func(x0)\n",
    "\n",
    "        for s in range(num_opti_steps):\n",
    "            nx = next_point(gp, ybest, acquisition_func)\n",
    "            ny = func(nx)\n",
    "\n",
    "            if ny < ybest:\n",
    "                xbest = nx\n",
    "                ybest = ny\n",
    "\n",
    "            X.append(nx)\n",
    "            Y.append(ny)\n",
    "\n",
    "            gp.fit(np.reshape(X, (-1, 1)),\n",
    "                   np.reshape(Y, (-1, 1)))\n",
    "            \n",
    "            if save_plain:\n",
    "                ax.clear()\n",
    "                plot_distro_func_data(x, gp, func=func, X=X, Y=Y, ax=ax,\n",
    "                                      intervals=False)\n",
    "                fig.savefig(\"output/gp_opti_plain_{}.svg\".format(s),\n",
    "                            bbox_inches=\"tight\", pad_inches=0)\n",
    "                \n",
    "            if save_plain_nofunc:\n",
    "                ax.clear()\n",
    "                plot_distro_func_data(x, gp, X=X, Y=Y, ax=ax,\n",
    "                                      intervals=False)\n",
    "                fig.savefig(\"output/gp_opti_plain_nofunc_{}.svg\".format(s),\n",
    "                            bbox_inches=\"tight\", pad_inches=0)\n",
    "                \n",
    "            if save_nofunc:\n",
    "                ax.clear()\n",
    "                plot_distro_func_data(x, gp, X=X, Y=Y, ax=ax)\n",
    "                fig.savefig(\"output/gp_opti_nofunc_{}.svg\".format(s),\n",
    "                            bbox_inches=\"tight\", pad_inches=0)\n",
    "\n",
    "            ax.clear()\n",
    "            plot_distro_func_data(x, gp, func=func, X=X, Y=Y, ax=ax)\n",
    "\n",
    "            plt.show()\n",
    "            if save_figures:\n",
    "                fig.savefig(\"output/gp_opti_{}.svg\".format(s),\n",
    "                            bbox_inches=\"tight\", pad_inches=0)\n",
    "            yield\n",
    "\n",
    "        ax.clear()\n",
    "        x = np.linspace(0, 5, 100)\n",
    "        plot_distro_func_data(x, gp, func=func, X=X, Y=Y, ax=ax)\n",
    "        ax.scatter([xbest], [ybest], c='cyan', marker='x', linewidth=5,\n",
    "                    s=100, zorder=10, edgecolors=(0, 0, 0))\n",
    "        plt.show()\n",
    "        if save_figures:\n",
    "            fig.savefig(\"output/gp_opti_final.svg\",\n",
    "                        bbox_inches=\"tight\", pad_inches=0)\n",
    "        yield\n",
    "        \n",
    "    print(\"solution:\", xbest, ybest)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Bayesian Optimization\n",
    "\n",
    "### The Intuition behind Bayesian Optimization\n",
    "\n",
    "There are many different kinds of optimization methods. Some, such as gradient descent are based on gradient information, some even on higher-order derivatives: e.g. the Newton method and its many approximations. Other classes of optimization methods rely on search and employ various clever tricks to make it computationally viable. Yet another class is based on populations of candidate solutions and employs different metaheuristic approaches such as mimicking evolution or other natural phenomena.\n",
    "\n",
    "But whichever of these methods we are going to choose, there is a class of problems that are exceptionally difficult to solve in a reasonable amount of time: problems where it is extremely computationally expensive to evaluate the objective function. Unfortunately, such problems make up a sizable portion of optimization tasks in practice. They are ubiquitous even within machine learning, because methods have hyperparameters, which usually need to be tuned for the method to achieve optimal performance. But to evaluate a set of hyperparameters we typically need to train the entire machine learning model (which, e.g. in the case of deep learning, can sometimes take days, even weeks) from scratch and to test it.\n",
    "\n",
    "#### Surrogate Optimization Methods\n",
    "\n",
    "In cases like that we need to make sure that we are able to squeeze out as much information as possible from every evaluation of the objective function. To that purpose we could use the points at which the objective function has already been evaluated to form a **surrogate model** : a function that we could then optimize instead of the objective function. This is what **surrogate optimization methods**  do.\n",
    "\n",
    "#### The Bayesian Approach to Surrogate Optimization\n",
    "\n",
    "There is another question, though. How do we pick the points to evaluate the objective function at, to get the data needed to construct our surrogate model in the first place? We could, perhaps, just take some uniformly random samples from the domain of the objective function and use those.\n",
    "\n",
    "However, our surrogate model will just be as good as the samples we happened to select. It may still be too expensive to build a sufficiently good surrogate, in which case the optimization process may simply find ways to exploit its errors to get good, but unrealistic scores.\n",
    "\n",
    "However, there is fortunately a better way: we can refine the surrogate iteratively. We can pick our first point (or a set of points) uniformly, set up our model around it and then use the information to determine which point to pick next. Let us start by setting up a Gaussian process – we'll be trying to minimize the function $\\sin([x-2.5]^2)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return np.sin((x - 2.5) ** 2)\n",
    "\n",
    "kernel = 1.0 * RBF(length_scale=1.0, length_scale_bounds=(1e-1, 1.0))\n",
    "gp = GaussianProcessRegressor(kernel=kernel)\n",
    "\n",
    "x = np.linspace(0, 5, 100)\n",
    "plot_distro_func_data(x, gp, func=func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "The dashed curve corresponds to our objective function. The thick black line represents the current mean predicted by our GP. As usual, the shaded area corresponds to $\\pm3\\sigma$ from the mean.\n",
    "\n",
    "Having received no evidence yet, we only have our prior. We have no reason to think that one region or another is more likely to contain the minimum. So, just as we said, let us select our initial data point uniformly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [np.random.uniform(0, 5)]\n",
    "Y = [func(xx) for xx in X]\n",
    "\n",
    "gp.fit(np.reshape(X, (-1, 1)),\n",
    "       np.reshape(Y, (-1, 1)))\n",
    "\n",
    "x = np.linspace(0, 5, 100)\n",
    "plot_distro_func_data(x, gp, func=func, X=X, Y=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "The interesting thing, of course, is that having selected our first point, we now already have some new evidence that we will be able to inform our choice of the next point.\n",
    "\n",
    "### The Exploration vs. Exploitation Trade-off\n",
    "\n",
    "When selecting subsequent points to evaluate, we will be trying to balance two subgoals:\n",
    "\n",
    "* **Exploration:**  Trying to reduce uncertainty in the not yet sufficiently explored regions – to find out whether they are likely to contain the minimum or whether they can be ruled out.\n",
    "* **Exploitation:**  Trying to focus attention onto areas that we already believe might contain the minimum (i.e. where there is already evidence that the objective function takes low values).\n",
    "What we have just described is, in fact, known as the **exploration vs. exploitation trade-off**  and is to be encountered in other areas as well, e.g. in reinforcement learning.\n",
    "\n",
    "The beatiful thing about Bayesian methods such as Gaussian processes is that by maintaining the full posterior instead of just predicting the most likely value, they allow us to explicitly keep track of uncertainty and thus to directly balance exploration and exploitation.\n",
    "\n",
    "So, all in all, we will on one hand be trying to get as close to the minimum as possible and on the other hand to remove as much uncertainty as possible.\n",
    "\n",
    "### The Optimization\n",
    "\n",
    "The component of Bayesian optimization that helps to suggest the next point to sample, is called the **acquisition function** . Given the acquisition function, any off-the-shelf optimization method of choice can be used to find its optimum w.r.t. the surrogate. One of the most popular acquisition functions is the **expected improvement** , which is defined as follows [[jones]](#jones):\n",
    "\n",
    "$$\n",
    "EI(\\mathbf{x}) \\equiv \\mathbb{E} \\left[ \\max(f_{\\min} - f(\\mathbf{x}), 0) \\right].\n",
    "$$\n",
    "where $f(\\mathbf{x})$ expresses the value of the surrogate at point $\\mathbf{x}$ (this is a random variable), hence the need for the expectation; $f_{\\min}$ is the best (the lowest) value obtained so far; and the improvement must be non-negative, therefore the $\\max$ operator.\n",
    "\n",
    "Thus, the expected improvement expresses exactly what the name suggests: the expected value of improvement, that is, the difference between the best value so far and the value at $\\mathbf{x}$. If the $f(\\mathbf{x})$ is Gaussian, i.e.:\n",
    "$f(\\mathbf{x}) \\sim \\mathcal{N}(\\mu(\\mathbf{x}), \\sigma(\\mathbf{x}))$\n",
    "(which, in the case of Gaussian processes, it, of course, is), the expected improvement can also be expressed in the following more convenient form [[jones]](#jones):\n",
    "\n",
    "$$\n",
    "EI(\\mathbf{x}) = \\left(\n",
    "    f_{\\min} - \\mu(\\mathbf{x})\n",
    "\\right)\\;\n",
    "\\Phi \\left(\n",
    "    \\frac{\n",
    "        f_{\\min} - \\mu(\\mathbf{x})\n",
    "    }{\n",
    "        \\sigma(\\mathbf{x})\n",
    "    }\n",
    "\\right)\n",
    "+ \\sigma(\\mathbf{x}) \\phi \\left(\n",
    "    \\frac{\n",
    "        f_{\\min} - \\mu(\\mathbf{x})\n",
    "    }{\n",
    "        \\sigma(\\mathbf{x})\n",
    "    }\n",
    "\\right)\n",
    "$$\n",
    "where $\\phi$ is the Gaussian probability density function (PDF) and $\\Phi$ is the Gaussian cumulative distribution function (CDF).\n",
    "\n",
    "To gain more explicit control of the exploration-exploitation trade-off, one can subtract parameter $\\xi$ from the difference $f_{\\min} - \\mu(\\mathbf{x})$ [[brochu]](#brochu):\n",
    "\n",
    "$$\n",
    "EI(\\mathbf{x}) = \\left(\n",
    "    f_{\\min} - \\mu(\\mathbf{x}) - \\xi\n",
    "\\right)\\;\n",
    "\\Phi \\left(\n",
    "    \\frac{\n",
    "        f_{\\min} - \\mu(\\mathbf{x}) - \\xi\n",
    "    }{\n",
    "        \\sigma(\\mathbf{x})\n",
    "    }\n",
    "\\right)\n",
    "+ \\sigma(\\mathbf{x}) \\phi \\left(\n",
    "    \\frac{\n",
    "        f_{\\min} - \\mu(\\mathbf{x}) - \\xi\n",
    "    }{\n",
    "        \\sigma(\\mathbf{x})\n",
    "    }\n",
    "\\right)\n",
    "$$\n",
    "The difference $f_{\\min} - \\mu(\\mathbf{x})$ is the performance term: it expresses how much better the point $\\mathbf{x}$ appears (through the mean of $f(\\mathbf{x}$) in comparison to the best value so far. The rest of the criterion is to take variance (uncertainty) into account as well. So by subtracting $\\xi$, we are lowering the weight of the performance term, encouraging more exploration.\n",
    "\n",
    "The value of $\\xi = 0.01$, scaled by the signal variance if necessary, has been reported to work well in most cases. Annealing $\\xi$ (to encourage exploration at the beginning and expoitation towards the end) has been shown not to work very well empirically [[jones]](#jones).\n",
    "\n",
    "---\n",
    "### Task 1: Implement the Expected Improvement\n",
    "\n",
    "**Implement the expected improvement acquisition function by rewriting the formula shown below into Python code. Use the signature provided in the cell below.** \n",
    "\n",
    "Note: you can use `norm.pdf` and `norm.cdf` to compute the Gaussian PDF and CDF respectively.\n",
    "\n",
    "$$\n",
    "EI(\\mathbf{x}) = \\left(\n",
    "    f_{\\min} - \\mu(\\mathbf{x}) - \\xi\n",
    "\\right)\\;\n",
    "\\Phi \\left(\n",
    "    \\frac{\n",
    "        f_{\\min} - \\mu(\\mathbf{x}) - \\xi\n",
    "    }{\n",
    "        \\sigma(\\mathbf{x})\n",
    "    }\n",
    "\\right)\n",
    "+ \\sigma(\\mathbf{x}) \\phi \\left(\n",
    "    \\frac{\n",
    "        f_{\\min} - \\mu(\\mathbf{x}) - \\xi\n",
    "    }{\n",
    "        \\sigma(\\mathbf{x})\n",
    "    }\n",
    "\\right)\n",
    "$$\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "def expected_improvement(gp, x, fmin, explo_rate=0.01):\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu = mu.reshape(-1); sigma = sigma.reshape(-1)\n",
    "    \n",
    "\n",
    "    \n",
    "    # ---\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "Finally, we will use our `expected_improvement` function with a predefined auxiliary function `bayes_opti_anim`, which will take care of optimizing the acquisition function over the surrogate using LBFGS and then iteratively updating the surrogate using the newly suggested points. The results will be presented in the form of an animated figure. We should see how the objective function is gradually explored and the approximate minimum found.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 1.0 * RBF(length_scale=1.0, length_scale_bounds=(1e-1, 1.0))\n",
    "gp = GaussianProcessRegressor(kernel=kernel)\n",
    "\n",
    "fig = plt.figure()\n",
    "x = np.linspace(0, 5, 100)\n",
    "frames = lambda: bayes_opti_anim(fig, gp, x, func=func,\n",
    "               acquisition_func=expected_improvement,\n",
    "               num_opti_steps=10)\n",
    "\n",
    "anim = FuncAnimation(fig, func=lambda x: None,\n",
    "                     interval=200, frames=frames)\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Visualizing the Expected Improvement\n",
    "\n",
    "To get more intuition as to what our acquisition function (expected improvement) expresses, let us visualize it for a simple GP conditioned on some data points. The exploration rate is set to $\\xi=0.01$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [0.5, 3.5]\n",
    "Y = [func(xx) for xx in X]\n",
    "\n",
    "kernel = 1.0 * RBF(length_scale=1.0, length_scale_bounds=(1e-1, 1.0))\n",
    "gp = GaussianProcessRegressor(kernel=kernel)\n",
    "gp.fit(np.reshape(X, (-1, 1)),\n",
    "       np.reshape(Y, (-1, 1)))\n",
    "\n",
    "x = np.linspace(0, 5, 100)\n",
    "fig, axes = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "explo_rate=0.01\n",
    "ac = expected_improvement(gp, x, np.min(Y), explo_rate=explo_rate)\n",
    "\n",
    "plot_distro_func_data(x, gp, X=X, Y=Y, ax=axes[0])\n",
    "axes[1].plot(x, ac)\n",
    "axes[1].set_xlabel(\"x\")\n",
    "axes[1].set_ylabel(\"EI(x)\")\n",
    "plt.grid(ls='--')\n",
    "\n",
    "fig.savefig(\"output/expected_improvement.svg\",\n",
    "            bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Understanding the Expected Improvement\n",
    "\n",
    "Now let's try to understand the math behind the expected improvement a bit more:\n",
    "\n",
    "$$\n",
    "EI(\\mathbf{x}) \\equiv \\mathbb{E} \\left[ \\max(f_{\\min} - f(\\mathbf{x}) - \\xi, 0) \\right].\n",
    "$$\n",
    "Let's go through it all in order.\n",
    "\n",
    "#### The Actual Improvement\n",
    "\n",
    " First, there is the actual improvement expressed as $f_{\\min} - f(\\mathbf{x})$ in the formula. The larger this difference is, the better $f(\\mathbf{x})$ is than the previous best.\n",
    "\n",
    "#### Bounding the Improvement from Below\n",
    "\n",
    "The $\\max(\\text{improvement}, 0)$ puts the lower bound of zero on the improvement. This means that we essentially ignore all cases where $f(\\mathbf{x})$ is actually worse than $f_{\\min}$ and we default to the improvement of 0 even though the value would otherwise be negative.\n",
    "\n",
    "As shown in the figure below, this means that we only consider the area **below the dashed red line**  (everything below the dashed line, but the shaded $\\pm 3\\sigma$ interval is where most of the probablity is). This is the only part that can make a non-zero contribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Expected improvement + visualization of clipping explo_rate=0.01 -- { display-mode: \"form\" }\n",
    "X = [0.5, 3.5]\n",
    "Y = [func(xx) for xx in X]\n",
    "\n",
    "kernel = 1.0 * RBF(length_scale=1.0, length_scale_bounds=(1e-1, 1.0))\n",
    "gp = GaussianProcessRegressor(kernel=kernel)\n",
    "gp.fit(np.reshape(X, (-1, 1)),\n",
    "       np.reshape(Y, (-1, 1)))\n",
    "\n",
    "x = np.linspace(0, 5, 100)\n",
    "fig, axes = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "explo_rate=0.01\n",
    "ac = expected_improvement(gp, x, np.min(Y), explo_rate=explo_rate)\n",
    "\n",
    "y_mean, y_std = plot_distro_func_data(x, gp, X=X, Y=Y, ax=axes[0], return_preds=True)\n",
    "axes[1].plot(x, ac)\n",
    "axes[1].set_xlabel(\"x\")\n",
    "axes[1].set_ylabel(\"EI(x)\")\n",
    "plt.grid(ls='--')\n",
    "\n",
    "f_min_xi = np.min(Y) - explo_rate\n",
    "axes[0].axhline(y=f_min_xi, c='r', ls='--', zorder=10, label=\"$f_{\\min}$\")\n",
    "axes[0].fill_between(x, np.minimum(y_mean - 3*y_std, f_min_xi), f_min_xi,\n",
    "                     color='r', alpha=0.3, zorder=5, label=\"unclipped area\")\n",
    "axes[0].legend()\n",
    "\n",
    "fig.savefig(\"output/expected_improvement_shaded_001.svg\",\n",
    "            bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### The Expected Value\n",
    "\n",
    "The rest is simple, really – we take the expected value of improvements below the dashed line, so areas where our confidence interval reaches down towards more optimal values will get preference.\n",
    "\n",
    "#### The Exploration Rate\n",
    "\n",
    "To make the effect of exploration rate $\\xi$ more obvious, we are going to increase it to $\\xi = 0.75$ from $0.01$. As you can see, this shifts the dashed line further down. This aids exploration because points within the margin are ignored, which, of course, benefits regions with more uncertainty, where the $\\pm 3 \\sigma$ region reaches further down and it is therefore not clipped as much.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Expected improvement + visualization of clipping with explo_rate=0.75 -- { display-mode: \"form\" }\n",
    "X = [0.5, 3.5]\n",
    "Y = [func(xx) for xx in X]\n",
    "\n",
    "kernel = 1.0 * RBF(length_scale=1.0, length_scale_bounds=(1e-1, 1.0))\n",
    "gp = GaussianProcessRegressor(kernel=kernel)\n",
    "gp.fit(np.reshape(X, (-1, 1)),\n",
    "       np.reshape(Y, (-1, 1)))\n",
    "\n",
    "x = np.linspace(0, 5, 100)\n",
    "fig, axes = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "explo_rate=0.75\n",
    "ac = expected_improvement(gp, x, np.min(Y), explo_rate=explo_rate)\n",
    "\n",
    "y_mean, y_std = plot_distro_func_data(x, gp, X=X, Y=Y, ax=axes[0], return_preds=True)\n",
    "axes[1].plot(x, ac)\n",
    "axes[1].set_xlabel(\"x\")\n",
    "axes[1].set_ylabel(\"EI(x)\")\n",
    "plt.grid(ls='--')\n",
    "\n",
    "f_min_xi = np.min(Y) - explo_rate\n",
    "axes[0].axhline(y=f_min_xi, c='r', ls='--', zorder=10, label=r\"$f_{\\min} - \\xi$\")\n",
    "axes[0].fill_between(x, np.minimum(y_mean - 3*y_std, f_min_xi), f_min_xi,\n",
    "                     color='r', alpha=0.3, zorder=5, label=\"unclipped area\")\n",
    "axes[0].legend()\n",
    "\n",
    "fig.savefig(\"output/expected_improvement_shaded_075.svg\",\n",
    "            bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "<a id=\"jones\">[jones]</a> Jones, D.R., Schonlau, M. and Welch, W.J., 1998. Efficient global optimization of expensive black-box functions. Journal of Global optimization, 13(4), pp.455-492. [https://link.springer.com/content/pdf/10.1023/A:1008306431147.pdf](https://link.springer.com/content/pdf/10.1023/A:1008306431147.pdf)\n",
    "\n",
    "<a id=\"brochu\">[brochu]</a> Brochu, E., Cora, V.M. and De Freitas, N., 2010. A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning. arXiv preprint arXiv:1012.2599. [https://arxiv.org/abs/1012.2599](https://arxiv.org/abs/1012.2599)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
