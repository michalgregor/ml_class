{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**NOTE: This notebook is written for the Google Colab platform. However it can also be run (possibly with minor modifications) as a standard Jupyter notebook.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install git+https://github.com/michalgregor/class_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, KBinsDiscretizer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from class_utils import error_histogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Downloading Data -- { display-mode: \"form\" }\n",
    "from class_utils.download import download_file_maybe_extract\n",
    "download_file_maybe_extract(\"https://www.dropbox.com/s/3jnf3000vwaxtcg/boston_housing.zip?dl=1\", directory=\"data/boston_housing\")\n",
    "\n",
    "# also create a directory for storing any outputs\n",
    "import os\n",
    "os.makedirs(\"output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Gaussian Process Regression: An Example\n",
    "\n",
    "In this notebook we are going to apply Gaussian process regression to an actual dataset: the Boston housing dataset, where the goal is to predict the median value of a house, given certain input attributes. We'll start by loading and preprocessing the data. Since we have done this many times and there is nothing very special about the preprocessing we are going to apply, the code of the next cell is hidden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Loading Data into X_train, Y_train, X_test, Y_test -- { display-mode: \"form\" }\n",
    "df = pd.read_csv(\"data/boston_housing/housing.csv\")\n",
    "display(df.head())\n",
    "\n",
    "# we discretize the target variable and use the result for stratification\n",
    "kbins = KBinsDiscretizer(10, encode='ordinal')\n",
    "y_stratify = kbins.fit_transform(df[[\"medv\"]])\n",
    "df_train, df_test = train_test_split(df, stratify=y_stratify,\n",
    "                        test_size=0.25, random_state=4)\n",
    "\n",
    "# we split the columns into categorical and numeric inputs and the output\n",
    "categorical_inputs = ['chas']\n",
    "numeric_inputs = ['crim', 'zn', 'indus', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
    "       'ptratio', 'black', 'lstat']\n",
    "output = [\"medv\"]\n",
    "\n",
    "# we create our preprocessing pipeline\n",
    "input_preproc = make_column_transformer(\n",
    "    (make_pipeline(\n",
    "        SimpleImputer(strategy=\"most_frequent\"),\n",
    "        OrdinalEncoder(categories='auto')),\n",
    "     categorical_inputs),\n",
    "    \n",
    "    (make_pipeline(\n",
    "        SimpleImputer(),\n",
    "        StandardScaler()),\n",
    "     numeric_inputs)\n",
    ")\n",
    "\n",
    "output_preproc = StandardScaler()\n",
    "\n",
    "# we fit the pipeline on the train set and then apply it to both train and test\n",
    "X_train = input_preproc.fit_transform(df_train[categorical_inputs+numeric_inputs])\n",
    "Y_train = output_preproc.fit_transform(df_train[output])\n",
    "X_test = input_preproc.transform(df_test[categorical_inputs+numeric_inputs])\n",
    "Y_test = output_preproc.transform(df_test[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "---\n",
    "### Task 1: Create the Gaussian Process Regressor\n",
    "\n",
    "**Use the concepts illustrated in the previous notebook to create a Gaussian process regressor with an RBF + white noise kernel and fit it to the training data.** \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "kernel = # ----\n",
    "model = # ----\n",
    "\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Testing the Model\n",
    "\n",
    "As our next step we are going to do our standard evaluation on the testing set and we will display the histogram of outputs and errors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Testing -- { display-mode: \"form\" }\n",
    "y_test = model.predict(X_test)\n",
    "min_output = np.min(Y_test)\n",
    "max_output = np.max(Y_test)\n",
    "\n",
    "# we compute and display the MSE and the MAE\n",
    "mse = mean_squared_error(Y_test, y_test)\n",
    "print(\"MSE = {}\".format(mse))\n",
    "\n",
    "mae = mean_absolute_error(Y_test, y_test)\n",
    "print(\"MAE = {}\".format(mae))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_test, y_test, Y_fit_scaling=Y_train)\n",
    "# plt.savefig(\"output/error_output_histogram.pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Comparison with a Baseline Model\n",
    "\n",
    "To get an idea of how good these results are, let's compare with one of the methods that we already know – e.g. with XGBoost which was one of our best models for structured datasets. We will create and fit an `XGBRegressor` and then evaluate its performance on the test set just as we did with the GP regressor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor()\n",
    "xgb.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Testing -- { display-mode: \"form\" }\n",
    "y_test = xgb.predict(X_test)\n",
    "\n",
    "# we compute and display the MSE and the MAE\n",
    "mse = mean_squared_error(Y_test, y_test)\n",
    "print(\"MSE = {}\".format(mse))\n",
    "\n",
    "mae = mean_absolute_error(Y_test, y_test)\n",
    "print(\"MAE = {}\".format(mae))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_test, y_test, Y_fit_scaling=Y_train)\n",
    "# plt.savefig(\"output/error_output_histogram.pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "It seems that, in our case, the results with the GP regressor are rather better. However, we should not draw any general conclusions from this. For one thing, we did not do any hyperparameter tuning. For another thing, to really get a meaningful comparison of both methods we would need to evaluate them over a larger number of different datasets.\n",
    "\n",
    "In any case though, this indicates that the results we achieved using GP regression were not bad.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdá sa, že v našom prípade sú výsledky GP regresora o dosť lepšie. Z toho by sme však v tejto fáze nemali robiť všeobecné závery. Nerobili sme napokon ani žiadne ladenie hyperparametrov. Druhým dôvodom je, že na zmysluplné porovnanie by sme museli obe metódy hodnotiť nad väčším počtom dátových množín.\n",
    "\n",
    "V každom prípade však porovnanie indikuje, že výsledky, ktoré sme získali pomocou GP regresie neboli zlé.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
