{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**NOTE: This notebook is written for the Google Colab platform. However it can also be run (possibly with minor modifications) as a standard Jupyter notebook.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install git+https://github.com/michalgregor/class_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Downloading Data -- { display-mode: \"form\" }\n",
    "DATA_HOME = \"https://github.com/michalgregor/ml_notebooks/blob/main/data/{}?raw=1\"\n",
    "\n",
    "from class_utils.download import download_file_maybe_extract\n",
    "download_file_maybe_extract(DATA_HOME.format(\"images/photo_rome.jpg\"), directory=\"data\")\n",
    "\n",
    "# also create a directory for storing any outputs\n",
    "import os\n",
    "os.makedirs(\"output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Auxiliary Functions -- { display-mode: \"form\" }\n",
    "\n",
    "def plot_colors(colors, cluster_centers=None):\n",
    "    _, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(14, 6))\n",
    "    ax1.scatter(colors[:, 0], colors[:, 1], s=10, c=colors/255.0)\n",
    "\n",
    "    ax1.set_xlabel(\"red\")\n",
    "    ax1.set_ylabel(\"green\")\n",
    "    ax1.grid(ls='--')\n",
    "    ax1.set_axisbelow(True)\n",
    "\n",
    "    if not cluster_centers is None:\n",
    "        ax1.scatter(cluster_centers[:, 0], cluster_centers[:, 1], s=100,\n",
    "            c='orange', edgecolors='k', linewidths=2.5\n",
    "        )\n",
    "\n",
    "    ax2.scatter(colors[:, 0], colors[:, 2], s=10, c=colors/255.0)\n",
    "    ax2.set_xlabel(\"red\")\n",
    "    ax2.set_ylabel(\"blue\")\n",
    "    ax2.grid(ls='--')\n",
    "    ax2.set_axisbelow(True)\n",
    "\n",
    "    if not cluster_centers is None:\n",
    "        ax2.scatter(cluster_centers[:, 0], cluster_centers[:, 2], s=100,\n",
    "            c='orange', edgecolors='k', linewidths=2.5\n",
    "        )\n",
    "\n",
    "    ax3.scatter(colors[:, 1], colors[:, 2], s=10, c=colors/255.0)\n",
    "    ax3.set_xlabel(\"green\")\n",
    "    ax3.set_ylabel(\"blue\")\n",
    "    ax3.grid(ls='--')\n",
    "    ax3.set_axisbelow(True)\n",
    "\n",
    "    if not cluster_centers is None:\n",
    "        ax3.scatter(cluster_centers[:, 1], cluster_centers[:, 2], s=100,\n",
    "            c='orange', edgecolors='k', linewidths=2.5\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## k-Means for Colour Quantization\n",
    "\n",
    "In this example, we are going to apply $k$-means to something a little different. We are going to take an image and try to compress it by quantizing the colour space. By default, our image is going to be RGB. We are going to have three 8-bit numbers: one for each colour channel (reg, green, blue). This gives us 256 different levels for each colour channel, i.e. $256^3 = 16\\ 777\\ 216$ different colours.\n",
    "\n",
    "Let's say that we will instead store a small palette of colours along with the image and for each pixel just store the index of its colour in that palette. That way we can use one 8-bit number for each pixel in place of three. Naturally, the number does not even need to be an 8-bit one: it could be smaller or larger depending on how large our palette is.\n",
    "\n",
    "In any case, the principle is simple enough – the real question is how to find a good palette. We want to pick colours so that the compressed image is not distorted too much. What we are going to do, then, is take the pixels from our image and perform $k$-means clustering on them. This way we'll obtain a palette with $k$ colours that represent clusters in colour space.\n",
    "\n",
    "### Loading an Image\n",
    "\n",
    "Let's start by loading and displaying an image. As we'll be able to see, it mostly has green, purple, blue, brown and white colours.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(Image.open(\"data/photo_rome.jpg\"))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Reshaping the Image\n",
    "\n",
    "Now let's reshape our image into a matrix of points in the colour space, i.e. an $m \\times n$ matrix, where $m$ is the total number of pixels in the image and $n$ is the dimension of the colour space – in our case $n=3$ because our image in RGB.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = img.shape\n",
    "X = img.reshape(-1, img_shape[2])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Exploring the Colour Space\n",
    "\n",
    "Afterwards we can use `np.unique` to check how many uniques colours there are in the image – as it turns out, it's actually a lot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.unique(X, axis=0)\n",
    "len(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "To get a better visual understanding of what regions our image occupies in the colour space, we can plot the points in three planes: in the red vs. green plane, the red vs. blue plane and the green vs. blue plane. We colour each point by its actual RGB colour.\n",
    "\n",
    "As we can see, our colours do indeed cover just a relatively small sub-space of the colour space so some compression should be possible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "sel_colors = colors[np.random.randint(0, len(colors), size=2500)]\n",
    "plot_colors(sel_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Mini-Batch $k$-Means\n",
    "\n",
    "Next we are going to apply $k$-means. We are going to set the number of clusters to 32 – this means we'll looking for a 32-colour palette. The number of points we are working with is relatively large. For this reason we will be using the mini-batch version of $k$-means – this will make finding the cluster centres much faster.\n",
    "\n",
    "The idea behind mini-batch $k$-means is not to use all points in every step, but just draw a different sub-sample at every step and work with that. This way one can even apply $k$-means to data that does not fit into memory all at once. Note that virtually the same idea is used to train artificial neural networks on very large datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MiniBatchKMeans(n_clusters=32)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "Once we have fitted our model, we run the dataset through it and obtain the cluster identifiers – these determine which palette colour we are going to assign to each original pixel. We also retrieve the palette itself by copying cluster centres from the model and casting them back to 8-bit integers. With these two elements, our image is effectively quantized.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusts = model.predict(X)\n",
    "cluster_centers = model.cluster_centers_.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "To inspect the results, we are again going to plot the colours in the three different planes, now also displaying the points corresponding to our cluster centres.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_colors(sel_colors, cluster_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Reconstructing the Quantized Image\n",
    "\n",
    "Finally, let's reconstruct the image from our quantized version and see what the result looks like. The only thing we need to do is to walk through all the points again and read out their matching colours from the palette. Once we are done, we reshape the data back into the original image shape and we display the reconstructed image.\n",
    "\n",
    "As we can see, the colours are definitely less vibrant, but even with 32 colours the bulk of the image is preserved quite well. The most notable exception to this is the sky, which was formed by a gradient of colours, which has now been very visibly quantized.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_X = cluster_centers[clusts]\n",
    "quantized_img = quantized_X.reshape(img_shape)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.imshow(quantized_img)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "---\n",
    "### Task: Re-run with Different Palette Sizes\n",
    "\n",
    "**Run the algorithm again with different palette sizes, e.g. with 16 colours and with 64 colours. Plot the resulting reconstructions.** \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Quantizing with a Random Palette\n",
    "\n",
    "Now, just for the sake of comparison, let us attempt colour quantization with a randomly drawn palette. We are first going to pick a number of colours at random and then – for each pixel – find the nearest match in this new palette using `NearestNeighbors`. Finally, we again display the resulting reconstruction. As you are going to see, the result is far from ideal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "model = NearestNeighbors(n_neighbors=1)\n",
    "cluster_centers_ = np.random.uniform(0, 255, (32, 3))\n",
    "model.fit(cluster_centers_)\n",
    "\n",
    "clusts = model.kneighbors(X)[1]\n",
    "\n",
    "cluster_centers = cluster_centers_.astype(np.uint8)\n",
    "quantized_X = cluster_centers[clusts]\n",
    "quantized_img = quantized_X.reshape(img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(quantized_img)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "b08d363ebb8492a302c7076da18bf168d910622d9da13f07c6e53914cde27110"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
