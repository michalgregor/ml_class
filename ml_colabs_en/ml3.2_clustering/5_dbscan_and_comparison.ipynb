{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**NOTE: This notebook is written for the Google Colab platform. However it can also be run (possibly with minor modifications) as a standard Jupyter notebook.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import MiniBatchKMeans, DBSCAN, AgglomerativeClustering\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import display, HTML, SVG\n",
    "from IPython.utils.capture import capture_output\n",
    "from io import BytesIO\n",
    "\n",
    "# get matplotblib's default color cycle\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Downloading Data -- { display-mode: \"form\" }\n",
    "# also create a directory for storing any outputs\n",
    "import os\n",
    "os.makedirs(\"output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Auxiliary Functions -- { display-mode: \"form\" }\n",
    "\n",
    "def plot_clust(\n",
    "    X, clusts, is_core=None, iclust=None, legend=True, ax=None,\n",
    "    core_point_size=100, other_point_size=50, rasterized=False\n",
    "):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    if is_core is None:\n",
    "        is_core = np.full(len(X), False)\n",
    "\n",
    "    if iclust is None:\n",
    "        iclust = np.max(clusts)\n",
    "\n",
    "    index = clusts >= 0\n",
    "    regular = np.where(index)[0]\n",
    "    out_of_cluster = np.where(~index)[0]\n",
    "\n",
    "    c = [colors[i] for i in clusts[regular]]\n",
    "    s = [core_point_size if is_core[i] else other_point_size for i in regular]\n",
    "\n",
    "    ax.scatter(X[regular, 0], X[regular, 1], c=c, s=s, rasterized=rasterized)\n",
    "    ax.scatter(X[out_of_cluster, 0], X[out_of_cluster, 1], c='black',\n",
    "        s=other_point_size, rasterized=rasterized)\n",
    "\n",
    "    if legend:\n",
    "        legend_patches = [mpatches.Patch(color=colors[i], label='Cluster {}'.format(i)) for i in range(iclust+1)]\n",
    "        if len(out_of_cluster):\n",
    "            legend_patches.append(mpatches.Patch(color='black', label='Out of cluster'))\n",
    "        ax.legend(handles=legend_patches)\n",
    "\n",
    "    ax.grid(ls='--')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "\n",
    "class DBScanAnimation:\n",
    "    def __init__(\n",
    "        self, X, min_pts=5, eps=0.5,\n",
    "        fig=None, ax=None,\n",
    "        highlight_pt=True, pt_circle=True,\n",
    "        plot_callback=plot_clust,\n",
    "        core_point_size=100,\n",
    "        other_point_size=25,\n",
    "        keep_ax_lims=True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.X = X\n",
    "        self.min_pts = min_pts\n",
    "        self.eps = eps\n",
    "\n",
    "        self.highlight_pt = highlight_pt\n",
    "        self.pt_circle = pt_circle\n",
    "        self.core_point_size = core_point_size\n",
    "        self.other_point_size = other_point_size\n",
    "\n",
    "        self.keep_ax_lims = keep_ax_lims\n",
    "        self.plot_callback = plot_callback\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "        with capture_output() as io:\n",
    "            if fig is None:\n",
    "                self.fig = plt.figure()\n",
    "            else:\n",
    "                self.fig = fig\n",
    "\n",
    "            if ax is None:\n",
    "                self.ax = self.fig.gca()\n",
    "            else:\n",
    "                self.ax = ax\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "        self.iclust = None\n",
    "        self.is_core = None\n",
    "        self.clusts = None\n",
    "        self.clust_candidates = None\n",
    "        self.clust_set = None\n",
    "        self.cpt = None\n",
    "        self.D = None\n",
    "        self.lims = None\n",
    "\n",
    "    def plot_func(\n",
    "        self, cpt=None, cpt_size=None, cpt_color=None,\n",
    "        circle_color='red', ax=None\n",
    "    ):\n",
    "        if ax is None:\n",
    "            ax = self.ax\n",
    "\n",
    "        if cpt_size is None:\n",
    "            cpt_size = self.core_point_size\n",
    "\n",
    "        if cpt_color is None:\n",
    "            cpt_color = 'red'\n",
    "\n",
    "        ax.clear()\n",
    "        \n",
    "        self.plot_callback(\n",
    "            X=self.X, clusts=self.clusts, is_core=self.is_core,\n",
    "            iclust=self.iclust, ax=ax,\n",
    "            core_point_size=self.core_point_size,\n",
    "            other_point_size=self.other_point_size,\n",
    "            **self.kwargs\n",
    "        )\n",
    "        \n",
    "        if self.highlight_pt and not cpt is None:\n",
    "            ax.scatter(self.X[cpt, 0], self.X[cpt, 1], c=cpt_color, s=cpt_size)\n",
    "\n",
    "            if self.pt_circle:\n",
    "                circle = plt.Circle(\n",
    "                    (X[cpt, 0], X[cpt, 1]),\n",
    "                    self.eps, color=circle_color, fill=False, linewidth=3\n",
    "                )\n",
    "\n",
    "                ax.add_patch(circle)\n",
    "\n",
    "        if self.keep_ax_lims and not self.lims is None:\n",
    "            ax.set_xlim(self.lims[0])\n",
    "            ax.set_ylim(self.lims[1])\n",
    "\n",
    "    def __call__(self):\n",
    "        self.iclust = -1\n",
    "        self.clusts = np.full(len(self.X), -1)\n",
    "        self.is_core = np.full(len(self.X), False)\n",
    "        self.clust_candidates = set(range(len(self.X)))\n",
    "        self.D = squareform(pdist(X))\n",
    "        self.lims = None\n",
    "\n",
    "        self.plot_func()\n",
    "        self.lims = self.ax.get_xlim(), self.ax.get_ylim()\n",
    "        yield\n",
    "\n",
    "        self.iclust = 0\n",
    "\n",
    "        while len(self.clust_candidates):\n",
    "            self.cpt = self.clust_candidates.pop()\n",
    "            nbrs = np.where((self.D[self.cpt] < self.eps) & (self.clusts == -1))[0]\n",
    "\n",
    "            if len(nbrs) < self.min_pts:\n",
    "                continue\n",
    "            \n",
    "            self.is_core[self.cpt] = True\n",
    "            self.clusts[self.cpt] = self.iclust\n",
    "\n",
    "            self.clusts[nbrs] = self.iclust\n",
    "            self.clust_candidates.difference_update(nbrs)\n",
    "            self.clust_set = set(nbrs)\n",
    "\n",
    "            self.plot_func(self.cpt)\n",
    "            yield\n",
    "\n",
    "            while len(self.clust_set):\n",
    "                self.cpt = self.clust_set.pop()\n",
    "                self.clusts[self.cpt] = self.iclust\n",
    "\n",
    "                neighbours_index = self.D[self.cpt] < self.eps\n",
    "                not_in_clust_index = self.clusts == -1\n",
    "                in_same_clust_index = self.clusts == self.iclust\n",
    "\n",
    "                if (neighbours_index & (not_in_clust_index | in_same_clust_index)).sum() < self.min_pts:\n",
    "                    continue\n",
    "\n",
    "                nbrs = np.where(neighbours_index & not_in_clust_index)[0]\n",
    "\n",
    "                self.is_core[self.cpt] = True\n",
    "                self.clusts[nbrs] = self.iclust\n",
    "                self.clust_candidates.difference_update(nbrs)    \n",
    "                self.clust_set.update(nbrs)\n",
    "\n",
    "                if len(nbrs):\n",
    "                    self.plot_func(self.cpt)\n",
    "                    yield\n",
    "\n",
    "            self.iclust += 1\n",
    "\n",
    "        self.iclust -= 1\n",
    "        self.plot_func()\n",
    "        yield\n",
    "\n",
    "        return self.clusts, self.is_core\n",
    "\n",
    "    def save_images(self, image_filename_tpl=\"output/dbscan_{step}.svg\"):\n",
    "        for istep, _ in enumerate(self()):\n",
    "            self.fig.savefig(\n",
    "                image_filename_tpl.format(step=istep),\n",
    "                bbox_inches='tight'\n",
    "            )\n",
    "            \n",
    "    def grab_frame(self, format='svg'):\n",
    "        file = BytesIO()\n",
    "        dbscan_ani.fig.savefig(fname=file, format=format)\n",
    "        file.seek(0)\n",
    "        image_str = file.read()\n",
    "        return image_str\n",
    "            \n",
    "    def make_all_frames(self, format='svg'):\n",
    "        gen = self()\n",
    "        return [self.grab_frame(format=format) for _ in gen]\n",
    "\n",
    "    def make_animation(self, interval=500):\n",
    "        ani = FuncAnimation(\n",
    "            self.fig, lambda x: [], frames=self,\n",
    "            interval=interval, repeat=False\n",
    "        )\n",
    "        \n",
    "        return ani\n",
    "\n",
    "    def animate(self, interval=500):\n",
    "        ani = self.make_animation(interval=interval)\n",
    "        return self.show_animation(ani)\n",
    "    \n",
    "    def show_animation(self, ani):\n",
    "        html = HTML(ani.to_jshtml())\n",
    "        return html\n",
    "    \n",
    "# algos and hyperparams for the comparison of methods\n",
    "algos = [\n",
    "    ('kmeans', MiniBatchKMeans),\n",
    "    ('hierarchical, ward', AgglomerativeClustering),\n",
    "    ('hierarchical, single', AgglomerativeClustering),\n",
    "    ('DBSCAN', DBSCAN)\n",
    "]\n",
    "\n",
    "hyperparams = defaultdict(dict)\n",
    "hyperparams['kmeans']['circles'] = {'n_clusters': 2}\n",
    "hyperparams['kmeans']['moons'] = {'n_clusters': 2}\n",
    "hyperparams['kmeans']['blobs'] = {'n_clusters': 3}\n",
    "hyperparams['kmeans']['varied_blobs'] = {'n_clusters': 3}\n",
    "\n",
    "hyperparams['hierarchical, ward']['circles'] = {'n_clusters': 2, 'linkage': 'ward'}\n",
    "hyperparams['hierarchical, ward']['moons'] = {'n_clusters': 2, 'linkage': 'ward'}\n",
    "hyperparams['hierarchical, ward']['blobs'] = {'n_clusters': 3, 'linkage': 'ward'}\n",
    "hyperparams['hierarchical, ward']['varied_blobs'] = {'distance_threshold': 75, 'n_clusters': None, 'linkage': 'ward'}\n",
    "\n",
    "hyperparams['hierarchical, single']['circles'] = {'n_clusters': 2, 'linkage': 'single'}\n",
    "hyperparams['hierarchical, single']['moons'] = {'n_clusters': 2, 'linkage': 'single'}\n",
    "hyperparams['hierarchical, single']['blobs'] = {'n_clusters': 3, 'linkage': 'single'}\n",
    "hyperparams['hierarchical, single']['varied_blobs'] = {'distance_threshold': 1.55, 'n_clusters': None, 'linkage': 'single'}\n",
    "\n",
    "hyperparams['DBSCAN']['circles'] = {'eps': 0.15, 'min_samples': 5}\n",
    "hyperparams['DBSCAN']['moons'] = {'eps': 0.18, 'min_samples': 5}\n",
    "hyperparams['DBSCAN']['blobs'] = {'eps': 1.5, 'min_samples': 5}\n",
    "hyperparams['DBSCAN']['varied_blobs'] = {'eps': 5.0, 'min_samples': 5}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## DBSCAN: Density-Based Clustering\n",
    "\n",
    "DBSCAN [[dbscan1996]](#dbscan1996) is a well-known clustering method based on density. Unlike in $k$-means / hierachical clustering, you do not need to specify the number of clusters (explicitly or implicitly by specifying where to cut the dendrogram). The idea is as follows:\n",
    "\n",
    "* If a point has at least $\\textrm{min\\_pts}$ neighbours at distances $\\leq \\epsilon$, it is a **core point**  of a cluster;\n",
    "\n",
    "\n",
    "* Any other points within the distance of $\\leq \\epsilon$ are connected to it and also belong into the same cluster;\n",
    "\n",
    "\n",
    "* If these connected points are:\n",
    "\n",
    "\n",
    "* *Also core points* , then same applies to any points within the distance $\\leq \\epsilon$ from them, etc.;\n",
    "\n",
    "\n",
    "* *Not core points* , then they are called **border points**  and no other points can connect to the cluster through them.\n",
    "\n",
    "\n",
    "\n",
    "Using these principles, DBSCAN discovers clusters. Once DBSCAN is done, some isolated points, which are not connected to any cluster, might remain. These are simply marked as **out-of-cluster points**  – they are too far from any cluster to be counted among its points.\n",
    "\n",
    "### A Demonstration\n",
    "\n",
    "Now that we know about the basic principles, let us have a simple demonstration. We are going to create a synthetic dataset with three ball-shaped clusters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = datasets.make_blobs(\n",
    "    n_samples=75,\n",
    "    centers=[(1, 3), (3, 5), (5, 2)],\n",
    "    cluster_std=0.4,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c='black')\n",
    "plt.grid(ls='--')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "Now we are going to go through what DBSCAN does step by step (using our custom class: `DBScanAnimation`). At the beginning, there will be no clusters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_ani = DBScanAnimation(X=X, eps=0.5, min_pts=5)\n",
    "frames = dbscan_ani.make_all_frames()\n",
    "display(SVG(frames[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "Then in the first step, we are going to pick points at random (or rather in an arbitrary order – we can pick them systematically if we like) until we arrive at one that is a core point (it has at least $\\textrm{min\\_pts}$ neighbours at distances $\\leq \\epsilon$). The figure highlighs one such point in red along with its $\\epsilon$-neighbourhood.\n",
    "\n",
    "This point is used to start the first cluster. The cluster will initially contain the core point and its $\\epsilon$-neigbourhood (the points are colour-coded as cluster 0 in the figure).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(SVG(frames[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "As the next step we go through all these points, determine which of them are core points (we assign larger circles to those in the plot) and also add their $\\epsilon$-neighbours into the cluster, etc. Points that belong into the cluster and they are not core points, are called border points. These still belong into the cluster, but further points cannot connect to the cluster through them.\n",
    "\n",
    "Let's show the first few steps of the process here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(SVG(frames[2]))\n",
    "display(SVG(frames[3]))\n",
    "\n",
    "display(HTML(\"<center><strong>⋮</strong></center>\"))\n",
    "\n",
    "display(SVG(frames[7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "Once we have exhausted all points connected to the first cluster, we go on with the remaining out-of-cluster points, trying to idenfity a further core point that we could use to start the next cluster. After that, we just keep going on analogically.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(SVG(frames[8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "Eventually we will have gone through all available points. It may happen that at that step some points will still be **out of cluster** . This is fine – it means that they do not meet the criteria to belong into a cluster. In practical applications it is often going to be useful to be able to identify such points.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(SVG(frames[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "Finally, let's check one of the border points. We should see that while it is in the $\\epsilon$-neighbourhood of a core point, it does not have enough points in its own $\\epsilon$-neighbourhood to be itself a core point.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "boundary_point = np.where(dbscan_ani.clusts != -1 & ~dbscan_ani.is_core)[0][0]\n",
    "dbscan_ani.plot_func(cpt=boundary_point, ax=ax, cpt_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "Finally, we can generate an animated version of the entire procedure so that you can go through all the steps at will.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_ani = DBScanAnimation(X=X, eps=0.5, min_pts=5)\n",
    "dbscan_ani.animate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### DBSCAN in Scikit-Learn\n",
    "\n",
    "Now that we understand the basics of how DBSCAN works, let us see how it can be applied in practice using `scikit-learn`. There are no surprises – DBSCAN uses the standard `scikit-learn` interface. The \"cluster number\" of out-of-cluster points is `-1`. The numbering of the regular clusters starts from 0.\n",
    "\n",
    "Note that in general, it will be a good idea to **standardize the data**  before applying DBSCAN (just as we did with other clustering methods). We only omit standardization here because these are purely illustrative examples and the data does not really require standardization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DBSCAN(eps=0.5, min_samples=5)\n",
    "clusts = model.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clust(X=X, clusts=clusts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Clustering Methods: A Comparison\n",
    "\n",
    "Finally, we are going to include a small comparison of $k$-means, hierarchical clustering (with ward and single linkage) and DBSCAN. We are going to be using several toy datasets to better showcase what kinds of clusters each method is going to be able to discover. Let's first generate the data and plot it: we are going to use data from an [example in scikit-learn's documentation](https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Data generation code -- { display-mode: \"form\" }\n",
    "n_samples = 1500\n",
    "circles, _ = datasets.make_circles(n_samples=n_samples, factor=0.5, noise=0.05, random_state=0)\n",
    "moons, _ = datasets.make_moons(n_samples=n_samples, noise=0.05, random_state=0)\n",
    "blobs, _ = datasets.make_blobs(n_samples=n_samples, random_state=8)\n",
    "varied_blobs, _ = datasets.make_blobs(n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5], random_state=170)\n",
    "\n",
    "data = [\n",
    "    ('circles', circles),\n",
    "    ('moons', moons),\n",
    "    ('blobs', blobs),\n",
    "    ('varied_blobs', varied_blobs)\n",
    "]\n",
    "\n",
    "# plotting\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(8, 8))\n",
    "\n",
    "axes[0, 0].scatter(circles[:, 0], circles[:, 1])\n",
    "axes[0, 0].set_title('circles')\n",
    "axes[0, 0].grid(ls='--')\n",
    "axes[0, 0].set_ylabel('y')\n",
    "\n",
    "axes[0, 1].scatter(moons[:, 0], moons[:, 1])\n",
    "axes[0, 1].set_title('moons')\n",
    "axes[0, 1].grid(ls='--')\n",
    "\n",
    "axes[1, 0].scatter(blobs[:, 0], blobs[:, 1])\n",
    "axes[1, 0].set_title('blobs')\n",
    "axes[1, 0].grid(ls='--')\n",
    "axes[1, 0].set_xlabel('x')\n",
    "axes[1, 0].set_ylabel('y')\n",
    "\n",
    "axes[1, 1].scatter(varied_blobs[:, 0], varied_blobs[:, 1])\n",
    "axes[1, 1].set_title('varied blobs')\n",
    "axes[1, 1].grid(ls='--')\n",
    "axes[1, 1].set_xlabel('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "Now we are going to apply each of the clustering methods to each dataset (with slightly different hyperparameters for each – but let's not worry about that here) and display the results in a plot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Clustering code -- { display-mode: \"form\" }\n",
    "fig, axes = plt.subplots(len(data), len(algos))\n",
    "fig.set_size_inches(10, 8)\n",
    "\n",
    "for jax in range(axes.shape[1]):\n",
    "    axes[0][jax].set_title(algos[jax][0])\n",
    "\n",
    "for iax in range(axes.shape[0]):\n",
    "    for jax in range(axes.shape[1]):\n",
    "        ax = axes[iax][jax]\n",
    "        X = data[iax][1]\n",
    "        alg = algos[jax][1]\n",
    "        params = hyperparams[algos[jax][0]][data[iax][0]]\n",
    "        \n",
    "        model = alg(**params)\n",
    "        clusts = model.fit_predict(X)\n",
    "        plot_clust(X=X, clusts=clusts, ax=ax, legend=False,\n",
    "            other_point_size=5, rasterized=True)\n",
    "        \n",
    "        if jax > 0:\n",
    "            ax.set_ylabel('')\n",
    "            \n",
    "        if iax < axes.shape[0] - 1:\n",
    "            ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### $k$-means\n",
    "\n",
    "One thing we will be able to see immediately is that $k$-means will only really be able to deal correctly with ball-shaped clusters – this is why it is only really going to work well with the blobs dataset.\n",
    "\n",
    "#### Hierarchical Clustering\n",
    "\n",
    "With hierarchical clustering, we can change the linkage method (how distances between clusters are determined). Note that ward linkage (and other linkages such as average or complete) do not work well with circles and moons. Single linkage is looking at the smallest distance between clusters so it is more locally oriented and works well in those cases. However, it does not really work well in the case of variable-density blobs.\n",
    "\n",
    "#### DBSCAN\n",
    "\n",
    "Similarly, DBSCAN works great for blobs, circles and moons, but – being density-based – **it cannot handle clusters with significantly different densities – there is no good value for $\\epsilon$ because it will either be too small for one cluster or too large for another.** \n",
    "\n",
    "To make the problem clearer, let's run DBSCAN on the varied blobs dataset again with two different values of $\\epsilon$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n",
    "\n",
    "model = DBSCAN(eps=5, min_samples=5)\n",
    "clusts = model.fit_predict(varied_blobs)\n",
    "plot_clust(X=varied_blobs, clusts=clusts, ax=axes[0],\n",
    "    legend=False, other_point_size=10, rasterized=True)\n",
    "\n",
    "model = DBSCAN(eps=0.5, min_samples=5)\n",
    "clusts = model.fit_predict(varied_blobs)\n",
    "plot_clust(X=varied_blobs, clusts=clusts, ax=axes[1],\n",
    "    legend=False, other_point_size=10, rasterized=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "<a id=\"dbscan1996\">[dbscan1996]</a> Ester, M., Kriegel, H.P., Sander, J. and Xu, X., 1996, August. A density-based algorithm for discovering clusters in large spatial databases with noise. In kdd (Vol. 96, No. 34, pp. 226-231).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a351393365bb1b108989afa08de3243f72f5e58927baf5d192f3cca79a41cbc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
