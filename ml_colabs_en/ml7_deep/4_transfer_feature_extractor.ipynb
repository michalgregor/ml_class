{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dkj4rzVsmjut",
    "tags": [
     "en"
    ]
   },
   "source": [
    "**NOTE: This notebook is written for the Google Colab platform, which provides free hardware acceleration. However it can also be run (possibly with minor modifications) as a standard Jupyter notebook, using a local GPU.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install torchinfo\n",
    "!{sys.executable} -m pip install git+https://github.com/michalgregor/class_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y7-4YhzosUs8"
   },
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from class_utils.pytorch_utils import BestModelCheckpointer, freeze_except_last\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchinfo\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "uxPlOyi3sUo_",
    "outputId": "0c8b07dc-86a0-4c7e-e27e-8ee3eb135dff"
   },
   "outputs": [],
   "source": [
    "#@title -- Downloading Data -- { display-mode: \"form\" }\n",
    "from class_utils.download import download_file_maybe_extract\n",
    "download_file_maybe_extract(\"https://www.dropbox.com/s/w4pg809npvatye0/food5v2.zip?dl=1\", directory=\"data/food5v2\")\n",
    "\n",
    "# also create a directory for storing any outputs\n",
    "import os\n",
    "os.makedirs(\"output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bm8Dnrk5OC-l",
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Transfer Learning: Using the Pre-trained Network as a Feature Extractor\n",
    "\n",
    "In a previous notebook we have explored the standard approach to transfer learning with frozen weights, training a new final layer and then fine-tuning. However, there is another alternative, where the pretrained network is used as a feature extractor. Under that approach, you would first strip off the network's classification layer so that the network returns the feature vector from the penultimate layer rather than the logits from the final layer. Then you would run over your entire dataset with it and preprocess it. This will make your dataset much, much smaller – unless it was super large to begin with, it should even fit in your memory all at once.\n",
    "\n",
    "You can then use the preprocessed data and train just your new layers – the training will go much faster, because you will not be loading the images and running them through your large network again and again. One downside is, of course, that you will not be able to use data augmentation techniques – but that might not be too high a price to pay.\n",
    "\n",
    "### Setting up the Data Loaders\n",
    "\n",
    "Since we are not going to be using data augmentation, we can just use the default image transforms provided with the pretrained weights directly. Other than that, the datasets and data loaders will be constructed the same way we constructed them in the previous example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "image_transforms = weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DEMPcRIits1V"
   },
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(\n",
    "    \"data/food5v2/training\",\n",
    "    image_transforms\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "valid_dataset = ImageFolder(\n",
    "    \"data/food5v2/validation\",\n",
    "    image_transforms\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_dataset = ImageFolder(\n",
    "    \"data/food5v2/testing\",\n",
    "    image_transforms\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2aLHWrpgOJOz",
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Loading the Pre-Trained Network\n",
    "\n",
    "Next, we are going to load our pretrained ResNet50. To strip away the final layer (`.fc`), we are going to replace it with an empty `nn.Sequential` module.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_net = models.resnet50(weights=weights).to(device)\n",
    "pretrained_net.fc = nn.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2aLHWrpgOJOz",
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Preprocessing the Data\n",
    "\n",
    "It's quite easy to use the network to preprocess the data. We'll just iterate over the data loader for each fold (train, valid, test) and collect the desired outputs and the preprocessed inputs into two tensors. Then we are going to set up a `TensorDataset` object and another corresponding data loader for each fold.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(feature_extractor, data_loader):\n",
    "    feature_extractor.eval()\n",
    "    X = []; Y = []\n",
    "\n",
    "    for X_batch, Y_batch in data_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            X_batch = feature_extractor(X_batch)\n",
    "\n",
    "        X.extend(X_batch.cpu())\n",
    "        Y.extend(Y_batch.cpu())\n",
    "  \n",
    "    return torch.stack(X), torch.stack(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = extract_features(pretrained_net, train_dataloader)\n",
    "X_valid, Y_valid = extract_features(pretrained_net, valid_dataloader)\n",
    "X_test, Y_test = extract_features(pretrained_net, test_dataloader)\n",
    "\n",
    "train_tensor_dataset = TensorDataset(X_train, Y_train)\n",
    "train_tensor_dataloader = DataLoader(train_tensor_dataset, batch_size=32, shuffle=True)\n",
    "valid_tensor_dataset = TensorDataset(X_valid, Y_valid)\n",
    "valid_tensor_dataloader = DataLoader(valid_tensor_dataset, batch_size=32, shuffle=True)\n",
    "test_tensor_dataset = TensorDataset(X_test, Y_test)\n",
    "test_tensor_dataloader = DataLoader(test_tensor_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2aLHWrpgOJOz",
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Training New Layers\n",
    "\n",
    "The new top of our network will look the same as it did in the previous example. The training loop will also be quite standard – except we'll now be using our `train_tensor_dataloader` and we'll be training our top separately, i.e. it will not be attached to the pretrained network. Since training is going to be much faster now, we can afford to increase the number of epochs as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTop(nn.Module):\n",
    "    def __init__(self, num_features, num_outputs):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(num_features, num_outputs)\n",
    "\n",
    "    def set_dropout(self, p):\n",
    "        self.dropout.p = p\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = torch.flatten(x, 1)\n",
    "        y = self.dropout(y)\n",
    "        y = self.fc(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelTop(X_train.shape[1], 10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "checkpointer = BestModelCheckpointer(checkpoint_path=\"output/best_model.pt\")\n",
    "loss_train = []\n",
    "loss_valid = []\n",
    "\n",
    "for epoch in range(200):\n",
    "    epoch_train_loss = []\n",
    "    epoch_valid_loss = []\n",
    "\n",
    "    model.train()\n",
    "    for X_batch, Y_batch in train_tensor_dataloader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        Y_batch = Y_batch.to(device)\n",
    "        \n",
    "        y_batch = model(X_batch)\n",
    "        loss = criterion(y_batch, Y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss.append(loss.item())\n",
    "\n",
    "    loss_train.append(np.mean(epoch_train_loss))\n",
    "\n",
    "    model.eval()\n",
    "    for X_batch, Y_batch in valid_tensor_dataloader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        Y_batch = Y_batch.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_batch = model(X_batch)\n",
    "            loss = criterion(y_batch, Y_batch)\n",
    "\n",
    "        epoch_valid_loss.append(loss.item())\n",
    "\n",
    "    loss_valid.append(np.mean(epoch_valid_loss))\n",
    "    checkpointer(loss_valid[-1], model)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"epoch {epoch}, train loss: {np.mean(loss_train[-5:])}, valid loss: {np.mean(loss_valid[-5:])}\")\n",
    "\n",
    "print(f\"epoch {epoch}, loss: {loss_train[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_train, label=\"train\")\n",
    "plt.plot(loss_valid, label=\"valid\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.grid(ls='--')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2aLHWrpgOJOz",
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "Once training is done, we can load back the weights with the best validation loss and evaluate the model on the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"output/best_model.pt\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_Y = []\n",
    "eval_y = []\n",
    "\n",
    "model.eval()\n",
    "for X_batch, Y_batch in test_tensor_dataloader:\n",
    "    eval_Y.extend(Y_batch.numpy())\n",
    "    X_batch = X_batch.to(device)\n",
    "    Y_batch = Y_batch.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_batch = model(X_batch)\n",
    "\n",
    "    eval_y.extend(y_batch.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "eval_Y = np.array(eval_Y)\n",
    "eval_y = np.array(eval_y)\n",
    "\n",
    "cm = pd.crosstab(\n",
    "    eval_Y, eval_y,\n",
    "    rownames=['actual'],\n",
    "    colnames=['predicted']\n",
    ")\n",
    "print(cm, '\\n')\n",
    "\n",
    "acc = accuracy_score(eval_Y, eval_y)\n",
    "print(\"Accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2aLHWrpgOJOz",
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Putting the Model Back Together\n",
    "\n",
    "Finally, we can put the model back together so that we are able to run it on the original data. This is very simple – we'll only need to assign our `model` to `pretrained_net.fc`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_net.fc = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_Y = []\n",
    "eval_y = []\n",
    "\n",
    "pretrained_net.eval()\n",
    "for X_batch, Y_batch in test_dataloader:\n",
    "    eval_Y.extend(Y_batch.numpy())\n",
    "    X_batch = X_batch.to(device)\n",
    "    Y_batch = Y_batch.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_batch = pretrained_net(X_batch)\n",
    "\n",
    "    eval_y.extend(y_batch.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "eval_Y = np.array(eval_Y)\n",
    "eval_y = np.array(eval_y)\n",
    "\n",
    "cm = pd.crosstab(\n",
    "    eval_Y, eval_y,\n",
    "    rownames=['actual'],\n",
    "    colnames=['predicted']\n",
    ")\n",
    "print(cm, '\\n')\n",
    "\n",
    "acc = accuracy_score(eval_Y, eval_y)\n",
    "print(\"Accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "7_transfer_learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "172ff158eadb4cd6bb7d13eb0b99bcf3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3db5a994401949858a1507e673cc87c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5a1034ec61384e90a57f3ca9f57e4bb6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80e98bc88f374275bedb82737935ab4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c8f6ae12235d4dfa864de5114a6e2bf5",
       "IPY_MODEL_f5e66d097cd94fcd92c0167d0baac031"
      ],
      "layout": "IPY_MODEL_5a1034ec61384e90a57f3ca9f57e4bb6"
     }
    },
    "c8f6ae12235d4dfa864de5114a6e2bf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6995b2241ae46cca768574f8cccf2d6",
      "max": 102502400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d6e67658bddb41a1b6e1261a63603158",
      "value": 102502400
     }
    },
    "d6995b2241ae46cca768574f8cccf2d6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6e67658bddb41a1b6e1261a63603158": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f5e66d097cd94fcd92c0167d0baac031": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_172ff158eadb4cd6bb7d13eb0b99bcf3",
      "placeholder": "​",
      "style": "IPY_MODEL_3db5a994401949858a1507e673cc87c9",
      "value": " 97.8M/97.8M [00:40&lt;00:00, 2.53MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
