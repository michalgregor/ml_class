{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OpDXNUfuhJ41",
    "tags": [
     "en"
    ]
   },
   "source": [
    "**NOTE: This notebook is written for the Google Colab platform. However it can also be run (possibly with minor modifications) as a standard Jupyter notebook.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uIGqXiLohJ5l",
    "outputId": "fcdbd92e-f9bb-4ea2-b0f8-775cf28c9b48"
   },
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install git+https://github.com/michalgregor/class_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5u1mk6jGhJ6q"
   },
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "bApCnClBhJ7U",
    "outputId": "e4afd628-3d72-4ce7-e974-be774e02b9c8"
   },
   "outputs": [],
   "source": [
    "#@title -- Downloading Data -- { display-mode: \"form\" }\n",
    "from class_utils.download import download_file_maybe_extract\n",
    "download_file_maybe_extract(\"https://www.dropbox.com/s/a5ux951zo01gd5z/cat.jpg?dl=1\", directory=\"data\")\n",
    "download_file_maybe_extract(\"https://www.dropbox.com/s/ma25i7w3jpqex2a/imagenet_classes?dl=1\", directory=\"data\")\n",
    "\n",
    "# also create a directory for storing any outputs\n",
    "import os\n",
    "os.makedirs(\"output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y4eIWvyhhJ75"
   },
   "outputs": [],
   "source": [
    "#@title -- Auxiliary Functions -- { display-mode: \"form\" }\n",
    "with open(\"data/imagenet_classes\", \"r\") as file:\n",
    "    classes = [c[:-1] for c in file.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HKASxihFM7Rq",
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Using a Pre-trained Classifier\n",
    "\n",
    "This notebook will show a very simple example of loading and using a classifier pre-trained on ImageNet. We will show how it can be used to classify new images.\n",
    "\n",
    "### Loading the Model\n",
    "\n",
    "In the previous examples we have defined a class for our own neural net and specified its architecture. Now we will instead use one of the predefined models with pretrained weights. These models are available in the `torchvision.models` package. We will use architecture `resnet50` in particular and when instantiating it, we'll specify which version of pretrained weights we want to use – in our case it will be the first version of weights trained on the ImageNet dataset. When calling this piece of code for the first time, the weights will first need to be downloaded over the internet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "88b3843c07734c88a4a1027c35470d6e",
      "4198b9d9ef2a4f088d4158db402a0344",
      "c1a088c890cf418cbbf1d72c3a7ba946",
      "1e14b124cb044861a43c21b7cc69174d",
      "d586edc61e8941ae8fa3762691476d5a",
      "56a2306ec26842e598b37f3e8b86f8e5",
      "e12efbd23f6f4c39a15787caf6bb8970",
      "96a334f228eb45fe898d3dbd2fad9649"
     ]
    },
    "colab_type": "code",
    "id": "g-U4h6xshJ8b",
    "outputId": "e7e253e4-1866-4983-e09e-f225a025433f"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = models.resnet50(weights='ResNet50_Weights.IMAGENET1K_V1').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HKASxihFM7Rq",
    "tags": [
     "en"
    ]
   },
   "source": [
    "A further thing we can get from `torchvision.models` for our architecture is the correct way to preprocess the input data – most of these vision models use some specific normalization, resize the image to some standard size, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = models.ResNet50_Weights.IMAGENET1K_V1.transforms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rZ-dVy7pM7SP",
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Using the Model\n",
    "\n",
    "We load and preprocess the image that we want to classify.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "Mq0YGlmqhJ9E",
    "outputId": "fac53330-78c9-45cd-979b-070c1a769249"
   },
   "outputs": [],
   "source": [
    "img = Image.open(\"data/cat.jpg\").convert(\"RGB\")\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2x8ifLZsM7Sf",
    "tags": [
     "en"
    ]
   },
   "source": [
    "Before plugging the image into the network we are going to apply preprocessing using `image_transforms`. We will also call `.unsqueeze(0)` on the result. This is because while we are working with a single image, the network expects a batch of images. By calling `.unsqueeze(0)` we add the batch dimension (with size 1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "gZgEBt8DhJ9V",
    "outputId": "66a00601-47aa-4377-dda4-c7a92a7f7ffb"
   },
   "outputs": [],
   "source": [
    "img_prep = image_transforms(img).unsqueeze(0)\n",
    "img_prep = img_prep.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_logit = model(img_prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4h3i3IjiM7Sv",
    "tags": [
     "en"
    ]
   },
   "source": [
    "The network will return the logits corresponding to all the ImageNet classes. As you'll recall, to get the index of the most probable class, we can `argmax`. In our case, we are storing class labels in the `classes` list (it was read from a file in the auxiliary code section), so we only need to index it using the class predicted by our network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "MaVRWVu4hJ9l",
    "outputId": "8d231148-c672-4e40-a9ae-79eb475fb8fb"
   },
   "outputs": [],
   "source": [
    "y = y_logit.argmax(dim=1)\n",
    "classes[y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mu-AO6xuM7S9",
    "tags": [
     "en"
    ]
   },
   "source": [
    "Given that our network can actually predict class probabilities (we can get them by passing the logits through a softmax layer), we might want to known about those and not just about the label of the most probable class. In fact, let's display the top-5 predictions and their probabilities. This will give us a better idea of how confident the neural network is about its prediction and whether the other, less probable predictions make any sense or not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_proba(proba, top=5):\n",
    "    proba = proba.ravel().detach().cpu()\n",
    "    ind = proba.argsort(descending=True)\n",
    "    \n",
    "    for c in ind[:top]:\n",
    "        print(\"{}:\\t{} ({})\".format(\n",
    "            np.array2string(proba[c], precision=5),\n",
    "            classes[c], c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = y_logit.softmax(dim=1)\n",
    "decode_proba(y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vlA1JLRFM7Tg",
    "tags": [
     "en"
    ]
   },
   "source": [
    "---\n",
    "### Task 1: Predictions about Other Images\n",
    "\n",
    "**Try to apply the same procedure to a different image.** \n",
    "\n",
    "Note: New images can be uploaded **directly through the notebook interface**  or else using:\n",
    "\n",
    "```\n",
    "from google.colab import files\n",
    "content_img = files.upload()\n",
    "filename = list(content_img)[0]\n",
    "```\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dJTJWW68hJ_v",
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# -----\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j5QLavr5M7T6",
    "tags": [
     "en"
    ]
   },
   "source": [
    "The list of classes that the network is supposed to be able to classify can be found in file `data/imagenet_classes`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "43lL_W0RhKAB",
    "outputId": "4b019816-ac3d-4bc2-cb0a-3556804b061b"
   },
   "outputs": [],
   "source": [
    "for ic, c in enumerate(classes):\n",
    "    print(\"{}:\\t{}\".format(ic, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XRImKJeYM7UG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "5_imagenet_pretrained.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a351393365bb1b108989afa08de3243f72f5e58927baf5d192f3cca79a41cbc4"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1e14b124cb044861a43c21b7cc69174d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96a334f228eb45fe898d3dbd2fad9649",
      "placeholder": "​",
      "style": "IPY_MODEL_e12efbd23f6f4c39a15787caf6bb8970",
      "value": " 54.7M/54.7M [00:01&lt;00:00, 44.8MB/s]"
     }
    },
    "4198b9d9ef2a4f088d4158db402a0344": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56a2306ec26842e598b37f3e8b86f8e5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88b3843c07734c88a4a1027c35470d6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c1a088c890cf418cbbf1d72c3a7ba946",
       "IPY_MODEL_1e14b124cb044861a43c21b7cc69174d"
      ],
      "layout": "IPY_MODEL_4198b9d9ef2a4f088d4158db402a0344"
     }
    },
    "96a334f228eb45fe898d3dbd2fad9649": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1a088c890cf418cbbf1d72c3a7ba946": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56a2306ec26842e598b37f3e8b86f8e5",
      "max": 57365526,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d586edc61e8941ae8fa3762691476d5a",
      "value": 57365526
     }
    },
    "d586edc61e8941ae8fa3762691476d5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e12efbd23f6f4c39a15787caf6bb8970": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
