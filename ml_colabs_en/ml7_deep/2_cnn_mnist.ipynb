{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gbvd2Q1MnLGG",
    "tags": [
     "en"
    ]
   },
   "source": [
    "**NOTE: This notebook is written for the Google Colab platform, which provides free hardware acceleration. However it can also be run (possibly with minor modifications) as a standard Jupyter notebook, using a local GPU.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "z2-NXRAuFhl6",
    "outputId": "4b07b0c2-f612-4a78-a9c4-99d5257f0d68"
   },
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uNN3tkqMnLG5",
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Classifying MNIST Digits\n",
    "\n",
    "This example will illustrate how to construct a simple convolutional network for image classification on the MNIST handwritten digits dataset.\n",
    "\n",
    "### Loading the Dataset\n",
    "\n",
    "We are going to start by loading the MNIST dataset. This step will be very simple, because the `datasets` package from HugginFace includes a built-in function, which does so. We merely call the `load_dataset` function, specifying `\"mnist\"` as the dataset. We will get a dataset that is already split into the train and test folds – you can retrieve them using `dataset['train']` and `dataset['test']`.\n",
    "\n",
    "Each fold contain two lists `'image'` and `'label'`; `'image'` is a list of `PIL` images, which can be cast to numpy arrays using `np.asarray`. Under `'label'`, you will find class labels (the desired outputs).\n",
    "\n",
    "When loading the data, we need to make sure that the tensors are properly scaled and of the correct shape. Our data is composed of $28 \\times 28$ images with a single colour channel. In `PyTorch` colour channels are represented by the 1st dimension of the tensor (with the 0th dimension being the batch dimension). Our tensor's shape is `(batch, 28, 28)` and we need it to be `(batch, 1, 28, 28)` so we call `.unsqueeze(1)`.\n",
    "\n",
    "Finally, the values ranges from 0 to 255 – we are going to scale this into the range of 0 to 1, i.e. divide by 255.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LoaaEB3NxvQx"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dataset = load_dataset(\"mnist\")\n",
    "\n",
    "X_train_np = np.asarray([np.asarray(img) for img in dataset['train']['image']])\n",
    "Y_train_np = np.asarray(dataset['train']['label'])\n",
    "X_test_np = np.asarray([np.asarray(img) for img in dataset['test']['image']])\n",
    "Y_test_np = np.asarray(dataset['test']['label'])\n",
    "\n",
    "X_train = torch.as_tensor(X_train_np).to(device)\n",
    "Y_train = torch.as_tensor(Y_train_np).to(device)\n",
    "X_test = torch.as_tensor(X_test_np).to(device)\n",
    "Y_test = torch.as_tensor(Y_test_np).to(device)\n",
    "\n",
    "X_train = X_train.unsqueeze(1) / 255.0\n",
    "X_test = X_test.unsqueeze(1) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "txWaLDB_nLHh",
    "tags": [
     "en"
    ]
   },
   "source": [
    "We can now display a few randomly selected examples from the train set:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "0ZmVUulDGXH-",
    "outputId": "e9c879a0-4082-43d5-caa8-9f8cabf84120"
   },
   "outputs": [],
   "source": [
    "num_rows = 4; num_cols = 4\n",
    "fig, axes = plt.subplots(num_rows, num_cols)\n",
    "\n",
    "for row in axes:\n",
    "    for ax in row:\n",
    "        ax.imshow(X_train_np[np.random.randint(0,\n",
    "                    len(X_train_np)-1)],\n",
    "                  cmap='Greys')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GphfkazlnLHy",
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Datasets and Data Loaders\n",
    "\n",
    "So far we have been work with our data in full-batch mode: we always ran our entire dataset through our network. This is, of course, only possible if your dataset is small enough to fit into memory all at once. If you are running your network on a GPU, you can then run on all your data in parallel so it's computationaly efficient.\n",
    "\n",
    "In deep learning, however, most datasets are far too large to fit into memory at once – they can easily have tens or hundreds of gigabytes and some are even larger. If your dataset is that large, it is, of course, essential that you are able to load the data from the hard drive on the fly and train in mini-batch mode. In PyTorch, this aspect of deep learning is handled using `Dataset` and `DataLoader` objects.\n",
    "\n",
    "#### The Dataset Class\n",
    "\n",
    "The `Dataset` class provides a unified interface for accessing data. There is a number of different classes that derive from `Dataset`, to support a number of different dataset formats, e.g. `ImageNet`, `VOCDetection`, `Cityscapes`, `CelebA`, etc. There is even the slightly more generic `ImageFolder`, which simply loads images and class labels from a folder.\n",
    "\n",
    "To define a custom dataset, you would need to implement the following interface:\n",
    "\n",
    "```\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, ...)\n",
    "        ...\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "        \"\"\"\n",
    "\n",
    "        ...\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the sample at index idx from the dataset.\n",
    "        \"\"\"\n",
    "\n",
    "        ...\n",
    "```\n",
    "#### The DataLoader Class\n",
    "\n",
    "Given a dataset, a data loader is in charge of drawing mini-batches from it, making sure the data is properly shuffled, etc. Usually, you won't need to implement your own dataloader – you'll just be able to use the `DataLoader` class from `torch.utils.data`, e.g. like this:\n",
    "\n",
    "```\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "```\n",
    "#### Our Example and TensorDataset\n",
    "\n",
    "Our MNIST dataset is again small enough to fit into memory all at once. With datasets like this we can use the `TensorDataset` class, which merely wraps an existing tensor in the dataset interface and allows it to be used with data loaders.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "test_dataset = TensorDataset(X_test, Y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GphfkazlnLHy",
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Constructing the Convolutional Network\n",
    "\n",
    "When constructing a convolutional net the procedure is usually to study literature that deals with similar tasks and use that knowledge to design a similar neural architecture for the problem at hand (and possibly to tune it).\n",
    "\n",
    "Given that the MNIST dataset is not especially difficult, we will use to illustrate an even simpler approach:\n",
    "\n",
    "* We will keep chaining blocks of convolutional layers, ReLU functions and pooling layers.\n",
    "* We will keep going until the dimensions of the inputs have decreased sufficiently.\n",
    "* Once that happens we will append one or several standard linear layers and ReLUs.\n",
    "To make it easier to keep track of what the dimensions of the output are after all the individual layers have been applied, we will not wrap our layers into a class just yet: we will instead experiment with them freely first. To this end we will take a few samples from the dataset, which will be used as a dummy input.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l0VLWcWQ_o4d"
   },
   "outputs": [],
   "source": [
    "y = X_train[:5].to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5tnUChCYtXBc",
    "tags": [
     "en"
    ]
   },
   "source": [
    "Let us now create our first block and apply it to tensor `y`. We will first create our 2D convolutional layer using class `nn.Conv2d`. We need to specify a few parameters: namely the number of input and output channels and the kernel size. The number of input channels is 1, of course, because as we mentioned, we have a single colour channel. The number of output channels is a hyperparameter – we are going to begin with 16 because our data is so simple. Note that in a typical convolutional network, the dimensions of the feature maps tend to decrease in later layers, but the numbers of channels tend to increase (the intuition is that the deeper the layer is, the more abstract – and more numerous – the concepts that it is going to represent).\n",
    "\n",
    "Convolutional kernels can be of different sizes, but the conventional wisdom based on empirical evidence is that $3 \\times 3$ kernels tend to work well. Making the kernel unnecessarily large is something we want to avoid because the larger the matrices we are working with, the longer it will take to multiply them.\n",
    "\n",
    "After the convolutional layer we apply the ReLU activation function and max-pooling, for which we again need to specify a kernel size. With pooling, the larger the kernel size, the more rapidly our data will be downsampled. We are therefore using a small $2 \\times 2$ kernel. A number of modern architectures have now dispensed with the use of pooling layers altogether and use strides or dilations in the convolutional layer to downsample the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a3aFchVN5lJD"
   },
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(\n",
    "    in_channels=1, out_channels=8,\n",
    "    kernel_size=(3, 3))\n",
    "\n",
    "y = conv1(y)\n",
    "y = torch.relu(y)\n",
    "y = torch.max_pool2d(y, kernel_size=(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YMKEQ8zQnLIS",
    "tags": [
     "en"
    ]
   },
   "source": [
    "After we have constructed our first block, let us check what effect this had on the dimensionality of our data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "M7URiPUI5lTK",
    "outputId": "a6028670-b456-4e72-a75d-9f6ba44a566d"
   },
   "outputs": [],
   "source": [
    "np.product(y.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uibE1TnAnLIl",
    "tags": [
     "en"
    ]
   },
   "source": [
    "Alas, our data still has too many dimensions and we need to reduce its dimensionality further. Let's try to apply one more block to it. Note that while the feature map is getting smaller, we do actually increase the number of channels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OnRZLp7h5lmV"
   },
   "outputs": [],
   "source": [
    "conv2 = nn.Conv2d(8, 16, (3, 3))\n",
    "y = conv2(y)\n",
    "y = torch.relu(y)\n",
    "y = torch.max_pool2d(y, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Gt8KrJsC5liQ",
    "outputId": "19bd9632-07a5-49ea-b594-a7aadd037b1b"
   },
   "outputs": [],
   "source": [
    "np.product(y.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "arpQnD5nnLI9",
    "tags": [
     "en"
    ]
   },
   "source": [
    "The number of dimensions is much more reasonable now. We can now flatten the output (transform it from a 2-dimensional image into a 1-dimensional vector) and apply some standard linear layers and ReLUs. Again we make sure that the dimension of the data decreases gradually and the change from one layer to the next is not too drastic. The output layer is going to have 10 output neurons, because we are going to classify into 10 classes: the digits. We will use softmax as its activation function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFx8XKrA5lei"
   },
   "outputs": [],
   "source": [
    "y = torch.flatten(y, 1)\n",
    "\n",
    "fc1 = nn.Linear(400, 128)\n",
    "y = fc1(y)\n",
    "y = torch.relu(y)\n",
    "\n",
    "fc2 = nn.Linear(128, 10)\n",
    "y = fc2(y)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3qrBx4t6nLJM",
    "tags": [
     "en"
    ]
   },
   "source": [
    "Now that we have designed our architecture, we need to wrap it in a class again. As usual, layers with parameters need to be constructed in `__init__` and then used in `forward`. To make the architecture a bit better, we are going to use `nn.PReLU` instead of `relu`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CPiXuQRQ5lFk"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, (3, 3))\n",
    "        self.conv_acti1 = nn.PReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(8, 16, (3, 3))\n",
    "        self.conv_acti2 = nn.PReLU()\n",
    "\n",
    "        self.fc1 = nn.Linear(400, 128)\n",
    "        self.fc_acti1 = nn.PReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(128, num_outputs)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, y):\n",
    "        y = self.conv1(y)\n",
    "        y = self.conv_acti1(y)\n",
    "        y = torch.max_pool2d(y, kernel_size=(2, 2))\n",
    "        y = self.dropout(y)\n",
    "        \n",
    "        y = self.conv2(y)\n",
    "        y = self.conv_acti2(y)\n",
    "        y = torch.max_pool2d(y, kernel_size=(2, 2))\n",
    "        y = self.dropout(y)\n",
    "        \n",
    "        y = torch.flatten(y, 1)\n",
    "        \n",
    "        y = self.fc1(y)\n",
    "        y = self.fc_acti1(y)\n",
    "        y = self.dropout(y)\n",
    "\n",
    "        y = self.fc2(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XbhYh26qn0NA",
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Constructing and Training the Classifier\n",
    "\n",
    "Our training loop is going to be a bit different now that we are using `Dataset` and `Dataloader` objects.\n",
    "\n",
    "There are going to be two nested loops now:\n",
    "\n",
    "* The outer one is iterating over epochs;\n",
    "* The inner one is iterating over mini-batches within the same epoch;\n",
    "Note that we are logging the loss for each mini-batch now. Consequently, the loss plot is going to be a bit more noisy – gradients are, of course, more stable when accumulated over the entire dataset rather than over the smaller mini-batches.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs = 10\n",
    "model = Net(num_outputs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_train = []\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "\n",
    "    for X_batch, Y_batch in train_dataloader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        Y_batch = Y_batch.to(device)\n",
    "        \n",
    "        y_batch = model(X_batch)\n",
    "        loss = criterion(y_batch, Y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train.append(loss.item())\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"epoch {epoch}, loss: {np.mean(loss_train[-20:])}\")\n",
    "\n",
    "print(f\"epoch {epoch}, loss: {np.mean(loss_train[-20:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_train)\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.grid(ls='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9GtNTcBBn3Z_",
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Testing\n",
    "\n",
    "Finally, we apply our standard testing procedure for classifiers: we display the confusion matrix and the accuracy.\n",
    "\n",
    "#### On the Train Set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_train_logit = model(X_train)\n",
    "    y_train = y_train_logit.argmax(dim=1)\n",
    "\n",
    "cm = pd.crosstab(\n",
    "    Y_train.cpu().numpy(),\n",
    "    y_train.cpu().numpy(),\n",
    "    rownames=['actual'],\n",
    "    colnames=['predicted']\n",
    ")\n",
    "print(cm, \"\\n\")\n",
    "\n",
    "acc = accuracy_score(Y_train.cpu().numpy(), y_train.cpu().numpy())\n",
    "print(\"Accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9GtNTcBBn3Z_",
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### On the Test Set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_logit = model(X_test)\n",
    "    y_test = y_test_logit.argmax(dim=1)\n",
    "\n",
    "cm = pd.crosstab(\n",
    "    Y_test.cpu().numpy(),\n",
    "    y_test.cpu().numpy(),\n",
    "    rownames=['actual'],\n",
    "    colnames=['predicted']\n",
    ")\n",
    "print(cm, \"\\n\")\n",
    "\n",
    "acc = accuracy_score(Y_test.cpu().numpy(), y_test.cpu().numpy())\n",
    "print(\"Accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XAGmqsvFVOPR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "6_cnn_mnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
