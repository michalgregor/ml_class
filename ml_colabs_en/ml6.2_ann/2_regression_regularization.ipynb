{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8rFleQJMA18",
    "tags": [
     "en"
    ]
   },
   "source": [
    "**NOTE: This notebook is written for the Google Colab platform, which provides free hardware acceleration. However it can also be run (possibly with minor modifications) as a standard Jupyter notebook, using a local GPU.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uYHzZMVjMA2N",
    "outputId": "759e5c64-250c-4f95-fe58-f237ba447821"
   },
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install git+https://github.com/michalgregor/class_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "yn6Mqh5qMA2r",
    "outputId": "7dec07c7-ce23-4791-ec26-118d72098114"
   },
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from class_utils import error_histogram\n",
    "from class_utils.pytorch_utils import EarlyStopping\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jLWb1LkMMA2-",
    "outputId": "2eb38179-d0ba-452b-ef61-d960ec4718bb"
   },
   "outputs": [],
   "source": [
    "#@title -- Downloading Data -- { display-mode: \"form\" }\n",
    "from class_utils.download import download_file_maybe_extract\n",
    "download_file_maybe_extract(\"https://www.dropbox.com/s/3jnf3000vwaxtcg/boston_housing.zip?dl=1\", directory=\"data/boston_housing\")\n",
    "\n",
    "# also create a directory for storing any outputs\n",
    "import os\n",
    "os.makedirs(\"output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TRv3uQX8MA3P",
    "tags": [
     "en"
    ]
   },
   "source": [
    "## A Real-Estate-Price Regression Model\n",
    "\n",
    "In this notebook we will apply neural regression to the problem of real estate price prediction. We will make use of the [Boston housing dataset](https://www.kaggle.com/c/boston-housing).\n",
    "\n",
    "**Note:**  The example is purely illustrational. The dataset is well-structured (the data is divided into columns with clear meanings etc.), and would therefore probably be approached with a different method in practice â€“ possibly with some approached based on decision trees. Artificial neural networks and deep learning are usually applied to problems with unstructured data, such as images, audio, text etc.\n",
    "\n",
    "### Loading and Preprocessing the Dataset\n",
    "\n",
    "Let us start by displaying the description of the dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vMO0LT4CMA3b",
    "outputId": "2a7518a9-1910-4ae9-b09e-4f76d1da9d86"
   },
   "outputs": [],
   "source": [
    "with open(\"data/boston_housing/description.txt\", \"r\") as file:\n",
    "    print(\"\".join(file.readlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UwIdli9oMA3u",
    "tags": [
     "en"
    ]
   },
   "source": [
    "As the next step, we will load the dataset itself from a CSV file:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "XlH4mJwxMA32",
    "outputId": "aa60320e-4928-456b-f994-f2863185c6cd"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/boston_housing/housing.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6UA381bPMA4D",
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### The Splitting of the Dataset\n",
    "\n",
    "Next we continue by splitting the dataset. In this case, however, the data will not be split into two parts the way we usually split it, but rather into three parts: training, validation and testing data in the ratio of 70 : 5 : 25. The validation data will be used during training for regularization and model selection (the details are below).\n",
    "\n",
    "Also, when splitting, we stratify by the discretized version of the output column:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "89Qbm_CvMA4L"
   },
   "outputs": [],
   "source": [
    "kbins = KBinsDiscretizer(10, encode='ordinal')\n",
    "\n",
    "y_stratify = kbins.fit_transform(df[[\"medv\"]])\n",
    "df_train_valid, df_test = train_test_split(df, test_size=0.25,\n",
    "                                     stratify=y_stratify,\n",
    "                                     random_state=9)\n",
    "\n",
    "y_stratify = kbins.fit_transform(df_train_valid[[\"medv\"]])\n",
    "df_train, df_valid = train_test_split(df_train_valid, test_size=0.05/0.75,\n",
    "                                     stratify=y_stratify,\n",
    "                                     random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qdVDQvxjMA4V",
    "tags": [
     "en"
    ]
   },
   "source": [
    "---\n",
    "#### Task 1: Data Preprocessing\n",
    "\n",
    "**Apply our standard preprocessing procedure for neural nets to the data and produce the training set `X_train`, `Y_train`, the validation set `X_valid`, `Y_valid` and the testing set `X_test`, `Y_test` as the result: in the necessary form and cast to the appropriate data type.** \n",
    "\n",
    "Remember to only reserve `fit_transform` for the train set and to use `transform` on the validation set and the test set.\n",
    "\n",
    "Do not forget to cast the data to PyTorch tensors with appropriate data types. Transfer the tensors to `device`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IqWPdiMmMA4m",
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "categorical_inputs = [          ] # -----\n",
    "\n",
    "numeric_inputs = [              ] # -----\n",
    "\n",
    "output = [\"medv\"]\n",
    "\n",
    "\n",
    "input_preproc = # ---\n",
    "\n",
    "\n",
    "\n",
    "# -----\n",
    "\n",
    "\n",
    "output_preproc = StandardScaler()\n",
    "\n",
    "\n",
    "# -----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-1N5WV3MA4x",
    "tags": [
     "en"
    ]
   },
   "source": [
    "---\n",
    "### Task 2: Creation of Neural Net and Training\n",
    "\n",
    "**Create a neural regressor and train it using the train set. The result should be a trained `net` object with a `scikit-learn` interface, the performance of which we will subsequently be able to test using the test set.** \n",
    "\n",
    "Aid: For the sizes of your layers, you can pick e.g. the following:\n",
    "\n",
    "* `num_inputs`;\n",
    "* 128;\n",
    "* 64;\n",
    "* 32;\n",
    "* `num_outputs`;\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BXtcSROsMA5N",
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        # -----\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = X_train.shape[1]\n",
    "num_outputs = Y_train.shape[1]\n",
    "model = Net(num_inputs, num_outputs).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_train = []\n",
    "\n",
    "for epoch in range(2000):\n",
    "    model.train()\n",
    "    y = model(X_train)\n",
    "\n",
    "    loss = criterion(y, Y_train)\n",
    "    loss_train.append(loss.detach().item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"epoch {epoch}, loss: {np.mean(loss_train[-20:]):.3g}\")\n",
    "\n",
    "print(f\"epoch {epoch}, loss: {np.mean(loss_train[-20:]):.3g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mH9-xhHqK_BT",
    "tags": [
     "en"
    ]
   },
   "source": [
    "Next we can use the losses recorded in `loss_train` to plot the learning curve.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_train)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.grid(ls='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mH9-xhHqK_BT",
    "tags": [
     "en"
    ]
   },
   "source": [
    "Once the training is done, let's also do our standard evaluation on the training set. We should see that the results are rather good and the errors are negligible on the scale of the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_cpu = Y_train.cpu()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_train_cpu = model(X_train).cpu()\n",
    "\n",
    "# we compute and display the MSE and the MAE\n",
    "mse = mean_squared_error(Y_train_cpu, y_train_cpu)\n",
    "print(\"MSE = {}\".format(mse))\n",
    "\n",
    "mae = mean_absolute_error(Y_train_cpu, y_train_cpu)\n",
    "print(\"MAE = {}\".format(mae))\n",
    "\n",
    "# we display the error histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_train_cpu, y_train_cpu, Y_fit_scaling=Y_train_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mH9-xhHqK_BT",
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### Testing the Model on the Validation Set\n",
    "\n",
    "Alright, so the results on the training set are quite satisfactory. But does the model actually generalize well?\n",
    "\n",
    "Given that this is not the final version of our model (we will introduce other versions below), we will **not yet test the performance using the testing set**  (we need to hold that out for the final testing in order to verify generalization), but rather using the **validation set** .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_valid_cpu = Y_valid.cpu()\n",
    "Y_train_cpu = Y_train.cpu()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_valid_cpu = model(X_valid).cpu()\n",
    "\n",
    "# we compute and display the MSE and the MAE\n",
    "mse = mean_squared_error(Y_valid_cpu, y_valid_cpu)\n",
    "print(\"MSE = {}\".format(mse))\n",
    "\n",
    "mae = mean_absolute_error(Y_valid_cpu, y_valid_cpu)\n",
    "print(\"MAE = {}\".format(mae))\n",
    "\n",
    "# we display the error histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_valid_cpu, y_valid_cpu, Y_fit_scaling=Y_train_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6lBsnW4MK7O7",
    "tags": [
     "en"
    ]
   },
   "source": [
    "After evaluating the model on the validation set, you should see that the metrics are not even close to those on the training set. This indicates that there is a significant amount of **overfitting** .\n",
    "\n",
    "#### Testing on the Validation Set Throughout Training\n",
    "\n",
    "To get a better idea of where the training went wrong, let's record the validation loss throughout training the same way we do with the training loss and let's plot both.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = X_train.shape[1]\n",
    "num_outputs = Y_train.shape[1]\n",
    "model = Net(num_inputs, num_outputs).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_train = []\n",
    "loss_valid = []\n",
    "\n",
    "for epoch in range(2000):\n",
    "    model.train()\n",
    "    y = model(X_train)\n",
    "\n",
    "    loss = criterion(y, Y_train)\n",
    "    loss_train.append(loss.detach().item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y = model(X_valid)\n",
    "        loss = criterion(y, Y_valid)\n",
    "        loss_valid.append(loss.item())\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"epoch {epoch}, train loss: {np.mean(loss_train[-20:]):.3g}, valid loss: {np.mean(loss_valid[-20:]):.3g}\")\n",
    "\n",
    "print(f\"epoch {epoch}, train loss: {np.mean(loss_train[-20:]):.3g}, valid loss: {np.mean(loss_valid[-20:]):.3g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_train, label=\"train\")\n",
    "plt.plot(loss_valid, label=\"valid\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.grid(ls='--')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_valid_cpu = Y_valid.cpu()\n",
    "Y_train_cpu = Y_train.cpu()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_valid_cpu = model(X_valid).cpu()\n",
    "\n",
    "# we compute and display the MSE and the MAE\n",
    "mse = mean_squared_error(Y_valid_cpu, y_valid_cpu)\n",
    "print(\"MSE = {}\".format(mse))\n",
    "\n",
    "mae = mean_absolute_error(Y_valid_cpu, y_valid_cpu)\n",
    "print(\"MAE = {}\".format(mae))\n",
    "\n",
    "# we display the error histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_valid_cpu, y_valid_cpu, Y_fit_scaling=Y_train_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6lBsnW4MK7O7",
    "tags": [
     "en"
    ]
   },
   "source": [
    "Well, the picture we get now is totally different! The loss on the validation set is much worse than on the test set and, if you look carefully, you may see that it even starts to increase after a while â€“ even though the loss on the train set still decreases or stays low.\n",
    "\n",
    "### Regularization\n",
    "\n",
    "How do we resolve the problem presented in the previous section and prevent the network from overfitting? Well, overfitting often occurs because when the model finds it difficult to decrease the loss in a legitimate way, it will start to cheat by memorize data.\n",
    "\n",
    "In order to prevent that kind of problem, we need to use some regularization methods. These are methods designed to help prevent overfitting. The name \"regularization\" derives from the fact that we want our model to capture the real regularities in the data and not start memorizing data, including the noise.\n",
    "\n",
    "#### Getting More Data\n",
    "\n",
    "Getting more data is generally the best way to improve generalization â€“ given enough data, a learning method should be better able to tell regularities apart from noise. It also shouldn't be able to memorize all data, so it is forced to learn the regularity itself.\n",
    "\n",
    "The problem with getting more data is that it is generally very difficult and expensive. A number of other regularization methods have therefore been developed, with a view of getting as much from the data we already have as possible.\n",
    "\n",
    "#### Regularization in Standard Machine Learning\n",
    "\n",
    "In most machine learning methods, regularization is done by reducing the capacity of the model in some way â€“ e.g. by decreasing its size (the degree of a polynomial, the size of a decision tree, ...).\n",
    "\n",
    "This helps because the model is no longer able to memorize the training set and actually needs to fit the regularities in the data. In artificial neural networks this can be done by decreasing the numbers and sizes of layers.\n",
    "\n",
    "#### Early Stopping\n",
    "\n",
    "Another way to decrease the capacity of a neural model is to use a technique known as early stopping. As we saw earlier, one thing that typically happens in the course of training is that even though the loss on the training set keeps decreasing, the loss on the validation set (if used) stops decreasing or even starts growing.\n",
    "\n",
    "The idea behind early stopping is to simply stop training at that point and restore weights to the point where the validation loss was actually at its minimum. The further advantage of this approach is that it saves some computation.\n",
    "\n",
    "#### Regularization in Deep Learning\n",
    "\n",
    "The area of deep learning is a bit of an exception, because regularization is typically not done by restricting the size of the model. Rather, deep learning practicioners make use of:\n",
    "\n",
    "* Special layers;\n",
    "* Clever architectures that inject better inductive preferences to the model (i.e. bias it towards the kind of solution that is likely to generalize well);\n",
    "* Data augmentation (e.g. generating new random variants of existing samples);\n",
    "* Transfer learning (i.e. pretraining on a larger dataset);\n",
    "* ...\n",
    "#### What We Are Going to Use In This Notebook\n",
    "\n",
    "In this particular notebook, we are going to keepthings simple. We are only going to use two simple regularization methods:\n",
    "\n",
    "* **Early stopping** ;\n",
    "* **Dropout** ;\n",
    "Plus, since the neural network we are using here is a **shallow**  one and the dataset is tiny, making the **neural net smaller**  may actually also be a good way to regularize â€“ even though you typically wouldn't do that in a deep network trained on millions of samples.\n",
    "\n",
    "Note again that throughout the entire process of developing our model, **we are using the training set and the validation set** , but **not**  the testing set. We are reserving the testing set so that we can evaluate the very final version of our model.\n",
    "\n",
    "### Early Stopping\n",
    "\n",
    "Let's start with early stopping then. Since the losses can be a bit noisy, early stopping usually has a \"patience\" hyperparameter â€“ this specifies how many steps to wait once the loss has stopped decreasing before the training is actually stopped.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(checkpoint_path=\"output/best_model.pt\")\n",
    "\n",
    "num_inputs = X_train.shape[1]\n",
    "num_outputs = Y_train.shape[1]\n",
    "model = Net(num_inputs, num_outputs).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_train = []\n",
    "loss_valid = []\n",
    "\n",
    "for epoch in range(2000):\n",
    "    model.train()\n",
    "    y = model(X_train)\n",
    "\n",
    "    loss = criterion(y, Y_train)\n",
    "    loss_train.append(loss.detach().item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y = model(X_valid)\n",
    "        loss = criterion(y, Y_valid)\n",
    "        loss_valid.append(loss.item())\n",
    "        if early_stopping(loss_valid[-1], model):\n",
    "            print(f\"Stopping the training early because the validation loss has not improved in the last {early_stopping.patience} epochs\")\n",
    "            break\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"epoch {epoch}, train loss: {np.mean(loss_train[-20:]):.3g}, valid loss: {np.mean(loss_valid[-20:]):.3g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_train, label=\"train\")\n",
    "plt.plot(loss_valid, label=\"valid\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.grid(ls='--')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "72j8DiAJK_CX",
    "tags": [
     "en"
    ]
   },
   "source": [
    "Once the training is done, we load the best model back from the checkpoint and run evaluation. The results may already be a bit better â€“ but it is also possible that more powerful regularization will be required.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"output/best_model.pt\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_valid_cpu = Y_valid.cpu()\n",
    "Y_train_cpu = Y_train.cpu()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_valid_cpu = model(X_valid).cpu()\n",
    "\n",
    "# we compute and display the MSE and the MAE\n",
    "mse = mean_squared_error(Y_valid_cpu, y_valid_cpu)\n",
    "print(\"MSE = {}\".format(mse))\n",
    "\n",
    "mae = mean_absolute_error(Y_valid_cpu, y_valid_cpu)\n",
    "print(\"MAE = {}\".format(mae))\n",
    "\n",
    "# we display the error histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_valid_cpu, y_valid_cpu, Y_fit_scaling=Y_train_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sKm5VoP1K_Cr",
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Dropout\n",
    "\n",
    "The other kind of regularization that we are going to explore in this notebook is called **dropout** . This method will turn off a portion of neurons in a layer randomly (during training, not in evaluation mode). In PyTorch this can be done by placing `nn.Dropout` after a layer. Dropout tends to make the network more robust, improving generalization.\n",
    "\n",
    "The portion of neurons to be turned off is a hyperparameter. If we wanted to use 0.3, we could add dropout in the following way:\n",
    "\n",
    "```\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        ...\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        ...\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        ...\n",
    "\n",
    "        y = torch.relu(y)\n",
    "        y = self.dropout(y)\n",
    "\n",
    "        ...\n",
    "```\n",
    "We typically do not insert a dropout layer after the output layer (given that the outputs are read directly from the output layer, if its outputs are zeroed out, this will cause errors that no network â€“ no matter how robust â€“ would be able to prevent).\n",
    "\n",
    "#### Dropout and the Model's Capacity\n",
    "\n",
    "Whenever we use more agressive forms of regularization, this may reduce the capacity of the model too significantly. When using many `Dropout` layers, it can therefore be necessary to make the model a bit larger than it would ordinarily be.\n",
    "\n",
    "The interaction between various kinds of regularization can also be nontrivial: e.g. when using dropout, we can expect the validation loss to be a lot more noisy (new sources of stochasticity have been added). If using early stopping as well, it can therefore be necessary to use significantly larger values of `patience`.\n",
    "\n",
    "---\n",
    "### Task 3\n",
    "\n",
    "**Try to insert a few `Dropout` layers into your network. E.g. one `Dropout` layer after each `relu`.** \n",
    "\n",
    "**When testing the effectiveness of your regularization only use the validation set. The testing set needs to be held out until the end â€“ we can only use it once!** \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BXtcSROsMA5N",
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "class DropoutNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        # -----\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9qolgoGK_DZ",
    "tags": [
     "en"
    ]
   },
   "source": [
    "Let's try training again using our new network. To keep things simple and avoid having to tune the `patience` parameter (an excessively low value could make our results worse), we are not going to be using early stopping in this run.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = X_train.shape[1]\n",
    "num_outputs = Y_train.shape[1]\n",
    "model = DropoutNet(num_inputs, num_outputs).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_train = []\n",
    "loss_valid = []\n",
    "\n",
    "for epoch in range(2000):\n",
    "    model.train()\n",
    "    y = model(X_train)\n",
    "\n",
    "    loss = criterion(y, Y_train)\n",
    "    loss_train.append(loss.detach().item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y = model(X_valid)\n",
    "        loss = criterion(y, Y_valid)\n",
    "        loss_valid.append(loss.item())\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"epoch {epoch}, train loss: {np.mean(loss_train[-20:]):.3g}, valid loss: {np.mean(loss_valid[-20:]):.3g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_train, label=\"train\")\n",
    "plt.plot(loss_valid, label=\"valid\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.grid(ls='--')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9qolgoGK_DZ",
    "tags": [
     "en"
    ]
   },
   "source": [
    "Note how our validation set now no longer increases. Note also how the losses are more noisy â€“ this is, of course, because of the noise introduced by dropout.\n",
    "\n",
    "The training loss and the validation loss now shouldn't differ quite so wildly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_cpu = Y_train.cpu()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_train_cpu = model(X_train).cpu()\n",
    "\n",
    "# we compute and display the MSE and the MAE\n",
    "mse = mean_squared_error(Y_train_cpu, y_train_cpu)\n",
    "print(\"MSE = {}\".format(mse))\n",
    "\n",
    "mae = mean_absolute_error(Y_train_cpu, y_train_cpu)\n",
    "print(\"MAE = {}\".format(mae))\n",
    "\n",
    "# we display the error histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_train_cpu, y_train_cpu, Y_fit_scaling=Y_train_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_valid_cpu = Y_valid.cpu()\n",
    "Y_train_cpu = Y_train.cpu()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_valid_cpu = model(X_valid).cpu()\n",
    "\n",
    "# we compute and display the MSE and the MAE\n",
    "mse = mean_squared_error(Y_valid_cpu, y_valid_cpu)\n",
    "print(\"MSE = {}\".format(mse))\n",
    "\n",
    "mae = mean_absolute_error(Y_valid_cpu, y_valid_cpu)\n",
    "print(\"MAE = {}\".format(mae))\n",
    "\n",
    "# we display the error histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_valid_cpu, y_valid_cpu, Y_fit_scaling=Y_train_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vIPdcMu4MA5g",
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Results on the Testing Set\n",
    "\n",
    "Once we have arrived at our final model, we are going to test its generalization on the testing data as well.\n",
    "\n",
    "Since we did not use early stopping in our final model, we could actually rerun training on train + validation set now before we do testing. That might improve the results of our final test a bit further â€“ you may add the necessary code if you like.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "colab_type": "code",
    "id": "w2d6xYOZMA5n",
    "outputId": "112c0937-5ce2-44ae-89a8-e2900d8749d8"
   },
   "outputs": [],
   "source": [
    "Y_test_cpu = Y_test.cpu()\n",
    "Y_train_cpu = Y_train.cpu()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_cpu = model(X_test).cpu()\n",
    "\n",
    "# we compute and display the MSE and the MAE\n",
    "mse = mean_squared_error(Y_test_cpu, y_test_cpu)\n",
    "print(\"MSE = {}\".format(mse))\n",
    "\n",
    "mae = mean_absolute_error(Y_test_cpu, y_test_cpu)\n",
    "print(\"MAE = {}\".format(mae))\n",
    "\n",
    "# we display the error histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_test_cpu, y_test_cpu, Y_fit_scaling=Y_train_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f-irkW--K_D7",
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Regression Using Gradient-Boosted Decision Trees\n",
    "\n",
    "To reinforce the point that neural nets do not bring many advantages when applied to structured data and that better results can usually be achieved by other methods, we will now compare our results with the XGBoost method, which is based on an ensemble of decision trees created using gradient boosting. There is a good chance that the results will be better than we were able to achieve using a neural net: and the learning will be significantly faster. The real advantages of neural networks generally only become obvious once they are applied to more complex unstructured data such as images, audio, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "X_train_np = X_train.cpu().numpy()\n",
    "Y_train_np = Y_train.cpu().numpy()\n",
    "X_test_np = X_test.cpu().numpy()\n",
    "Y_test_np = Y_test.cpu().numpy()\n",
    "\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train_np, Y_train_np);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = model.predict(X_test_np)\n",
    "\n",
    "# we compute and display the MSE and the MAE\n",
    "mse = mean_squared_error(Y_test_np, y_test)\n",
    "print(\"MSE = {}\".format(mse))\n",
    "\n",
    "mae = mean_absolute_error(Y_test_np, y_test)\n",
    "print(\"MAE = {}\".format(mae))\n",
    "\n",
    "# we display the error histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_test_np, y_test, Y_fit_scaling=Y_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "4_regression_exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "a351393365bb1b108989afa08de3243f72f5e58927baf5d192f3cca79a41cbc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
