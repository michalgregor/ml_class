{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sbbM4HbNK-9J",
    "tags": [
     "en"
    ]
   },
   "source": [
    "**NOTE: This notebook is written for the Google Colab platform, which provides free hardware acceleration. However it can also be run (possibly with minor modifications) as a standard Jupyter notebook, using a local GPU.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4ANSllpGK-9Y",
    "outputId": "ace294df-961d-45e4-9ebd-bdcf74a06e32"
   },
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install git+https://github.com/michalgregor/class_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJSZAu1FK-9v"
   },
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "RnPU7T0VK--J",
    "outputId": "ac84e0e0-b68e-4842-a110-c374bb2af1f4"
   },
   "outputs": [],
   "source": [
    "#@title -- Downloading Data -- { display-mode: \"form\" }\n",
    "from class_utils.download import download_file_maybe_extract\n",
    "download_file_maybe_extract(\"https://www.dropbox.com/s/8s0ivlo9yshhxkn/winequality.zip?dl=1\", directory=\"data/winequality\")\n",
    "\n",
    "# also create a directory for storing any outputs\n",
    "import os\n",
    "os.makedirs(\"output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5SLk1arGK--q",
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Classifying Wine Quality using Neural Nets\n",
    "\n",
    "In this notebook you can try out a neural classifier on another simple dataset.\n",
    "\n",
    "**Note:**  The example is purely illustrational. The dataset is well-structured (the data is divided into columns with clear meanings etc.), and would therefore probably be better approached with a different method in practice – possibly with some approached based on decision trees. Artificial neural networks and deep learning are usually applied to problems with unstructured data such as images, audio, text etc.\n",
    "\n",
    "### Loading and Preprocessing the Dataset\n",
    "\n",
    "We will load our dataset from a CSV file:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "colab_type": "code",
    "id": "ClWoKTQEK--z",
    "outputId": "0723a5b5-36fe-4654-d6ff-6feddae984e4"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/winequality/winequality-white.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gPAnn_X6K-_B",
    "tags": [
     "en"
    ]
   },
   "source": [
    "The description of the data comes in a separate file, should we need it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "agNFax_-K-_M",
    "outputId": "8307679e-809f-4e4f-a685-1d2a286e345e"
   },
   "outputs": [],
   "source": [
    "with open(\"data/winequality/winequality\", \"r\") as file:\n",
    "    print(\"\".join(file.readlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6q4B9PkjK-_a",
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### The Splitting of the Dataset\n",
    "\n",
    "Next we continue by splitting the dataset. In this case, however, the data will not be split into two parts the way we usually split it, but rather into three parts: training, validation and testing data in the ratio of 70 : 5 : 25. The validation data will be used during learning for regularization and model selection (the details are below). When splitting, we stratify by quality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "it9yeH0QK-_i"
   },
   "outputs": [],
   "source": [
    "df_train_valid, df_test = train_test_split(df, test_size=0.25,\n",
    "                                     stratify=df['quality'],\n",
    "                                     random_state=4)\n",
    "df_train, df_valid = train_test_split(df_train_valid, test_size=0.05/0.75,\n",
    "                                     stratify=df_train_valid['quality'],\n",
    "                                     random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1D1POYkSK-_u",
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### Column Selection and Pipeline Creation\n",
    "\n",
    "As usual, we will determine which columns are numeric and which are categorical and we will create our pipeline object for preprocessing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c5JkS7xWK-_2"
   },
   "outputs": [],
   "source": [
    "categorical_inputs = []\n",
    "numeric_inputs = list(df.columns[:-1])\n",
    "output = [\"quality\"]\n",
    "\n",
    "input_preproc = make_column_transformer(\n",
    "    (make_pipeline(\n",
    "        SimpleImputer(strategy='constant', fill_value='MISSING'),\n",
    "        OneHotEncoder()),\n",
    "     categorical_inputs),\n",
    "    \n",
    "    (make_pipeline(\n",
    "        SimpleImputer(),\n",
    "        StandardScaler()),\n",
    "     numeric_inputs)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnKBk-0YK_AD",
    "tags": [
     "en"
    ]
   },
   "source": [
    "Wine quality is given on a scale from 1 to 10 in our dataset (column `quality`). Given that our dataset contains a relatively large amount of noise, this scale might be too fine: we will instead differentiate between three degrees of quality and we will do the transformation to the new scale automatically: using transformer `KBinsDiscretizer` from the `scikit-learn` package.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2LaQCaouK_AK"
   },
   "outputs": [],
   "source": [
    "output_preproc = KBinsDiscretizer(3, encode='ordinal', strategy='quantile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yr143A6hK_AV",
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### Application of Pre-processing\n",
    "\n",
    "Finally, we apply our transformers to the data. As usual, we make sure to apply the `transform` method and not the `fit_transform` method to our testing – and in this case also to our validation – data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "18P5pSuMK_Ab"
   },
   "outputs": [],
   "source": [
    "X_train = input_preproc.fit_transform(df_train[categorical_inputs+numeric_inputs])\n",
    "Y_train = output_preproc.fit_transform(df_train[output]).reshape(-1)\n",
    "\n",
    "X_valid = input_preproc.transform(df_valid[categorical_inputs+numeric_inputs])\n",
    "Y_valid = output_preproc.transform(df_valid[output]).reshape(-1)\n",
    "\n",
    "X_test = input_preproc.transform(df_test[categorical_inputs+numeric_inputs])\n",
    "Y_test = output_preproc.transform(df_test[output]).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ulLh8aH5K_Al",
    "tags": [
     "en"
    ]
   },
   "source": [
    "We also convert into the datatypes expected by Pytorch, i.e. to 32-bit floats (inputs) and 64-bit integers (class labels).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s81Nm3XZK_As"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "X_train = torch.as_tensor(X_train, dtype=torch.float32).to(device)\n",
    "Y_train = torch.as_tensor(Y_train, dtype=torch.long).to(device)\n",
    "X_valid = torch.as_tensor(X_valid, dtype=torch.float32).to(device)\n",
    "Y_valid = torch.as_tensor(Y_valid, dtype=torch.long).to(device)\n",
    "X_test = torch.as_tensor(X_test, dtype=torch.float32).to(device)\n",
    "Y_test = torch.as_tensor(Y_test, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yKvggbQIK_A2",
    "tags": [
     "en"
    ]
   },
   "source": [
    "---\n",
    "### Task 1\n",
    "\n",
    "**Apply a neural classifier with dropout to the wine quality classification problem. In your training loop, log results on the validation set at each epoch. You can use the results on the validation set to tune your network architecture, the amount of dropout, etc.** \n",
    "\n",
    "**Aid: For the sizes of linear layers, you can start with the following:** \n",
    "\n",
    "* `num_inputs`;\n",
    "* 64;\n",
    "* 32;\n",
    "* 16;\n",
    "* `num_outputs`;\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kja-0c4MK_BJ",
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        \n",
    "    \n",
    "    # ------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kja-0c4MK_BJ",
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "num_inputs = X_train.shape[1]\n",
    "num_outputs = len(np.unique(Y_train.cpu()))\n",
    "model = Net(num_inputs, num_outputs).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_train, label=\"train\")\n",
    "plt.plot(loss_valid, label=\"valid\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.grid(ls='--')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy on the train set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_train_logit = model(X_train)\n",
    "    y_train = y_train_logit.argmax(dim=1)\n",
    "\n",
    "Y_train_cpu = Y_train.cpu()\n",
    "y_train_cpu = y_train.cpu()\n",
    "\n",
    "cm = pd.crosstab(\n",
    "    output_preproc.inverse_transform(\n",
    "        Y_train_cpu.reshape(-1, 1)).reshape(-1),\n",
    "    output_preproc.inverse_transform(\n",
    "        y_train_cpu.reshape(-1, 1)).reshape(-1),\n",
    "    rownames=['actual'],\n",
    "    colnames=['predicted']\n",
    ")\n",
    "print(cm)\n",
    "\n",
    "acc = accuracy_score(Y_train_cpu, y_train_cpu)\n",
    "print(\"Accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy on the validation set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_valid_logit = model(X_valid)\n",
    "    y_valid = y_valid_logit.argmax(dim=1)\n",
    "\n",
    "Y_valid_cpu = Y_valid.cpu()\n",
    "y_valid_cpu = y_valid.cpu()\n",
    "\n",
    "cm = pd.crosstab(\n",
    "    output_preproc.inverse_transform(\n",
    "        Y_valid_cpu.reshape(-1, 1)).reshape(-1),\n",
    "    output_preproc.inverse_transform(\n",
    "        y_valid_cpu.reshape(-1, 1)).reshape(-1),\n",
    "    rownames=['actual'],\n",
    "    colnames=['predicted']\n",
    ")\n",
    "print(cm)\n",
    "\n",
    "acc = accuracy_score(Y_valid_cpu, y_valid_cpu)\n",
    "print(\"Accuracy on valid = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yKvggbQIK_A2",
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Evaluation on the Test Set\n",
    "\n",
    "Once your final model is ready, you can evaluate it on the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_logit = model(X_test)\n",
    "    y_test = y_test_logit.argmax(dim=1)\n",
    "\n",
    "Y_test_cpu = Y_test.cpu()\n",
    "y_test_cpu = y_test.cpu()\n",
    "\n",
    "cm = pd.crosstab(\n",
    "    output_preproc.inverse_transform(\n",
    "        Y_test_cpu.reshape(-1, 1)).reshape(-1),\n",
    "    output_preproc.inverse_transform(\n",
    "        y_test_cpu.reshape(-1, 1)).reshape(-1),\n",
    "    rownames=['actual'],\n",
    "    colnames=['predicted']\n",
    ")\n",
    "print(cm)\n",
    "\n",
    "acc = accuracy_score(Y_test_cpu, y_test_cpu)\n",
    "print(\"Accuracy on test = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yKvggbQIK_A2",
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Classification using XGBoost\n",
    "\n",
    "Finally, just like in the regression notebook, since we are working with nice, structured, tabular data here, we are also going to fit an XGBoost model to our dataset for comparison. Chances are that the results will be on par with our neural model or even better at a fraction of the computational cost.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "wjbNKJWtK_EB",
    "outputId": "7f0faff4-d0df-44c5-acb0-e7a4e0780c77"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "X_train_np = X_train.cpu().numpy()\n",
    "Y_train_np = Y_train.cpu().numpy()\n",
    "X_test_np = X_test.cpu().numpy()\n",
    "Y_test_np = Y_test.cpu().numpy()\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train_np, Y_train_np);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NunRMYRK_EO"
   },
   "outputs": [],
   "source": [
    "y_test = model.predict(X_test_np)\n",
    "cm = pd.crosstab(Y_test_np.reshape(-1),\n",
    "                 y_test.reshape(-1),\n",
    "                 rownames=['actual'],\n",
    "                 colnames=['predicted'])\n",
    "print(cm)\n",
    "\n",
    "print(\"Accuracy on test: {}.\".format(accuracy_score(\n",
    "    Y_test_np, y_test\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "2_classification_regularization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "a351393365bb1b108989afa08de3243f72f5e58927baf5d192f3cca79a41cbc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
