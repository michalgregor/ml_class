{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4g3wFGqWktH",
    "tags": [
     "en"
    ]
   },
   "source": [
    "**NOTE: This notebook is written for the Google Colab platform. However it can also be run (possibly with minor modifications) as a standard Jupyter notebook.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 776
    },
    "colab_type": "code",
    "id": "v3edtGynYnV2",
    "outputId": "e408772e-a5c8-4ff2-9b42-dedb4ce69d79"
   },
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install umap-learn\n",
    "!{sys.executable} -m pip install git+https://github.com/michalgregor/class_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKGimae0aMhb"
   },
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from class_utils.plots import crosstab_plot\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Downloading Data -- { display-mode: \"form\" }\n",
    "DATA_HOME = \"https://github.com/michalgregor/ml_notebooks/blob/main/data/{}?raw=1\"\n",
    "\n",
    "from class_utils.download import download_file_maybe_extract\n",
    "download_file_maybe_extract(DATA_HOME.format(\"UCI%20HAR%20Dataset.zip\"), directory=\"data\")\n",
    "\n",
    "# also create a directory for storing any outputs\n",
    "import os\n",
    "os.makedirs(\"output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CJ4ficzmWktv",
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Dimensionality Reduction on the Human Activity Recognition Dataset\n",
    "\n",
    "In the next example, we are going to apply dimensionality reduction to the [Human Activitity Recognition dataset](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones). The data has been collected using smartphone sensors (accelerometer, gyroscope) and transformed into a number of different summary features such as the mean, standard deviation, IRQ, energy, entropy, etc.\n",
    "\n",
    "There are 6 different activities:\n",
    "\n",
    "* walking;\n",
    "* walking upstairs;\n",
    "* walking downstairs;\n",
    "* sitting;\n",
    "* standing;\n",
    "* laying.\n",
    "### Loading the Data\n",
    "\n",
    "The data is a series of numbers separated by spaces â€“ here is the beginning of the first line.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/UCI HAR Dataset/train/X_train.txt\", \"r\") as file:\n",
    "    firstline = file.readline()\n",
    "    print(firstline[:150], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CJ4ficzmWktv",
    "tags": [
     "en"
    ]
   },
   "source": [
    "Data in this format can be loaded easily using `np.loadtxt`. When loading the target labels, we subtract 1. The label indices start from 1 and we need to make them 0-based.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.loadtxt(\"data/UCI HAR Dataset/train/X_train.txt\")\n",
    "Y_train = np.loadtxt('data/UCI HAR Dataset/train/y_train.txt').astype(int) - 1\n",
    "\n",
    "X_test = np.loadtxt(\"data/UCI HAR Dataset/test/X_test.txt\")\n",
    "Y_test = np.loadtxt('data/UCI HAR Dataset/test/y_test.txt').astype(int) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CJ4ficzmWktv",
    "tags": [
     "en"
    ]
   },
   "source": [
    "To find out more about the dataset, we can have a look at the README.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/UCI HAR Dataset/README.txt\", 'r', errors=\"ignore\") as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CJ4ficzmWktv",
    "tags": [
     "en"
    ]
   },
   "source": [
    "One interesting thing that the README mentions is that the features are already normalized into the range of [-1, 1]. This is good because it allows us to drop the preprocessing step again.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE DO NOT NEED THIS BECAUSE ACCORDING TO THE DOCS, THE DATA IS ALREADY\n",
    "# NORMALIZED TO THE RANGE OF [-1, 1]\n",
    "\n",
    "# input_preproc = make_pipeline(\n",
    "#     SimpleImputer(),\n",
    "#     StandardScaler()\n",
    "# )\n",
    "\n",
    "# X_train_preproc = input_preproc.fit_transform(X_train.reshape(X_train.shape[0], -1))\n",
    "# X_train_preproc = X_train_preproc.reshape(X_train.shape)\n",
    "# X_train = X_train_preproc\n",
    "\n",
    "# X_test_preproc = input_preproc.transform(X_test.reshape(X_test.shape[0], -1))\n",
    "# X_test_preproc = X_test_preproc.reshape(X_test.shape)\n",
    "# X_test = X_test_preproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CJ4ficzmWktv",
    "tags": [
     "en"
    ]
   },
   "source": [
    "Finally we are going to get the list of class names from a file so that we can use it when analyzing the results later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = []\n",
    "\n",
    "with open(\"data/UCI HAR Dataset/activity_labels.txt\", 'r', errors=\"ignore\") as file:\n",
    "    for line in file:\n",
    "        class_names.append(line[2:-1])\n",
    "\n",
    "class_names = np.array(class_names)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gm_KpQHvWku9",
    "tags": [
     "en"
    ]
   },
   "source": [
    "---\n",
    "### Task 1: Apply PCA to the Dataset\n",
    "\n",
    "**In the cell below, apply PCA to the dataset (use `X_train` and `Y_train`) and plot the resulting points in 2D, coloured by class. Show the class names in the legend so that the plot is easy to interpret.** \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gm_KpQHvWku9",
    "tags": [
     "en"
    ]
   },
   "source": [
    "---\n",
    "### Task 2: Interpreting the PCA Plot\n",
    "\n",
    "**In the cell below, insert a qualitative description of what you can see in the PCA plot.** \n",
    "\n",
    "* What have you learned about the structure of the space?\n",
    "* Based on the plot, which classes do you think it would be easy for a shallow classifier to separate correctly?\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gm_KpQHvWku9",
    "tags": [
     "en"
    ]
   },
   "source": [
    "---\n",
    "### Task 3: Apply UMAP to the Dataset\n",
    "\n",
    "**In the cell below, apply UMAP to the dataset (use `X_train` and `Y_train`) and plot the resulting points in 2D, coloured by class. Show the class names in the legend so that the plot is easy to interpret.** \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "colab_type": "code",
    "id": "YLxu5YV8rWUA",
    "outputId": "6a558f7a-00da-4624-c894-44204e503510"
   },
   "outputs": [],
   "source": [
    "um = umap.UMAP(verbose=True)\n",
    "points_umap = um.fit_transform(X_train)\n",
    "\n",
    "perm_ind = np.random.permutation(points_umap.shape[0])\n",
    "xx = points_umap[perm_ind]\n",
    "yy = Y_train[perm_ind]\n",
    "xt = X_train[perm_ind]\n",
    "\n",
    "plt.figure(figsize=[10, 7])\n",
    "cmap = plt.cm.get_cmap('jet', len(class_names))\n",
    "plt.scatter(xx[:, 0], xx[:, 1], c=yy,\n",
    "            cmap=cmap,\n",
    "            rasterized=True)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_ticks(range(len(class_names)))\n",
    "cbar.set_ticklabels(class_names)\n",
    "plt.xlabel(\"dim 1\")\n",
    "plt.ylabel(\"dim 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gm_KpQHvWku9",
    "tags": [
     "en"
    ]
   },
   "source": [
    "---\n",
    "### Task 4: Interpreting the UMAP Plot\n",
    "\n",
    "**In the cell below, insert a qualitative description of what you can see in the UMAP plot.** \n",
    "\n",
    "* What does the structure of the space look like according to this plot?\n",
    "* Based on the plot, which classes do you think it would be easy for a shallow classifier to separate correctly?* How does your insight differ from what you learned from the PCA plot?\n",
    "* Why is there a difference?\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gm_KpQHvWku9",
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Training a Simple Classifier\n",
    "\n",
    "Next, we are going to train a simple classifier on the dataset to see whether any of the intuitions we gathered will be borne out.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, Y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gm_KpQHvWku9",
    "tags": [
     "en"
    ]
   },
   "source": [
    "Next, we are going to evaluate the model on the test set and especially plot the confusion matrix. What you should see is that it is easy to tell apart activities that involve a lot of movement from activities that are more static.\n",
    "\n",
    "Within these groups, results are more mixed. On the whole though, one can still get most of the samples right even with a super simple classifier without any hyperparameter tuning. Class \"laying\" seems to be especially easy to recognize.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = model.predict(X_test).astype(int)\n",
    "acc = accuracy_score(Y_test, y_test)\n",
    "print(\"Accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dataframe with Y_test and y_test\n",
    "df = pd.DataFrame({\"Y_test\": Y_test, \"y_test\": y_test})\n",
    "crosstab_plot(\"y_test\", \"Y_test\", data=df)\n",
    "plt.gca().set_xticklabels(class_names);\n",
    "plt.gca().set_yticklabels(reversed(class_names));\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "1_dimred.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a351393365bb1b108989afa08de3243f72f5e58927baf5d192f3cca79a41cbc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
