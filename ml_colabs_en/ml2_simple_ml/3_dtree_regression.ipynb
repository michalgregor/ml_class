{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**NOTE: This notebook is written for the Google Colab platform. However it can also be run (possibly with minor modifications) as a standard Jupyter notebook.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install git+https://github.com/michalgregor/class_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, KBinsDiscretizer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from class_utils import error_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Downloading Data -- { display-mode: \"form\" }\n",
    "DATA_HOME = \"https://github.com/michalgregor/ml_notebooks/blob/main/data/{}?raw=1\"\n",
    "\n",
    "from class_utils.download import download_file_maybe_extract\n",
    "download_file_maybe_extract(DATA_HOME.format(\"sigmoid_regression_data.csv\"), directory=\"data\")\n",
    "\n",
    "# also create a directory for storing any outputs\n",
    "import os\n",
    "os.makedirs(\"output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Decision Trees for Regression\n",
    "\n",
    "Decision trees can be applied to both: classification and regression. We will now show a very straight-forward example of how to apply them to regression. The dataset that we will be using is 2-dimensional, which will enable us to plot it easily and to examine the regression curve visually. The code to load and preprocess the data follows in the next cell and is hidden for the sake of brevity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Loading and Preprocessing the Data: X_train, Y_train, X_test, Y_test -- { display-mode: \"form\" }\n",
    "df = pd.read_csv(\"data/sigmoid_regression_data.csv\")\n",
    "\n",
    "kbins = KBinsDiscretizer(6, encode='ordinal')\n",
    "y_stratify = kbins.fit_transform(df[['y']])\n",
    "\n",
    "df_train, df_test = train_test_split(\n",
    "    df, stratify=y_stratify, test_size=0.3, random_state=4)\n",
    "\n",
    "plt.scatter(df_train['x'], df_train['y'], marker='x', label=\"training data\")\n",
    "plt.scatter(df_test['x'], df_test['y'], c='r', label=\"testing data\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(ls='--')\n",
    "plt.legend()\n",
    "\n",
    "categorical_inputs = []\n",
    "numeric_inputs = ['x']\n",
    "output = 'y'\n",
    "\n",
    "input_preproc = make_column_transformer(\n",
    "    (make_pipeline(\n",
    "        SimpleImputer(strategy=\"most_frequent\"),\n",
    "        OrdinalEncoder()),\n",
    "     categorical_inputs),\n",
    "    \n",
    "    (make_pipeline(\n",
    "        SimpleImputer(),\n",
    "        StandardScaler()),\n",
    "     numeric_inputs)\n",
    ")\n",
    "\n",
    "X_train = input_preproc.fit_transform(df_train[categorical_inputs+numeric_inputs])\n",
    "Y_train = df_train[output].values\n",
    "\n",
    "X_test = input_preproc.transform(df_test[categorical_inputs+numeric_inputs])\n",
    "Y_test = df_test[output].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Creating and Training the Regressor\n",
    "\n",
    "To create the regressor, we merely need to instantiate class `DecisionTreeRegressor`. We will be using the default parameters so we do not need to specify anything at this stage. The training will be done using the standard `fit` interface.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Testing\n",
    "\n",
    "The testing will be done by measuring the mean square error (MSE) and the mean absolute error (MAE) of our model on the test set. We will also display the error histogram to get a better idea of how the errors are distributed and what their scale is w.r.t. the original data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Testing -- { display-mode: \"form\" }\n",
    "y_test = model.predict(X_test)\n",
    "\n",
    "# we compute and display the MSE and the MAE\n",
    "mse = mean_squared_error(Y_test, y_test)\n",
    "print(\"MSE = {}\".format(mse))\n",
    "\n",
    "mae = mean_absolute_error(Y_test, y_test)\n",
    "print(\"MAE = {}\".format(mae))\n",
    "\n",
    "# we display the error histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_test, y_test, Y_fit_scaling=Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "The results should quite good: the errors should be negligible compared to the scale of the data.\n",
    "\n",
    "### Visualizing the Regression Curve\n",
    "\n",
    "When we visualize the regression curve, we will notice that it is not smooth, but rather piece-wise constant. This is because each leaf of the tree corresponds to a certain area of the input space and it predicts a single constant value. Consequently the input area will be divided into discrete areas with various constant outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Regression Curve vs. Data -- { display-mode: \"form\" }\n",
    "x_min = min(np.min(X_train), np.min(X_test))\n",
    "x_max = max(np.max(X_train), np.max(X_test))\n",
    "\n",
    "xx = np.linspace(x_min, x_max, 250).reshape((-1, 1)).astype(np.float32)\n",
    "yy = model.predict(xx)\n",
    "\n",
    "plt.scatter(X_train, Y_train, marker='x', label=\"training data\")\n",
    "plt.scatter(X_test, Y_test, c='r', label=\"testing data\")\n",
    "\n",
    "plt.plot(xx, yy, label=\"regression curve\", c='k')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(ls='--')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
