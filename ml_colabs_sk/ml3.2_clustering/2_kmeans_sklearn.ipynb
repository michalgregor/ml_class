{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "**POZNÁMKA: Tento notebook je určený pre platformu Google Colab. Je však možné ho spustiť (možno s drobnými úpravami) aj ako štandardný Jupyter notebook.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install yellowbrick\n",
    "!{sys.executable} -m pip install git+https://github.com/michalgregor/class_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "from class_utils import ColGrid, sorted_order, show_tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from yellowbrick.contrib.classifier import DecisionViz\n",
    "from yellowbrick.cluster import SilhouetteVisualizer, KElbowVisualizer\n",
    "# revert yellowbrick's invasive changes to matplotlib's\n",
    "# styling; also suppressing deprecation warnings\n",
    "import warnings\n",
    "import yellowbrick\n",
    "\n",
    "with warnings.catch_warnings(record=True) as w:\n",
    "    yellowbrick.style.rcmod.set_aesthetic('reset')\n",
    "    yellowbrick.style.rcmod.reset_orig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Downloading Data -- { display-mode: \"form\" }\n",
    "\n",
    "# create a directory for storing any outputs\n",
    "import os\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# create a synthetic dataset\n",
    "_blobs, _labels = datasets.make_blobs(\n",
    "    n_samples=600, random_state=3,\n",
    "    cluster_std=0.75, centers=5\n",
    ")\n",
    "\n",
    "_df_blobs = pd.DataFrame(np.hstack([_blobs, _labels.reshape(-1, 1)]),\n",
    "                         columns=['x', 'y', 'label'])\n",
    "_df_blobs['y'] *= 100\n",
    "_df_blobs.to_csv(\"data/blobs_2d.csv\", index=False)\n",
    "\n",
    "del _blobs\n",
    "del _labels\n",
    "del _df_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Auxiliary Functions -- { display-mode: \"form\" }\n",
    "cluster_colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k', 'gray']\n",
    "\n",
    "def scatter_legend(ax, sc, labels, num_colors, color_array,\n",
    "                   s, edgecolor):\n",
    "    handles = []\n",
    "    \n",
    "    for i in range(num_colors):\n",
    "        h = mlines.Line2D([0], [0], ls=\"\", color=color_array[i],\n",
    "                          ms=s, marker=sc.get_paths()[0],\n",
    "                          markeredgecolor=edgecolor)\n",
    "        handles.append(h)\n",
    "\n",
    "    ax.legend(handles=handles, labels=labels)\n",
    "\n",
    "def plot_data(\n",
    "    data, cluster_centres=None, color='b', ax=None,\n",
    "    cluster_colors=cluster_colors,\n",
    "    edgecolors='k', labels=None,\n",
    "    center_color='orange', center_size=200,\n",
    "    legend=True\n",
    "):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    if labels is None:\n",
    "        ax.scatter(data[:, 0], data[:, 1], s=50,\n",
    "                   color=color, edgecolors=edgecolors)\n",
    "    else:\n",
    "        c = np.asarray(cluster_colors)[labels]\n",
    "        \n",
    "        sc = ax.scatter(data[:, 0], data[:, 1], s=50,\n",
    "                        c=c, edgecolors=edgecolors,\n",
    "                        #cmap=plt.cm.get_cmap('category10', np.max(labels)+1)\n",
    "                       )\n",
    "        \n",
    "        if legend:\n",
    "            nclusts = np.max(labels)+1\n",
    "            scatter_legend(ax, sc, ['$c_{}$'.format(i) for i in range(nclusts)],\n",
    "                           nclusts, cluster_colors, s=6, edgecolor='k')\n",
    "        \n",
    "    if not cluster_centres is None:\n",
    "        ax.scatter(cluster_centres[:, 0],\n",
    "                   cluster_centres[:, 1],\n",
    "            s=center_size, c=center_color,\n",
    "            edgecolors=edgecolors)\n",
    "\n",
    "    ax.grid(ls='--')\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_axisbelow(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "## k-means v balíčku Scikit-Learn\n",
    "\n",
    "Teraz keď sme preskúmali princípy na ktorých je založený algoritmus $k$-means, pozrieme sa aj na jeho praktickú implementáciu zo známeho balíčka `scikit-learn`. Okrem ilustrácie ako $k$-means aplikovať na dátovú množinu, sa pozrieme aj na niektoré techniky vizualizácie umožňujúce preskúmať určité vlastnosti zhlukov a dokonca pomôcť zvoliť vhodný počet zhlukov $k$.\n",
    "\n",
    "### Predspracovanie: nezabudnite normalizovať dáta\n",
    "\n",
    "Na načítanie a predspracovanie dát použijeme náš štandardný pipeline, ktorý **normalizuje**  (štandardizuje) numerické stĺpce. Keďže je algoritmus $k$-means založený na vzdialenostiach, správne škálovanie je kľúčové a **nemali by sme zabudnúť dáta normalizovať** . Ak bude obor rozsah niektorého stĺpca omnoho väčší než u iných stĺpcov a normalizáciu neaplikujeme, daný stĺpec bude mať na výsledky zhlukovania podstatne väčší vplyv než zvyšné stĺpce. To typicky nie je žiaduce.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the data from the CSV\n",
    "df = pd.read_csv(\"data/blobs_2d.csv\")\n",
    "\n",
    "# all inputs are numeric\n",
    "categorical_inputs = []\n",
    "numeric_inputs = list(df.columns[:-1])\n",
    "\n",
    "# the preprocessing pipeline\n",
    "input_preproc = make_column_transformer(\n",
    "    (make_pipeline(\n",
    "        SimpleImputer(strategy='constant', fill_value='MISSING'),\n",
    "        OneHotEncoder()),\n",
    "     categorical_inputs),\n",
    "    \n",
    "    (make_pipeline(\n",
    "        SimpleImputer(),\n",
    "        StandardScaler()),\n",
    "     numeric_inputs)\n",
    ")\n",
    "\n",
    "# the preprocessed data and the classes\n",
    "X = input_preproc.fit_transform(df[categorical_inputs+numeric_inputs])\n",
    "labels = df[\"label\"]\n",
    "\n",
    "# let's also keep the unnormalized data\n",
    "X_unnorm = df[categorical_inputs+numeric_inputs].values\n",
    "\n",
    "# plot the data\n",
    "plt.figure(figsize=(6, 5))\n",
    "plot_data(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Zhlukovanie\n",
    "\n",
    "Keď už máme pripravené dáta, aplikovať zhlukovanie je veľmi ľahké. Jediné, čo treba spraviť, je vytvoriť objekt triedy `KMeans` z balíčka `scikit-learn` a špecifikovať počet zhlukov na $k=5$. Následne model naladíme na dáta pomocou štandardného rozhrania `fit`. Všimnite si, že teraz realizujeme nekontrolované učenie, takže nepracujeme s vektorom požadovaných výstupov `y`. Metóda  `predict` navracia identifikátory zhlukov.\n",
    "\n",
    "Keď sme vykonali zhlukovanie, znovu si zobrazíme dátovú množinu: tento raz zafarbíme body podľa vypočítaných identifikátorov zhlukov. To nám umožní overiť či zhlukovanie prebehlo správne.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=5)\n",
    "model.fit(X)\n",
    "clusts = model.predict(X)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plot_data(X, labels=clusts, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "#### Zhlukovanie s nenormalizovanými dátami\n",
    "\n",
    "Aby sme sa presvedčili prečo je normalizácia dát taká potrebná, aplikujeme si teraz zhklukovanie aj na nenormalizovanú verziu dátovej množiny.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=5)\n",
    "model.fit(X_unnorm)\n",
    "clusts = model.predict(X_unnorm)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plot_data(X_unnorm, labels=clusts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Ako vidno, niektoré zhluky tento raz neboli identifikované celkom správne. Deje sa to preto, lebo rozmer $y$ má teraz omnoho väčší rozsah a prikladá sa mu preto väčšia váha.\n",
    "\n",
    "### Určenie počtu zhlukov $k$\n",
    "\n",
    "Vo vyššie uvedenom príklade sme predpokladali, že správny počet zhlukov $k$ poznáme. V praxi to je pravda málokedy: ibaže by sme vopred presne vedeli, čo hľadáme. Ako teda určiť dobrú hodnotu $k$? V skutočnosti na to existuje hneď niekoľko metód.\n",
    "\n",
    "#### Elbow graf\n",
    "\n",
    "Jedným zo spôsobov ako určiť dobrú hodnotu $k$ je použiť elbow graf (lakťový graf). Jeho myšlienka spočíva v tom, že sa $k$-means spustí viackrát s rôznymi hodnotami $k$, vypočíta sa pre každý prípad skreslenie (distortion score) a výsledky sa vizualizujú. V grafe potom hľadáme \"lakeť\" (elbow), t.j. bod s maximálnym zakrivením – kde sa najprudšie mení strmosť grafu. Na vytvorenie grafu použijeme balíček `yellowbrick`, ktorý vie elbow bod nájsť a vizualizovať automaticky pomocou knee point detection algoritmu [[yellowbrick]](#yellowbrick).\n",
    "\n",
    "Skreslenie sa počíta ako súčet kvadratických chýb (sum of squared errors; SSE), t.j. súčet euklidovských vzdialeností medzi bodmi a zodpovedajúcimi stredmi zhlukov [[yellowbrick](#yellowbrick), [k_research](#k_research)]:\n",
    "$$\n",
    "J(C) = \\sum*{j=1}^{k} \\sum* {x_i \\in c_j} | x_i - \\mu_j |^2.\n",
    "$$\n",
    "\n",
    "Všimnite si, že ide o to isté kritérium, ktoré sa snaží minimalizovať algoritmus $k$-means. Tiež vezmite do úvahy, že nie je možné jednoducho vybrať také $k$ , ktoré bude skreslenie minimalizovať: to by znamenalo vytvoriť toľko zhlukov, koľko je bodov v dátovej množine: potom by sa skreslenie znížilo na nulu, ale výsledkom by nebolo kvalitné zhlukovanie. Intuícia za výberom elbow bodu spočíva v tom, že keď dosiahneme správnu hodnotu $k$, skreslenie by sa malo prudko znížiť, lebo relatívne blízko ku každému bodu by mal existovať nejaký stred zhluku. Pridávanie ďalších zhlukov by však uť nemalo mať veľký efekt: bude len deliť už dobre definované zhluky na menšie časti.\n",
    "\n",
    "Elbow graf sa dá vytvoriť aj pomocou iných kritérií, napr. pomocou Calinski-Harabasz indexu alebo pomocou Silhoutte skóre  [[yellowbrick](#yellowbrick), [ch_index](#ch_index)]: pokojne experimentujte aj s týmito možnosťami. Silhoutte skóre budeme ešte používať aj v neskoršej časti notebook-u v rámci Silhoutte analýzy. \n",
    "\n",
    "#### Elbow graf: príklad\n",
    "\n",
    "Použime teraz elbow graf na určenie najlepšieho $k$ pre našu dátovú množinu. Použijeme triedu `KElbowVisualizer` z balíčka `yellowbrick` a vyskúšame $k \\in \\{2, 3, ..., 9\\}$. Keďže už vieme, že korektný počet zhlukov je v našom prípade  5, mali by sme vidieť, že lakeť grafu je na $k=5$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = KElbowVisualizer(model, k=(2, 10), timings=False)\n",
    "visualizer.fit(X)\n",
    "visualizer.ax.grid(ls='--')\n",
    "visualizer.finalize()\n",
    "\n",
    "plt.savefig(\"output/kmeans_elbow.svg\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Silhouette analýza\n",
    "\n",
    "Silhouette analýza predstavuje ďalší spôsob ako zvoliť vhodnú hodnotu $k$. Poskytuje ale tiež spôsob ako pre každé $k$ vizualizovať niektoré kľúčové vlastnosti zhlukov. Prístup je založený na Silhoutte koeficiente, ktorý je definovaný takto [[k_research]](#k_research):\n",
    "$$\n",
    "s(x_i) = \\frac{\n",
    "    b_i - a_i\n",
    "}{\n",
    "    \\max{ a_i, b_i }\n",
    "},\n",
    "$$\n",
    "\n",
    "kde $a_i$ je **vnútrozhluková rozličnosť**  (intra-cluster dissimilarity), t.j. priemerná vzdialenosť vzorky $x_i$ od všetkých ostatných vzoriek z toho istého zhluku; a $b_i$ je **medzizhluková rozličnosť**  (inter-cluster dissimilarity), t.j. najkratšia \n",
    "vzdialenosť ku vzorke z iného zhluku. Čím nižšia je vnútrozhluková rozličnosť $a_i$, tým viac by mal bod $x_i$ patriť do daného zhluku. Čím väčšia je medzizhluková rozličnosť $b_i$, tým menej by mala vzorka $x_i$ patriť do hociktorého iného zhluku [[k_research]](#k_research).\n",
    "\n",
    "**Silhouette skóre**  je priemer Silhouette koeficientov naprieč všetkými vzorkami $x_i \\in X$:\n",
    "$$\n",
    "S = \\frac{\\sum_{x_i \\in X} s(x_i)}{|X|},\n",
    "$$\n",
    "kde $X$ je dátová množina a $|X|$ je počet vzoriek v nej (jej kardinalita).\n",
    "\n",
    "Čím vyššie je Silhouette skóre, do tým väčšej miery by mali v priemere body patriť do svojich zhlukov a nie do hociktorých iných zhlukov. Môžeme si preto zobraziť Silhouette skóre pre viacero hodnôt $k$ a zvoliť $k$ s najvyšším skóre. Na vytvorenie grafu znovu použijeme `KElbowVisualizer`, tento raz však špecifikujeme ako metriku `silhouette`. Je zrejmé, že najvyššiu hodnotu nadobúda pre $k=5$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = KElbowVisualizer(model, k=(3, 8),\n",
    "                              metric='silhouette',\n",
    "                              timings=False)\n",
    "visualizer.fit(X)\n",
    "visualizer.ax.grid(ls='--')\n",
    "visualizer.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Na Silhouette analýze je však skvelé, že poskytuje aj spôsob ako vizualizovať kľúčové vlastnosti všetkých jednotlivých zhlukov. Pre všetky body sa vypočítajú Silhouette koeficienty, zoskupia sa podľa zhlukov, zoradia sa podľa veľkosti a vykreslia sa.\n",
    "\n",
    "Výsledné grafy indikujú aké veľké sú jednotlivé zhluky a s akou mierou istoty by mal každý jednotlivý bod patriť do daného zhluku a nie do iných zhlukov: body z nižšími Silhouette koeficientami sú pravdepodobne na okraji zhluku a body s veľmi nízkymi koeficientmi môžu byť priradené k nesprávnym zhlukom.\n",
    "\n",
    "V nasledujúcich grafoch zobrazujeme vedľa seba Silhouette grafy a bodové grafy, aby sa dali ľahšie vykonať porovnania. Pamätajte však, že v praxi, pri práci s vysokorozmernými dátovými množinami by ste, samozrejme, mali k dispozícii len Silhouette grafy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(3, 8)\n",
    "fig, axes = plt.subplots(len(k_range), 2)\n",
    "\n",
    "for k, ax in zip(k_range, axes):\n",
    "    model = KMeans(n_clusters=k)\n",
    "    \n",
    "    visualizer = SilhouetteVisualizer(\n",
    "        model, colors=cluster_colors,\n",
    "        alpha=1.0, ax=ax[0])\n",
    "    visualizer.fit(X)\n",
    "    visualizer.ax.grid(ls='--')\n",
    "    visualizer.finalize()\n",
    "    \n",
    "    clusts = model.predict(X)\n",
    "    plot_data(X, labels=clusts, ax=ax[1])\n",
    "\n",
    "fig.set_size_inches([10, len(k_range)*3])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Všimnite si veľmi nízke Silhouette koeficienty niektorých bodov, ktoré indikujú, že pravdepodobne nie sú priradené do správneho zhluku. Pri $k=5$ sa žiadne body s veľmi nízkymi koeficientmi nevyskytujú, čo indikuje, že ide o omnoho kvalitnejšie zhlukovanie. Všimnite si tiež, že pomocou týchto grafov vieme vizuálne porovnať veľkosti zhlukov.\n",
    "\n",
    "### Interpretácia zhlukov\n",
    "\n",
    "Nájsť v rámci dátovej analýzy zhluky je väčšinou tá ľahšia časť úlohy: ťažšie ich býva interpretovať. Sada nástrojov potrebných na interpretáciu zhlukov je však v podstate tá istá, ktorá sa používa pri exploratívnej analýze dát. Identifikátory zhlukov môžeme do dátovej množiny pridať ako ďalší stĺpec a následne preskúmať jeho interakcie s inými stĺpcami, tie, ktoré korelujú, si zobraziť podrobnejšie atď.\n",
    "\n",
    "#### Husličkové grafy\n",
    "\n",
    "V našom prípade by mohli byť užitočné husličkové grafy: povedia nám akým rozsahom $x$ a $y$ každý zhluk približne zodpovedá. Aby sme uľahčili porovnanie, prikladáme znovu aj bodový graf.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=5)\n",
    "model.fit(X)\n",
    "clusts = model.predict(X)\n",
    "\n",
    "# add the cluster identifiers as a new column to the dataset\n",
    "df['cluster'] = clusts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ColGrid(df, ['cluster'], ['x', 'y'])\n",
    "fig, axes = g.map_dataframe(sorted_order(sns.violinplot),\n",
    "                  palette=cluster_colors)\n",
    "fig.set_size_inches((10, 4))\n",
    "\n",
    "for ax in axes:\n",
    "    ax.grid(ls='--')\n",
    "    ax.set_axisbelow(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(X_unnorm, labels=clusts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "#### Rozhodovací strom\n",
    "\n",
    "Ďalšou možnosťou je natrénovať si na dátach malý rozhodovací strom a pozrieť sa, aké pravidlá objavil.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_unnorm, clusts)\n",
    "show_tree(dtree, numeric_inputs, filled=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Aby sa dalo ľahšie skontrolovať či strom správne identifikoval hranice zhlukov, môžeme si v našom prípade zobraziť aj rozhodovacie hranice vzhľadom na $x$ a $y$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = DecisionViz(\n",
    "    dtree, features=numeric_inputs,\n",
    "    classes=['$c_{}$'.format(i) for i in range(np.max(clusts)+1)]\n",
    ")\n",
    "\n",
    "viz.fit(X_unnorm, clusts)\n",
    "viz.draw(X_unnorm, clusts)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "<a id=\"k_research\">[k_research]</a> Yuan, C. and Yang, H., 2019. Research on K-value selection method of K-means clustering algorithm. J—Multidisciplinary Scientific Journal, 2(2), pp.226-235.\n",
    "\n",
    "<a id=\"ch_index\">[ch_index]</a> Wang, X. and Xu, Y., 2019, July. An improved index for clustering validation based on Silhouette index and Calinski-Harabasz index. In IOP Conference Series: Materials Science and Engineering (Vol. 569, No. 5, p. 052024). IOP Publishing.\n",
    "\n",
    "<a id=\"yellowbrick\">[yellowbrick]</a> Yellowbrick. URL: <https://github.com/DistrictDataLabs/yellowbrick>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a351393365bb1b108989afa08de3243f72f5e58927baf5d192f3cca79a41cbc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
