{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4HJy3BTaXtsB",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "**POZNÁMKA: Tento notebook je určený pre platformu Google Colab, ktorá zdarma poskytuje hardvérovú akceleráciu. Je však možné ho spustiť (možno s drobnými úpravami) aj ako štandardný Jupyter notebook, pomocou lokálnej grafickej karty.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vt9sKp4g5vQC",
    "outputId": "5345464f-1956-45b0-eda8-e5d07e65630d"
   },
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install captum\n",
    "!{sys.executable} -m pip install git+https://github.com/michalgregor/class_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3E0t0wPS5vRa"
   },
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "\n",
    "from captum.attr import IntegratedGradients, Saliency, GuidedBackprop\n",
    "from captum.attr import GradientShap\n",
    "from captum.attr import Occlusion\n",
    "from captum.attr import visualization as viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KdwWHj8V5vQo"
   },
   "outputs": [],
   "source": [
    "#@title -- Downloading Data -- { display-mode: \"form\" }\n",
    "from class_utils.download import download_file_maybe_extract, download_files_maybe_extract\n",
    "DATA_HOME = \"https://github.com/michalgregor/ml_notebooks/blob/main/data/{}?raw=1\"\n",
    "\n",
    "download_files_maybe_extract([\n",
    "    DATA_HOME.format(\"imagenet_classes\"),\n",
    "    DATA_HOME.format(\"images/toucan.png\"),\n",
    "    DATA_HOME.format(\"images/raccoon_example.jpg\"),\n",
    "    DATA_HOME.format(\"images/nails.jpg\"),\n",
    "    DATA_HOME.format(\"images/screws.jpg\"),\n",
    "    DATA_HOME.format(\"images/ambulance.jpg\")\n",
    "], directory=\"data\")\n",
    "\n",
    "# also create a directory for storing any outputs\n",
    "import os\n",
    "os.makedirs(\"output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aU2ZTD0Q5vR6"
   },
   "outputs": [],
   "source": [
    "#@title -- Auxiliary Functions -- { display-mode: \"form\" }\n",
    "with open(\"data/imagenet_classes\", \"r\") as file:\n",
    "    class_names = [c[:-1] for c in file.readlines()]\n",
    "\n",
    "def resize_image(img, size=224):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(size)\n",
    "    ])\n",
    "    return np.asarray(transform(img))\n",
    "\n",
    "def decode_proba(proba, top=5, verbose=True):\n",
    "    with torch.no_grad():\n",
    "        probs, classes = torch.topk(proba, 5)\n",
    "        probs = probs[0]\n",
    "        classes = classes[0]\n",
    "\n",
    "    if verbose:\n",
    "        for p, c in zip(probs.cpu().numpy(),\n",
    "                        classes.cpu().numpy()):\n",
    "            print(\"{}:\\t{} ({})\".format(\n",
    "                np.array2string(p, precision=5),\n",
    "                class_names[c], c))\n",
    "            \n",
    "    return probs, classes\n",
    "\n",
    "vis_kwargs_default = dict(\n",
    "    methods=['original_image', 'alpha_scaling', 'heat_map'],\n",
    "    cmap=\"viridis\",\n",
    "    show_colorbar=True,\n",
    "    signs=['all', 'absolute_value', 'absolute_value'],\n",
    "    fig_size=(12.5, 4)\n",
    ")\n",
    "\n",
    "class ProcImage:\n",
    "    def __init__(self, model, weights, device, verbose=True):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.verbose = verbose\n",
    "\n",
    "        weight_transforms = weights.transforms()\n",
    "        self.normalize = transforms.Normalize(\n",
    "            mean=weight_transforms.mean,\n",
    "            std=weight_transforms.std\n",
    "        )\n",
    "\n",
    "    def preproc_image(self, img, size=224):\n",
    "        if not isinstance(img, Image.Image):\n",
    "            img = torchvision.transforms.functional.to_pil_image(img)\n",
    "\n",
    "        img = img.convert('RGB')\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(size),\n",
    "            transforms.ToTensor(),\n",
    "            self.normalize\n",
    "        ])\n",
    "\n",
    "        tensor = transform(img).unsqueeze(0)\n",
    "        return tensor\n",
    "\n",
    "    def __call__(self, img_path):\n",
    "        img = Image.open(img_path)\n",
    "        img_preproc = self.preproc_image(img)\n",
    "        img_resized = resize_image(img)\n",
    "        \n",
    "        if not self.device is None:\n",
    "            img_preproc = img_preproc.to(self.device)\n",
    "            self.model.to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "        img_preproc.requires_grad = True\n",
    "        \n",
    "        output = torch.nn.functional.softmax(self.model(img_preproc), dim=1)\n",
    "        pred_class = decode_proba(output, verbose=True)[1][0]\n",
    "\n",
    "        return img_preproc, img_resized, pred_class\n",
    "\n",
    "def visualize_attrib(attrib, **kwargs):\n",
    "    kwargs_merged = dict(**vis_kwargs_default)\n",
    "    kwargs_merged.update(kwargs)\n",
    "    attrib = np.transpose(attrib.squeeze().cpu().detach().numpy(), (1,2,0))\n",
    "\n",
    "    # workaround for a matplotlib-related bug in captum\n",
    "    visualize_image_attr_multiple(attrib, img_resized, **kwargs_merged)\n",
    "    #viz.visualize_image_attr_multiple(attrib, img_resized, **kwargs_merged)\n",
    "\n",
    "# workaround for a matplotlib-related bug in captum\n",
    "\n",
    "from matplotlib.figure import Figure\n",
    "from captum.attr._utils.visualization import (\n",
    "    _prepare_image, ImageVisualizationMethod, _normalize_attr,\n",
    "    VisualizeSign, make_axes_locatable, LinearSegmentedColormap\n",
    ")\n",
    "\n",
    "def visualize_image_attr(\n",
    "    attr, original_image=None, method=\"heat_map\", sign=\"absolute_value\",\n",
    "    plt_fig_axis=None, outlier_perc=2, cmap=None, alpha_overlay=0.5,\n",
    "    show_colorbar=False, title=None, fig_size=(6, 6), use_pyplot=True\n",
    "):\n",
    "    # Create plot if figure, axis not provided\n",
    "    if plt_fig_axis is not None:\n",
    "        plt_fig, plt_axis = plt_fig_axis\n",
    "    else:\n",
    "        if use_pyplot:\n",
    "            plt_fig, plt_axis = plt.subplots(figsize=fig_size)\n",
    "        else:\n",
    "            plt_fig = Figure(figsize=fig_size)\n",
    "            plt_axis = plt_fig.subplots()\n",
    "\n",
    "    if original_image is not None:\n",
    "        if np.max(original_image) <= 1.0:\n",
    "            original_image = _prepare_image(original_image * 255)\n",
    "    elif ImageVisualizationMethod[method] != ImageVisualizationMethod.heat_map:\n",
    "        raise ValueError(\n",
    "            \"Original Image must be provided for\"\n",
    "            \"any visualization other than heatmap.\"\n",
    "        )\n",
    "\n",
    "    # Remove ticks and tick labels from plot.\n",
    "    plt_axis.xaxis.set_ticks_position(\"none\")\n",
    "    plt_axis.yaxis.set_ticks_position(\"none\")\n",
    "    plt_axis.set_yticklabels([])\n",
    "    plt_axis.set_xticklabels([])\n",
    "    plt_axis.grid(visible=False)\n",
    "\n",
    "    heat_map = None\n",
    "    # Show original image\n",
    "    if ImageVisualizationMethod[method] == ImageVisualizationMethod.original_image:\n",
    "        assert (\n",
    "            original_image is not None\n",
    "        ), \"Original image expected for original_image method.\"\n",
    "        if len(original_image.shape) > 2 and original_image.shape[2] == 1:\n",
    "            original_image = np.squeeze(original_image, axis=2)\n",
    "        plt_axis.imshow(original_image)\n",
    "    else:\n",
    "        # Choose appropriate signed attributions and normalize.\n",
    "        norm_attr = _normalize_attr(attr, sign, outlier_perc, reduction_axis=2)\n",
    "\n",
    "        # Set default colormap and bounds based on sign.\n",
    "        if VisualizeSign[sign] == VisualizeSign.all:\n",
    "            default_cmap = LinearSegmentedColormap.from_list(\n",
    "                \"RdWhGn\", [\"red\", \"white\", \"green\"]\n",
    "            )\n",
    "            vmin, vmax = -1, 1\n",
    "        elif VisualizeSign[sign] == VisualizeSign.positive:\n",
    "            default_cmap = \"Greens\"\n",
    "            vmin, vmax = 0, 1\n",
    "        elif VisualizeSign[sign] == VisualizeSign.negative:\n",
    "            default_cmap = \"Reds\"\n",
    "            vmin, vmax = 0, 1\n",
    "        elif VisualizeSign[sign] == VisualizeSign.absolute_value:\n",
    "            default_cmap = \"Blues\"\n",
    "            vmin, vmax = 0, 1\n",
    "        else:\n",
    "            raise AssertionError(\"Visualize Sign type is not valid.\")\n",
    "        cmap = cmap if cmap is not None else default_cmap\n",
    "\n",
    "        # Show appropriate image visualization.\n",
    "        if ImageVisualizationMethod[method] == ImageVisualizationMethod.heat_map:\n",
    "            heat_map = plt_axis.imshow(norm_attr, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        elif (\n",
    "            ImageVisualizationMethod[method]\n",
    "            == ImageVisualizationMethod.blended_heat_map\n",
    "        ):\n",
    "            assert (\n",
    "                original_image is not None\n",
    "            ), \"Original Image expected for blended_heat_map method.\"\n",
    "            plt_axis.imshow(np.mean(original_image, axis=2), cmap=\"gray\")\n",
    "            heat_map = plt_axis.imshow(\n",
    "                norm_attr, cmap=cmap, vmin=vmin, vmax=vmax, alpha=alpha_overlay\n",
    "            )\n",
    "        elif ImageVisualizationMethod[method] == ImageVisualizationMethod.masked_image:\n",
    "            assert VisualizeSign[sign] != VisualizeSign.all, (\n",
    "                \"Cannot display masked image with both positive and negative \"\n",
    "                \"attributions, choose a different sign option.\"\n",
    "            )\n",
    "            plt_axis.imshow(\n",
    "                _prepare_image(original_image * np.expand_dims(norm_attr, 2))\n",
    "            )\n",
    "        elif ImageVisualizationMethod[method] == ImageVisualizationMethod.alpha_scaling:\n",
    "            assert VisualizeSign[sign] != VisualizeSign.all, (\n",
    "                \"Cannot display alpha scaling with both positive and negative \"\n",
    "                \"attributions, choose a different sign option.\"\n",
    "            )\n",
    "            \n",
    "            original_image = original_image[..., :3]\n",
    "            plt_axis.imshow(\n",
    "                np.concatenate(\n",
    "                    [\n",
    "                        original_image,\n",
    "                        _prepare_image(np.expand_dims(norm_attr, 2) * 255),\n",
    "                    ],\n",
    "                    axis=2,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            raise AssertionError(\"Visualize Method type is not valid.\")\n",
    "\n",
    "    # Add colorbar. If given method is not a heatmap and no colormap is relevant,\n",
    "    # then a colormap axis is created and hidden. This is necessary for appropriate\n",
    "    # alignment when visualizing multiple plots, some with heatmaps and some\n",
    "    # without.\n",
    "    if show_colorbar:\n",
    "        axis_separator = make_axes_locatable(plt_axis)\n",
    "        colorbar_axis = axis_separator.append_axes(\"bottom\", size=\"5%\", pad=0.1)\n",
    "        if heat_map:\n",
    "            plt_fig.colorbar(heat_map, orientation=\"horizontal\", cax=colorbar_axis)\n",
    "        else:\n",
    "            colorbar_axis.axis(\"off\")\n",
    "    if title:\n",
    "        plt_axis.set_title(title)\n",
    "\n",
    "    if use_pyplot:\n",
    "        plt.show()\n",
    "\n",
    "    return plt_fig, plt_axis\n",
    "\n",
    "\n",
    "def visualize_image_attr_multiple(\n",
    "    attr, original_image, methods, signs, titles=None,\n",
    "    fig_size=(8, 6), use_pyplot=True, **kwargs\n",
    "):\n",
    "    assert len(methods) == len(signs), \"Methods and signs array lengths must match.\"\n",
    "    if titles is not None:\n",
    "        assert len(methods) == len(titles), (\n",
    "            \"If titles list is given, length must \" \"match that of methods list.\"\n",
    "        )\n",
    "    if use_pyplot:\n",
    "        plt_fig = plt.figure(figsize=fig_size)\n",
    "    else:\n",
    "        plt_fig = Figure(figsize=fig_size)\n",
    "    plt_axis = plt_fig.subplots(1, len(methods))\n",
    "\n",
    "    # When visualizing one\n",
    "    if len(methods) == 1:\n",
    "        plt_axis = [plt_axis]\n",
    "\n",
    "    for i in range(len(methods)):\n",
    "        visualize_image_attr(\n",
    "            attr,\n",
    "            original_image=original_image,\n",
    "            method=methods[i],\n",
    "            sign=signs[i],\n",
    "            plt_fig_axis=(plt_fig, plt_axis[i]),\n",
    "            use_pyplot=False,\n",
    "            title=titles[i] if titles else None,\n",
    "            **kwargs,\n",
    "        )\n",
    "    plt_fig.tight_layout()\n",
    "    if use_pyplot:\n",
    "        plt.show()\n",
    "    return plt_fig, plt_axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usD74Q6XXttm",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "## Vizuálna interpretácia neurónových sietí\n",
    "\n",
    "Neurónové siete a hlboké učenie predstavujú veľmi silnú paradigmu v oblasti strojového učenia. Nie sú však známe vysokou interpretovateľnosťou. Napriek tomu existuje niekoľko techník, ktoré dokážu poskytnúť určitú predstavu o tom, či sa neurónová sieť správa ako má. Pri tabuľkových dátach sa samozrejme vysvetlenia dajú vytvoriť pomocou metód ako LIME. Existuje však aj niekoľko techník, ktoré pracujú s obrázkami a niektoré z nich si ukážeme v tomto notebook-u.\n",
    "\n",
    "### Načítanie modelu\n",
    "\n",
    "Začneme načítaním predtrénovaného modelu, ktorý budeme testovať.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VP0l6CIW5vTB"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "weights = models.ResNet50_Weights.DEFAULT\n",
    "model = models.resnet50(weights=weights).to(device)\n",
    "proc_image = ProcImage(model, weights, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjhdKJ1p9_Kn",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Saliency\n",
    "\n",
    "Začneme s konceptom známym ako visual saliency (vizuálna význačnosť). Myšlienka je jednoduchá: skrátka použijeme spätné šírenie chyby (backprop, autodiff), vypočítame citlivosť predikcie na rôzne vstupné pixely a výsledok vizualizujeme: získame tzv. mapu význačností (saliency map). Zjednodušene povedané, mapa význačností rozsvieti pixely úmerne ich relevantnosti pri predikcii. To nám umožní overiť, či sieť sleduje správne časti obrázka: t.j. že predikuje lietadlo preto, že ho naozaj rozpoznáva, a nie preto, že väčšina pixelov na pozadí obrázka je modrá.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2IHGiRF25vTT"
   },
   "outputs": [],
   "source": [
    "attributor = Saliency(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO3fXTFWXtuU",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Ďalej si načítame obrázok tukana, spustíme na ňom model a zobrazíme mapu význačností. Uvidíme, že oblasť okolo tukana sa rozsvieti najviac. Zvýraznené však budú aj iné oblasti. Ako čoskoro uvidíme, v tomto prípade je to skôr vlastnosťami metódy než modelu: klasický gradient nie je až takým dobrým indikátorom.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "A4nj4pOQHrMr",
    "outputId": "cd57216b-fa90-4a94-ad9e-232209df6fe5"
   },
   "outputs": [],
   "source": [
    "img_preproc, img_resized, pred_class = proc_image('data/toucan.png')\n",
    "attrib = attributor.attribute(img_preproc, target=pred_class)\n",
    "visualize_attrib(attrib, outlier_perc=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CZftXWA9_Ku",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Navádzané spätné šírenie (guided backprop)\n",
    "\n",
    "Druhá metóda, ktorú si vyskúšame bude produkovať omnoho lepšie výsledky. Nazýva sa navádzané spätné šírenie (guided backprop) a vlastne nie je veľmi odlišná od vizuálnej význačnosti: tiež je založená na určitej verzii gradientu. Rozdiel je v tom, že modifikuje šírenie gradientu cez ReLU aktivačné funkcie tak, že sa prešíria len nezáporné gradienty. Tým sa v podstate ignorujú signály, ktoré negatívne prispievajú k aktivácii predikovanej triedy.\n",
    "\n",
    "Keďže sa zdá, že súčasná verzia balíka `captum` má problémy s inplace ReLU kvôli niektorým zmenám v `torch` a `torchvision` balíčkoch, model najprv prejdeme a zmeníme `.inplace` príznak všetkých ReLU na `False`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzvPDEJPPglp"
   },
   "outputs": [],
   "source": [
    "for module in model.modules():\n",
    "    if isinstance(module, torch.nn.ReLU):\n",
    "        module.inplace=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RGq513CKHp9R"
   },
   "outputs": [],
   "source": [
    "attributor = GuidedBackprop(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Q6zuP-V9_Kx",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Teraz našu metódu opäť aplikujeme na obrázok tukana: tento raz by mal sa mali už výstupy jasne sústrediť na obrysy tukana.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "EJrVVBr-7r9n",
    "outputId": "c7908229-24a7-4902-f383-310c57a11f88"
   },
   "outputs": [],
   "source": [
    "img_preproc, img_resized, pred_class = proc_image('data/toucan.png')\n",
    "attrib = attributor.attribute(img_preproc, target=pred_class)\n",
    "visualize_attrib(attrib, outlier_perc=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XK15aFf9_K0",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Dobre, teraz si to isté vyskúšajme aj na pár ďalších obrázkoch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oPoL-ycHMeRT",
    "outputId": "2c5ea6ca-cf4b-4754-9d15-65ba93169a44"
   },
   "outputs": [],
   "source": [
    "for img_path in ['data/ambulance.jpg', 'data/screws.jpg', 'data/nails.jpg', 'data/raccoon_example.jpg']:\n",
    "    img_preproc, img_resized, pred_class = proc_image(img_path)\n",
    "    attrib = attributor.attribute(img_preproc, target=pred_class)\n",
    "    visualize_attrib(attrib, outlier_perc=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyqFLAMgMnSo",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Prekrytie\n",
    "\n",
    "Existuje ešte mnoho iných prístupov založených na gradiente: niektoré z nich sa dajú preskúmať s použitím dokumentácie balíčka `captum`, ktorý používame na vytvorenie vizualizácií v tomto notebook-u.\n",
    "\n",
    "My spravíme už len jeden experiment – s vizualizačnou metódou založenou na úplne inom princípe: na prekrytí. Myšlienka je, že ak je pixel (alebo skupina pixelov) podstatný vzhľadom na predikciu, jeho prekrytie (napr. nastavením na nuly), bude mať veľmi silný dopad na predikciu. Ak teda budeme po obrázku kĺzať krycím oknom určitej veľkosti a pozorovať dopady, zistíme, na ktoré časti obrázka je výstup najviac citlivý.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1CP7zlO_bwN"
   },
   "outputs": [],
   "source": [
    "attributor = Occlusion(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilzblZdG9_K3",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Skúsme túto metódu aplikovať opäť na náš obrázok tukana. Použijeme najprv pomerne malé krycie okno. Ako vidno, model sa evidentne sústredí na tukana, ale vysvietili sa aj iné oblasti – ako napr. niektoré časti stromu.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "W_hC6-UrK-M5",
    "outputId": "c6f0d4eb-8e19-477f-a1d3-f6cde3f4affd"
   },
   "outputs": [],
   "source": [
    "img_preproc, img_resized, pred_class = proc_image('data/toucan.png')\n",
    "attrib = attributor.attribute(img_preproc, target=pred_class,\n",
    "                              strides = (3, 20, 20),\n",
    "                              sliding_window_shapes=(3, 30, 30),\n",
    "                              baselines=0)\n",
    "visualize_attrib(attrib, outlier_perc=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McePWKu89_K5",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Aby sme ilustrovali vplyv veľkosti krycieho okna, spustíme vizualizáciu ešte raz s väčším oknom. Teraz sa zdá byť najviac relevantná oblasť okolo tukanovho zobáka.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "LhW_aQXIJAiz",
    "outputId": "1221da9e-6f77-4513-9748-f07fd201cd3f"
   },
   "outputs": [],
   "source": [
    "img_preproc, img_resized, pred_class = proc_image('data/toucan.png')\n",
    "attrib = attributor.attribute(img_preproc, target=pred_class,\n",
    "                              strides = (3, 50, 50),\n",
    "                              sliding_window_shapes=(3, 60, 60),\n",
    "                              baselines=0)\n",
    "visualize_attrib(attrib, outlier_perc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JlpHbNGNdKr9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [
    "tEc0N6iSYh2E"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
