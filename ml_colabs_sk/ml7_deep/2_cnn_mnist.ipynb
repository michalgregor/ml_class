{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HYCI4dKVnLGQ",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "**POZNÁMKA: Tento notebook je určený pre platformu Google Colab, ktorá zdarma poskytuje hardvérovú akceleráciu. Je však možné ho spustiť (možno s drobnými úpravami) aj ako štandardný Jupyter notebook, pomocou lokálnej grafickej karty.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "z2-NXRAuFhl6",
    "outputId": "4b07b0c2-f612-4a78-a9c4-99d5257f0d68"
   },
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DpZmOfu_FHlh",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "## Klasifikácia MNIST číslic\n",
    "\n",
    "Tento príklad bude ilustrovať, ako sa dá zostrojiť jednoduchá konvolučná sieť na klasifikáciu obrazu na dátovej množine MNIST obsahujúcej rukou písané číslice.\n",
    "\n",
    "### Načítanie dátovej množiny\n",
    "\n",
    "Začneme načítaním dátovej množiny MNIST. Tento krok bude veľmi jednoduchý, pretože balíček `datasets` od HugginFace obsahuje vstavanú funkciu, ktorá dáta stiahne aj načíta. Zavoláme iba funkciu `load_dataset`, pričom ako dátovú množinu špecifikujeme `\"mnist\"`. Získame takto dátovú množinu, ktorá je už rozdelená na tréningovú a testovaciu časť – získať ich vieme pomocou `dataset['train']` a `dataset['test']`.\n",
    "\n",
    "Každá časť obsahuje dva zoznamy `'image'` a `'label'`; `'image'` je zoznam `PIL` obrázkov, ktoré je možné prviesť nanumpy polia pomocou funkcie `np.asarray`. Pod kľúčom `'label'` nájdete označenia tried (požadované výstupy).\n",
    "\n",
    "Pri načítavaní dát sa musíme uistiť, že tenzory sú správne škálované a majú správny tvar. Naše údaje sa skladajú z obrázkov $28 \\times 28$ s jedným farebným kanálom. V `PyTorch`-i sú farebné kanály reprezentované 1. rozmerom tenzora (pričom 0. rozmer je rozmer dávky). Náš tenzor má tvar `(dávka, 28, 28)` a my potrebujeme, aby mal tvar `(dávka, 1, 28, 28)`, takže zavoláme `.unsqueeze(1)`. Napokon si všimneme, že rozsah hodnôt je od 0 do 255 a preškálujeme ich do rozsahu od 0 po 1, t. j. delíme ich číslom 255.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LoaaEB3NxvQx"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dataset = load_dataset(\"mnist\")\n",
    "\n",
    "X_train_np = np.asarray([np.asarray(img) for img in dataset['train']['image']])\n",
    "Y_train_np = np.asarray(dataset['train']['label'])\n",
    "X_test_np = np.asarray([np.asarray(img) for img in dataset['test']['image']])\n",
    "Y_test_np = np.asarray(dataset['test']['label'])\n",
    "\n",
    "X_train = torch.as_tensor(X_train_np).to(device)\n",
    "Y_train = torch.as_tensor(Y_train_np).to(device)\n",
    "X_test = torch.as_tensor(X_test_np).to(device)\n",
    "Y_test = torch.as_tensor(Y_test_np).to(device)\n",
    "\n",
    "X_train = X_train.unsqueeze(1) / 255.0\n",
    "X_test = X_test.unsqueeze(1) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N9ZkiUnHGy7x",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Niekoľko náhodne zvolených vzoriek z tréningovej množiny si zobrazme.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "0ZmVUulDGXH-",
    "outputId": "e9c879a0-4082-43d5-caa8-9f8cabf84120"
   },
   "outputs": [],
   "source": [
    "num_rows = 4; num_cols = 4\n",
    "fig, axes = plt.subplots(num_rows, num_cols)\n",
    "\n",
    "for row in axes:\n",
    "    for ax in row:\n",
    "        ax.imshow(X_train_np[np.random.randint(0,\n",
    "                    len(X_train_np)-1)],\n",
    "                  cmap='Greys')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lFTpGs7j5q2-",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Dátové množiny a data loader-y\n",
    "\n",
    "Doteraz sme s dátami pracovali v režime úplných dávok: do siete sme v každom kroku vložili vždy celú dátovú množinu. To je, samozrejme možné iba vtedy, ak je dátová množina dostatočne malá na to, aby sa do pamäte zmestila celá naraz. Ak so sieťou pracujeme na GPU, vieme ju potom spustiť na všetkých dátach paralelne, takže beh je výpočtovo efektívny.\n",
    "\n",
    "Pri hlbokom učení je však väčšina dátových množín príliš veľká na to, aby sa zmestila do pamäte naraz – môžu mať pokojne desiatky alebo stovky gigabajtov a niektoré sú ešte väčšie. Ak je vaša dátová množina taká veľká, je samozrejme nevyhnutné, aby bolo možné načítavať dáta z pevného disku za pochodu a trénovať v režime mini-dávok. V PyTorch-i sa tento aspekt hlbokého učenia rieši pomocou objektov `Dataset` a `DataLoader`.\n",
    "\n",
    "#### Trieda Dataset\n",
    "\n",
    "Trieda `Dataset` poskytuje unifikované rozhranie na prístup k dátam. Existuje množstvo rôznych tried, ktoré dedia z `Dataset`, a implementujú podporu pre rôzne formáty dátových množín, napr. `ImageNet`, `VOCDetection`, `Cityscapes`, `CelebA`. Existuje dokonca aj o niečo všeobecnejšia trieda `ImageFolder`, ktorá jednoducho načítava obrázky a označenia tried z priečinka.\n",
    "\n",
    "Na definovanie vlastnej dátovej množiny by sme potrebovali implementovať nasledujúce rozhranie:\n",
    "\n",
    "```\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, ...)\n",
    "        ...\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "        \"\"\"\n",
    "\n",
    "        ...\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the sample at index idx from the dataset.\n",
    "        \"\"\"\n",
    "\n",
    "        ...\n",
    "```\n",
    "#### Trieda DataLoader\n",
    "\n",
    "Data loader dostane ako argument dátovú množinu a je zodpovedný za zostavovanie mini-dávok z nej, zabezpečuje, aby boli dáta korektne zamiešané a pod. Typicky nie je potrebné implementovať vlastný data loader — vo väčšine prípadov stačí použiť triedu `DataLoader` z `torch.utils.data`, napr. takto:\n",
    "\n",
    "```\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "```\n",
    "#### Náš príklad a TensorDataset\n",
    "\n",
    "Dátová množina MNIST je opäť dostatočne malá na to, aby sa zmestila do pamäte celá naraz. S dátovými množinami ako je táto môžeme použiť triedu `TensorDataset`, ktorá iba zabalí existujúci tenzor do `DataSet` rozhrania a umožní ho použiť s DataLoader-mi. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "test_dataset = TensorDataset(X_test, Y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lFTpGs7j5q2-",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Zostavenie konvolučnej siete\n",
    "\n",
    "Pri zostavovaní konvolučnej siete väčšinou postupujeme tak, že preštudujeme literatúru týkajúcu sa podobných úloh a na základe toho vytvoríme podobnú architektúru neurónovej siete pre náš problém (a prípadne ju doladíme).\n",
    "\n",
    "Keďže dátová množina MNIST nie je až taká náročná, ukážeme si na nej ešte o čosi jednoduchší prístup:\n",
    "\n",
    "* Budeme za sebou radiť bloky konvolučných vrstiev, ReLU funkcií a združovacích vrstiev.\n",
    "* Pokračovať budeme dovtedy, kým sa rozmer vstupného obrazu dostatočne nezníži.\n",
    "* Následne zaradíme do siete jednu alebo viacero klasických lineárnych vrstiev s ReLU aktivačnými funkciami.\n",
    "Aby sa nám ľahšie sledovalo, aký rozmer majú dáta po aplikácii jednotlivých vrstiev, neobalíme si všetky vrstvy hneď do tried, ale s nimi budeme najprv voľne experimentovať. Z dátovej množiny si vyberieme zopár vzoriek, ktoré použijeme ako pokusný vstup.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l0VLWcWQ_o4d"
   },
   "outputs": [],
   "source": [
    "y = X_train[:5].to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zpeALxHbnLIF",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Teraz si teda vytvorme prvý blok a aplikujme ho na tenzor `y`. Ako prvú vytvoríme 2D konvolučnú vrstvu pomocou triedy `nn.Conv2d`. Treba pri tom špecifikovať niekoľko parametrov: konkrétne počet vstupných a výstupných kanálov a veľkosť konvolučného jadra. Počet vstupných kanálov bude samozrejme 1, pretože, ako sme už spomenuli, pracujeme s jedným farebným kanálom. Počet výstupných kanálov je jedným z hyperparametrov nášho modelu – začneme s hodnotou 16 keďže naše dáta sú také jednoduché. Za zmienku stojí, že v typickej konvolučnej sieti sa rozmery príznakových máp zvyknú v neskorších vrstvách zmenšovať, ale počet kanálov naopak narastá (intuícia je, že čím hlbšia vrstva, tým abstraktnejšie – a početnejšie – sú koncepty, ktoré reprezentuje).\n",
    "\n",
    "Konvolučné jadrá môžu mať tiež rôzne veľkosti, ale všeobecné odporúčania vychádzajúce z empirických výsledkov hovoria, že jadrá rozmeru $3 \\times 3$ zvyknú fungovať dobre. Snahou je vyhnúť sa tomu, aby jadrá boli príliš veľké, pretože s čím väčšími maticami budeme pracovať, tým dlhšie bude trvať, kým ich medzi sebou vynásobíme.\n",
    "\n",
    "Po konvolučnej vrstve aplikujeme ReLU aktivačnú funkciu a maximálne združovanie, ktorému je opäť potrebné nastaviť eľkosť jadra. Pri združovaní platí, že čím väčšia je veľkosť jadra, tým rapídnejšie dáta podvzorkovávame. Budeme preto používať malé jadro rozmeru $2 \\times 2$. Mnohé moderné architektúry sa v poslednom čase združovacích vrstiev zbavili úplne a namiesto nich používajú na podvzorkovanie väčší krok alebo dilatáciu v konvolučných vrstvách.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a3aFchVN5lJD"
   },
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(\n",
    "    in_channels=1, out_channels=8,\n",
    "    kernel_size=(3, 3))\n",
    "\n",
    "y = conv1(y)\n",
    "y = torch.relu(y)\n",
    "y = torch.max_pool2d(y, kernel_size=(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eaMl4zmcnLIX",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Potom, ako sme skonštruovali prvý blok, overme si, aký mal vplyv na rozmer našich dát.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "M7URiPUI5lTK",
    "outputId": "a6028670-b456-4e72-a75d-9f6ba44a566d"
   },
   "outputs": [],
   "source": [
    "np.product(y.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aohRJPmDnLIo",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Ukazuje sa, že naše dáta sú stále príliš vysokorozmerné a budeme ich rozmer musieť ešte o čosi znížiť. Aplikujme teda ešte jeden blok. Všimnite si, že hoci príznaková mapa sa zmenšuje, počet kanálov zvyšujeme.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OnRZLp7h5lmV"
   },
   "outputs": [],
   "source": [
    "conv2 = nn.Conv2d(8, 16, (3, 3))\n",
    "y = conv2(y)\n",
    "y = torch.relu(y)\n",
    "y = torch.max_pool2d(y, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Gt8KrJsC5liQ",
    "outputId": "19bd9632-07a5-49ea-b594-a7aadd037b1b"
   },
   "outputs": [],
   "source": [
    "np.product(y.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-x9ocRPTnLI_",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Po aplikácií druhého bloku je počet rozmerov omnoho rozumnejší. Môžeme preto aktuálny výstup zalomiť do vektora (2-rozmernému obraz zmeníme tvar tak, aby sa z neho stal 1-rozmerný vektor) a aplikujme zopár štandardných lineárnych vrstiev s ReLU aktivačnými funkciami. Znovu si pritom dajme pozor, aby sa rozmer dát znižoval postupne a zmena nebola z jednej vrstvy na druhú príliš drastická. Výstupná vrstva bude mať 10 výstupných neurónov, pretože klasifikujeme do 10 tried: na číslice. Ako aktivačnú funckiu použijeme softmax funkciu.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFx8XKrA5lei"
   },
   "outputs": [],
   "source": [
    "y = torch.flatten(y, 1)\n",
    "\n",
    "fc1 = nn.Linear(400, 128)\n",
    "y = fc1(y)\n",
    "y = torch.relu(y)\n",
    "\n",
    "fc2 = nn.Linear(128, 10)\n",
    "y = fc2(y)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "svGYRvNgnigw",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Keď sme teda navrhli celú architektúru, potrebujeme ju znovu obaliť do triedy. Ako zvyčajne, vrstvy s parametrami treba vytvoriť už v konštruktore `__init__` a potom použiť vo funkcii `forward`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CPiXuQRQ5lFk"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, (3, 3))\n",
    "        self.conv_acti1 = nn.PReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(8, 16, (3, 3))\n",
    "        self.conv_acti2 = nn.PReLU()\n",
    "\n",
    "        self.fc1 = nn.Linear(400, 128)\n",
    "        self.fc_acti1 = nn.PReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(128, num_outputs)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, y):\n",
    "        y = self.conv1(y)\n",
    "        y = self.conv_acti1(y)\n",
    "        y = torch.max_pool2d(y, kernel_size=(2, 2))\n",
    "        y = self.dropout(y)\n",
    "        \n",
    "        y = self.conv2(y)\n",
    "        y = self.conv_acti2(y)\n",
    "        y = torch.max_pool2d(y, kernel_size=(2, 2))\n",
    "        y = self.dropout(y)\n",
    "        \n",
    "        y = torch.flatten(y, 1)\n",
    "        \n",
    "        y = self.fc1(y)\n",
    "        y = self.fc_acti1(y)\n",
    "        y = self.dropout(y)\n",
    "\n",
    "        y = self.fc2(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2avggNUrnLJr",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Konštrukcia a tréning klasifikátora\n",
    "\n",
    "Naša tréningová slučka bude teraz trochu iná, keďže používame `Dataset` a `DataLoader` objekty.\n",
    "\n",
    "Po novom budeme pracovať s dvoma vnorenými slučkami:\n",
    "\n",
    "* Vonkajšia iteruje cez epochy;\n",
    "* Vnútorná iteruje cez minidávky v rámci tej istej epochy;\n",
    "Všimnite si, že teraz zaznamenávame chybu pre každú minidávku. V dôsledku toho bude krivka učenia o niečo viac zašumená – gradienty sú, samozrejme, stabilnejšie, keď sa akumulujú v rámci celej dátovej množiny než keď sa akumulujú len v rámci menšej minidávky.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs = 10\n",
    "model = Net(num_outputs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_train = []\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "\n",
    "    for X_batch, Y_batch in train_dataloader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        Y_batch = Y_batch.to(device)\n",
    "        \n",
    "        y_batch = model(X_batch)\n",
    "        loss = criterion(y_batch, Y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train.append(loss.item())\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"epoch {epoch}, loss: {np.mean(loss_train[-20:])}\")\n",
    "\n",
    "print(f\"epoch {epoch}, loss: {np.mean(loss_train[-20:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_train)\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.grid(ls='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EHbXgZ2lnLKK",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Testovanie\n",
    "\n",
    "Napokon aplikujeme opäť našu štandardnú testovaciu procedúru pre klasifikátory: zobrazíme maticu zámen a správnosť na testovacej množine.\n",
    "\n",
    "#### Na tréningových dátach\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_train_logit = model(X_train)\n",
    "    y_train = y_train_logit.argmax(dim=1)\n",
    "\n",
    "cm = pd.crosstab(\n",
    "    Y_train.cpu().numpy(),\n",
    "    y_train.cpu().numpy(),\n",
    "    rownames=['actual'],\n",
    "    colnames=['predicted']\n",
    ")\n",
    "print(cm, \"\\n\")\n",
    "\n",
    "acc = accuracy_score(Y_train.cpu().numpy(), y_train.cpu().numpy())\n",
    "print(\"Accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EHbXgZ2lnLKK",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "#### Na testovacích dátach\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_logit = model(X_test)\n",
    "    y_test = y_test_logit.argmax(dim=1)\n",
    "\n",
    "cm = pd.crosstab(\n",
    "    Y_test.cpu().numpy(),\n",
    "    y_test.cpu().numpy(),\n",
    "    rownames=['actual'],\n",
    "    colnames=['predicted']\n",
    ")\n",
    "print(cm, \"\\n\")\n",
    "\n",
    "acc = accuracy_score(Y_test.cpu().numpy(), y_test.cpu().numpy())\n",
    "print(\"Accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XAGmqsvFVOPR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "6_cnn_mnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
