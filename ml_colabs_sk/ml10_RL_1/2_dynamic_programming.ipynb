{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5664949a",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "**POZNÁMKA: Tento notebook je určený pre platformu Google Colab. Je však možné ho spustiť (možno s drobnými úpravami) aj ako štandardný Jupyter notebook.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d85e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install git+https://github.com/michalgregor/gym_plannable.git\n",
    "!{sys.executable} -m pip install git+https://github.com/michalgregor/rl_tabular.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc7fb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "%matplotlib inline\n",
    "from gym_plannable.env import MazeEnv\n",
    "from rl_tabular import StateValueTable, ActionValueTable, collect_states\n",
    "from rl_tabular.maze_env_plots import plot_action_values, plot_state_values\n",
    "from rl_tabular import vtable_control, qtable_control\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dc95bc",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "## Dynamické programovanie: iterácia hodnotami\n",
    "\n",
    "Ako sme sa už dozvedeli, učenie s odmenou je o nájdení stratégie, ktorá by maximalizovala dlhodobé odmeny. Vieme tiež, že jedna skupina týchto prístupov je založená na hodnotových funkciách.\n",
    "\n",
    "*Hodnotová funkcia stavov*  $V(s)$ vyjadruje, aké dlhodobé odmeny môžeme očakávať v budúcnosti ak sa teraz nachádzame v stave $s$ a ďalej sa budeme riadiť stratégiou $\\pi$ [[sutton1998]](#sutton1998):\n",
    "\n",
    "$$\n",
    "V^{\\pi}(s) = \\mathbb{E}_{\\pi}\\{ R_{t}|s_{t}=s \\}\n",
    "$$\n",
    "Spomeňte si tiež, že ak máme k dispozícii distribučný model prostredia a priestor akcií je malý, môžeme hodnotovú funkciu stavov vypočítať pomocou metódy známej ako **iterácia hodnotami** .\n",
    "\n",
    "Na začiatku nastavíme hodnoty všetkých stavov na nuly:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da90bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtable = StateValueTable()\n",
    "plot_state_values(vtable);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dbc4f8",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Potom aplikujeme nasledujúce pravidlo, pričom iterujeme viackrát po všetkých stavoch $s$:\n",
    "\n",
    "$$\n",
    "V_{\\color{red} k+1}(s) = \\max_{a \\in A} \\sum_{s'} P_{ss'}^{a} \\left[r_{ss'}^{a} + \\gamma V_{\\color{red} k}(s') \\right].\n",
    "$$kde $P_{ss'}^{a}$ je pravdepodobnosť prechodu zo stavu $s$ do stavu $s'$ po vykonaní akcie $a$; a $r^a_{ss'}$ je odmena získaná za ten istý prechod.\n",
    "\n",
    "---\n",
    "### Úloha 1: Iterácia hodnotami\n",
    "\n",
    "**Do nasledujúcej bunky doplňte pravidlo iterácie hodnotami.** \n",
    "\n",
    "$$\n",
    "V_{\\color{red} k+1}(s) = \\max_{a \\in A} \\sum_{s'} P_{ss'}^{a} \\left[r_{ss'}^{a} + \\gamma V_{\\color{red} k}(s') \\right].\n",
    "$$\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a05df",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "gamma = 0.9\n",
    "env = MazeEnv()\n",
    "env.reset()\n",
    "\n",
    "# we collect all reachable states\n",
    "states = collect_states(env.single_plannable_state())\n",
    "\n",
    "for it in range(15):\n",
    "    print(f\"Iteration {it} started.\")\n",
    "    \n",
    "    for state in states:\n",
    "        if state.is_done():\n",
    "            continue\n",
    "            \n",
    "        legals = state.legal_actions()\n",
    "        maxval = -np.inf\n",
    "\n",
    "        for a in legals:\n",
    "            val = 0\n",
    "\n",
    "            for next_state, prob in state.all_next(a):\n",
    "                r = next_state.reward()                \n",
    "                \n",
    "                \n",
    "                \n",
    "                # r, gamma, prob, vtable, next_state       \n",
    "                val +=     # -----\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "            maxval = max(val, maxval)\n",
    "\n",
    "        vtable[state] = maxval\n",
    "        \n",
    "    plot_state_values(vtable, states, env=env, update_display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50907064",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Riadenie agenta na základe hodnotovej funkcie stavov\n",
    "\n",
    "Ak je priestor akcií diskrétny a relatívne malý a už poznáme optimálnu hodnotovú funkciu, je ľahké z nej odvodiť optimálnu stratégiu – jednoducho iterujeme cez všetky akcie a vyberieme tú, u ktorej je najpravdepodobnejšie, že bude viesť do stavu s vysokou hodnotou.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b067ace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MazeEnv(render_mode='human', show_path=True)\n",
    "vtable_control(env, vtable, max_steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a963bb",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Konverzia medzi hodnotovou funkciou stavov a akcií\n",
    "\n",
    "Ak máme k dispozícii model, hodnotovú funkciu stavov je možné konvertovať na hodnotovú funkciu akcií podľa v podstate rovnakej logiky, akú sme aplikovali pri riadení agenta podľa hodnotovej funkcie stavov.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd088e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qtable = vtable.to_action_values(states)\n",
    "plot_action_values(qtable, states, action_spec=env.action_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed2e45e",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Je tiež možné konvertovať hodnotovú funkciu akcií na hodnotovú funkciu stavov:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f6b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtable2 = qtable.to_state_values()\n",
    "plot_state_values(vtable2, states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f1f4d",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Riadenie pomocou hodnotovej funkcie akcií\n",
    "\n",
    "Riadenie agentov pomocou hodnotovej funkcie akcií je ešte jednoduchšie než pomocou hodnotovej funkcie stavov. Keďže hodnotová funkcia akcií nám poskytuje priamo hodnoty akcií, stačí nám vybrať akciu s najvyššou hodnotou – nepotrebujeme už model, ktorý by nás informoval o možných nasledujúcich stavoch atď.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea10e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MazeEnv(render_mode='human', show_path=True)\n",
    "qtable_control(env, qtable, max_steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c95e78",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "<a id=\"sutton1998\">[sutton1998]</a> SUTTON, R.S. - BARTO, A.G. Reinforcement Learning: An Introduction. [s.l.]: The MIT Press, 1998. ISBN 0262193981.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae3a8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "b08d363ebb8492a302c7076da18bf168d910622d9da13f07c6e53914cde27110"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
