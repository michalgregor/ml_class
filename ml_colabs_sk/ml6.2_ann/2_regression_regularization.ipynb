{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xnMz4MPyMA2F",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "**POZNÁMKA: Tento notebook je určený pre platformu Google Colab, ktorá zdarma poskytuje hardvérovú akceleráciu. Je však možné ho spustiť (možno s drobnými úpravami) aj ako štandardný Jupyter notebook, pomocou lokálnej grafickej karty.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uYHzZMVjMA2N",
    "outputId": "759e5c64-250c-4f95-fe58-f237ba447821"
   },
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install git+https://github.com/michalgregor/class_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "yn6Mqh5qMA2r",
    "outputId": "7dec07c7-ce23-4791-ec26-118d72098114"
   },
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from class_utils import error_histogram\n",
    "from class_utils.pytorch_utils import EarlyStopping\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jLWb1LkMMA2-",
    "outputId": "2eb38179-d0ba-452b-ef61-d960ec4718bb"
   },
   "outputs": [],
   "source": [
    "#@title -- Downloading Data -- { display-mode: \"form\" }\n",
    "from class_utils.download import download_file_maybe_extract\n",
    "download_file_maybe_extract(\"https://www.dropbox.com/s/3jnf3000vwaxtcg/boston_housing.zip?dl=1\", directory=\"data/boston_housing\")\n",
    "\n",
    "# also create a directory for storing any outputs\n",
    "import os\n",
    "os.makedirs(\"output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DnzDgmr6MA3U",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "## Regresný model pre ceny nehnuteľností\n",
    "\n",
    "V tomto notebook-u budeme aplikovať regresiu na báze umelých neurónových sietí na problém predikcie ceny nehnuteľností. Pracovať budeme s dátovou množinou [Boston housing dataset](https://www.kaggle.com/c/boston-housing).\n",
    "\n",
    "**Note:**  The example is purely illustrational. The dataset is well-structured (the data is divided into columns with clear meanings etc.), and would therefore probably be approached with a different method in practice – possibly with some approached based on decision trees. Artificial neural networks and deep learning are usually applied to problems with unstructured data, such as images, audio, text etc.\n",
    "\n",
    "### Načítanie predspracovanie dátovej množiny\n",
    "\n",
    "Začnime tým, že si zobrazíme opis dát:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vMO0LT4CMA3b",
    "outputId": "2a7518a9-1910-4ae9-b09e-4f76d1da9d86"
   },
   "outputs": [],
   "source": [
    "with open(\"data/boston_housing/description.txt\", \"r\") as file:\n",
    "    print(\"\".join(file.readlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z5iddwYmMA3y",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Ďalej si z CSV súboru načítajme samotnú dátovú množinu:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "XlH4mJwxMA32",
    "outputId": "aa60320e-4928-456b-f994-f2863185c6cd"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/boston_housing/housing.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rNsP0gZTMA4I",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "#### Rozdelenie dátovej množiny\n",
    "\n",
    "Ďalej pokračujeme rozdelením dátovej množiny. Dáta budeme v tomto prípade deliť nie na dve, ale až na tri časti: na tréningové, validačné a testovacie dáta v pomere 70 : 5 : 25. Validačná dáta budeme používať počas učenia na regularizáciu a výber modelu (detaily nižšie).\n",
    "\n",
    "Zároveň pri delení použijeme stratifikáciu podľa diskretizovanej verzie výstupného stĺpca:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "89Qbm_CvMA4L"
   },
   "outputs": [],
   "source": [
    "kbins = KBinsDiscretizer(10, encode='ordinal')\n",
    "\n",
    "y_stratify = kbins.fit_transform(df[[\"medv\"]])\n",
    "df_train_valid, df_test = train_test_split(df, test_size=0.25,\n",
    "                                     stratify=y_stratify,\n",
    "                                     random_state=9)\n",
    "\n",
    "y_stratify = kbins.fit_transform(df_train_valid[[\"medv\"]])\n",
    "df_train, df_valid = train_test_split(df_train_valid, test_size=0.05/0.75,\n",
    "                                     stratify=y_stratify,\n",
    "                                     random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DLNBFM3NMA4Y",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "---\n",
    "#### Úloha 1: Predspracovanie dát\n",
    "\n",
    "**Aplikujte na dátovú množinu náš štandardný postup predspracovanie pre neurónové siete. Výstupom nech je tréningová množina `X_train`, `Y_train`, validačná množina `X_valid`, `Y_valid` a testovacia množina `X_test`, `Y_test` v príslušnom tvare a s príslušnými dátovými typmi.** \n",
    "\n",
    "Pamätajte na to, že `fit_transform` treba použiť len na trénovacej množine. Na validačnú a testovaciu množinu sa používa `transform`.\n",
    "\n",
    "Nezabudnite dáta konvertovať na PyTorch tenzory s vhodnými dátovými typmi. Tenzory preneste na `device`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IqWPdiMmMA4m",
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "categorical_inputs = [          ] # -----\n",
    "\n",
    "numeric_inputs = [              ] # -----\n",
    "\n",
    "output = [\"medv\"]\n",
    "\n",
    "\n",
    "input_preproc = # ---\n",
    "\n",
    "\n",
    "\n",
    "# -----\n",
    "\n",
    "\n",
    "output_preproc = StandardScaler()\n",
    "\n",
    "\n",
    "# -----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J2G78Sd6MA41",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "---\n",
    "### Úloha 2: Vytvorenie a tréning neurónovej siete\n",
    "\n",
    "**Vytvorte neurónovú sieť na regresiu a natrénujte ju na tréningovej množine. Výstupom by mal byť natrénovaný objekt `net` so `scikit-learn` rozhraním, ktorý sa následne bude dať otestovať na testovacích dátach.** \n",
    "\n",
    "**Pomôcka: Veľkosti lineárnych vrstiev môžete voliť napr. takéto:** \n",
    "\n",
    "* `num_inputs`;\n",
    "* 128;\n",
    "* 64;\n",
    "* 32;\n",
    "* `num_outputs`;\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BXtcSROsMA5N",
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        # -----\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = X_train.shape[1]\n",
    "num_outputs = Y_train.shape[1]\n",
    "model = Net(num_inputs, num_outputs).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_train = []\n",
    "\n",
    "for epoch in range(2000):\n",
    "    model.train()\n",
    "    y = model(X_train)\n",
    "\n",
    "    loss = criterion(y, Y_train)\n",
    "    loss_train.append(loss.detach().item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"epoch {epoch}, loss: {np.mean(loss_train[-20:]):.3g}\")\n",
    "\n",
    "print(f\"epoch {epoch}, loss: {np.mean(loss_train[-20:]):.3g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqejrSGaK_BV",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Ďalej môžeme použiť chyby uložené v `loss_train` na vykreslenie krivky učenia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_train)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.grid(ls='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqejrSGaK_BV",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Keď je tréning hotový, urobme aj štandardné vyhodnotenie na tréningových dátach. Mali by sme vidieť, že výsledky sú vcelku dobré a chyby sú v rámci škály dát zanedbateľné.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_cpu = Y_train.cpu()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_train_cpu = model(X_train).cpu()\n",
    "\n",
    "# we compute and display the MSE and the MAE\n",
    "mse = mean_squared_error(Y_train_cpu, y_train_cpu)\n",
    "print(\"MSE = {}\".format(mse))\n",
    "\n",
    "mae = mean_absolute_error(Y_train_cpu, y_train_cpu)\n",
    "print(\"MAE = {}\".format(mae))\n",
    "\n",
    "# we display the error histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_train_cpu, y_train_cpu, Y_fit_scaling=Y_train_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqejrSGaK_BV",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "#### Testovanie modelu na validačných dátach\n",
    "\n",
    "Dobre, výsledky nášho modelu na tréningových dátach sú vcelku uspokojivé. Ale platí aj, že nám model dobre zovšeobecňuje?\n",
    "\n",
    "Keďže s návrhom siete sme ešte neskončili (nižšie budeme pokračovať), otestujeme si úspešnosť zatiaľ **nie na testovacích dátach**  (tie sa smú použiť až na konci), ale **pomocou validačných dát** . Testovacie dáta použijeme až na úplnom konci na overenie zovšeobecnenia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_valid_cpu = Y_valid.cpu()\n",
    "Y_train_cpu = Y_train.cpu()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_valid_cpu = model(X_valid).cpu()\n",
    "\n",
    "# we compute and display the MSE and the MAE\n",
    "mse = mean_squared_error(Y_valid_cpu, y_valid_cpu)\n",
    "print(\"MSE = {}\".format(mse))\n",
    "\n",
    "mae = mean_absolute_error(Y_valid_cpu, y_valid_cpu)\n",
    "print(\"MAE = {}\".format(mae))\n",
    "\n",
    "# we display the error histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_valid_cpu, y_valid_cpu, Y_fit_scaling=Y_train_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VRDneWuJK7O-",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Po vyhodnotení modelu na validačných dátach by ste mali vidieť, že metriky sa ani len nepribližujú tým na tréningových dátach. To indikuje, že došlo k silnému **preučeniu** .\n",
    "\n",
    "#### Testovanie na validačných dátach v priebehu učenia\n",
    "\n",
    "Aby sme získali lepšiu predstavu o tom, kde sa učenie v rámci učenia objavili problémy, zaznamenajme si hodnoty chybovej funkcie na validačných dátach počas učenia rovnako, ako sme to robili s chybami na tréningových dátach a následne si oboje vykreslime.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = X_train.shape[1]\n",
    "num_outputs = Y_train.shape[1]\n",
    "model = Net(num_inputs, num_outputs).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_train = []\n",
    "loss_valid = []\n",
    "\n",
    "for epoch in range(2000):\n",
    "    model.train()\n",
    "    y = model(X_train)\n",
    "\n",
    "    loss = criterion(y, Y_train)\n",
    "    loss_train.append(loss.detach().item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y = model(X_valid)\n",
    "        loss = criterion(y, Y_valid)\n",
    "        loss_valid.append(loss.item())\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"epoch {epoch}, train loss: {np.mean(loss_train[-20:]):.3g}, valid loss: {np.mean(loss_valid[-20:]):.3g}\")\n",
    "\n",
    "print(f\"epoch {epoch}, train loss: {np.mean(loss_train[-20:]):.3g}, valid loss: {np.mean(loss_valid[-20:]):.3g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_train, label=\"train\")\n",
    "plt.plot(loss_valid, label=\"valid\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.grid(ls='--')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_valid_cpu = Y_valid.cpu()\n",
    "Y_train_cpu = Y_train.cpu()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_valid_cpu = model(X_valid).cpu()\n",
    "\n",
    "# we compute and display the MSE and the MAE\n",
    "mse = mean_squared_error(Y_valid_cpu, y_valid_cpu)\n",
    "print(\"MSE = {}\".format(mse))\n",
    "\n",
    "mae = mean_absolute_error(Y_valid_cpu, y_valid_cpu)\n",
    "print(\"MAE = {}\".format(mae))\n",
    "\n",
    "# we display the error histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_valid_cpu, y_valid_cpu, Y_fit_scaling=Y_train_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VRDneWuJK7O-",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Ako vidno, veci sa zrazu javia celkom inak. Chyba na validačných dátach je oveľa horšia než na testovacích dátach a pri pozornejšom pohľade možno uvidíte, že sa po chvíli dokonca začína zvyšovať – napriek tomu, že na tréningových dátach stále klesá či zostáva nízka.\n",
    "\n",
    "### Regularizácia\n",
    "\n",
    "Ako vyriešime problém uvedený v predchádzajúcej časti a zabránime preučeniu siete? Nuž, k preučeniu často dochádza preto, že keď je pre sieť ťažké znížiť chybu legitímnym spôsobom, začne podvádzať tak, že sa dáta učí naspamäť.\n",
    "\n",
    "Aby sme predišli takýmto problémom, je potrebné použiť nejaké metódy regularizácie. Ide o metódy ktoré majú pomôcť predísť preučeniu. Názov \"regularizácia\" vychádza z toho, že chceme, aby náš model zachytával skutočné zákonitosti v dátach a nezačal sa dáta učiť naspamäť, aj vrátane šumu.\n",
    "\n",
    "#### Získanie ďalších dát\n",
    "\n",
    "Získanie väčšieho množstva dát je vo všeobecnosti najlepším spôsobom, ako zlepšiť zovšeobecnenie – pri dostatočnom množstve dát by metóda učenia mala byť schopná lepšie rozlíšiť zákonitosti od šumu. Rovnako by model nemal byť schopný zapamätať si všetky dáta, a teda je nútený učiť sa samotné zákonitosti.\n",
    "\n",
    "Problém pri získavaní väčšieho množstva dát je ten, že je to vo všeobecnosti veľmi náročné a drahé. Preto bolo vyvinutých množstvo iných metód regularizácie – cieľom je získať čo najviac z dát, ktoré už máme.\n",
    "\n",
    "#### Regularizácia v štandardnom strojovom učení\n",
    "\n",
    "Vo väčšine metód strojového učenia sa regularizácia uskutočňuje tak, že sa nejakým spôsobom zníži kapacita modelu – napr. zmenšením jeho veľkosti (stupeň polynómu, veľkosť rozhodovacieho stromu, ...).\n",
    "\n",
    "To pomáha, pretože model už nie je schopný zapamätať si tréningovú množinu a musí skutočne hľadať zákonitosti v dátach. V umelých neurónových sieťach sa to dá dosiahnuť znížením počtu a veľkosti vrstiev.\n",
    "\n",
    "#### Skoré ukončenie učenia\n",
    "\n",
    "Ďalším spôsobom, ako znížiť kapacitu neurálneho modelu, je použiť techniku ​​známu ako skoré ukončenie učenia. Ako sme videli už vyššie, jedna vec, ktorá sa zvyčajne stáva v priebehu tréningu, je, že aj keď chyba na tréningových dátach neustále klesá, strata na validačných dátach (ak sa používajú) prestane klesať alebo dokonca začne rásť.\n",
    "\n",
    "Myšlienkou skorého ukončenia učenia je jednoducho prestať trénovať v tomto bode a obnoviť váhy siete do bodu, kedy bola validačná chyba na minime. Ďalšou výhodou tohto prístupu je, že prináša úsporu výpočtov.\n",
    "\n",
    "#### Regularizácia v hlbokom učení\n",
    "\n",
    "Oblasť hlbokého učenia je tak trochu výnimkou, pretože regularizácia sa zvyčajne nevykonáva obmedzením veľkosti modelu. Odborníci na hlboké učenie využívajú skôr:\n",
    "\n",
    "* Špeciálne vrstvy;\n",
    "* Dômyselné architektúry, ktoré zanášajú do modelu lepšie indukčné preferencie (t. j. prispôsobujú ho druhu riešenia, o ktorom je možné predpokladať, že bude dobre zovšeobecňovať);\n",
    "* Zväčšovanie dátovej množiny (napr. generovanie nových náhodných variantov existujúcich vzoriek);\n",
    "* Transfer učenie (t. j. predtrénovanie na väčšom množstve údajov);\n",
    "*...\n",
    "#### Čo budeme používať v tomto notebooku\n",
    "\n",
    "V tomto konkrétnom notebooku nebudeme veci zbytočne komplikovať. Použijeme iba dve jednoduché metódy regularizácie:\n",
    "\n",
    "* **Skoré ukončenie učenia** ;\n",
    "* **Dropout** ;\n",
    "Za zmienku stojí, že keďže neurónová sieť, ktorú tu používame, je **plytká**  a množina údajov je malá, zmenšenie **neurónovej siete**  môže byť v skutočnosti tiež dobrým spôsobom, ako regularizovať – aj keď v hlbokej siete trénovanej na miliónoch vzoriek by ste to isté nerobili.\n",
    "\n",
    "Znova si všimnite, že počas celého procesu vývoja modelu **používame trénovaciu a validačnú množinu** , ale **nie**  testovaciu množinu. Testovaciu množinu nechávame bokom, aby sme mohli vyhodnotiť úplne finálnu verziu nášho modelu.\n",
    "\n",
    "### Skoré ukončenie učenia\n",
    "\n",
    "Začnime teda skorým ukončením učenia. Keďže chyby môžu byť trochu zašumené, skoré ukončenie má zvyčajne hyperparameter \"patience\" (trpezlivosť) – tento udáva, koľko krokov sa bude čakať potom, ako sa chyba prestane znižovať, kým sa tréning skutočne zastaví.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(checkpoint_path=\"output/best_model.pt\")\n",
    "\n",
    "num_inputs = X_train.shape[1]\n",
    "num_outputs = Y_train.shape[1]\n",
    "model = Net(num_inputs, num_outputs).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_train = []\n",
    "loss_valid = []\n",
    "\n",
    "for epoch in range(2000):\n",
    "    model.train()\n",
    "    y = model(X_train)\n",
    "\n",
    "    loss = criterion(y, Y_train)\n",
    "    loss_train.append(loss.detach().item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y = model(X_valid)\n",
    "        loss = criterion(y, Y_valid)\n",
    "        loss_valid.append(loss.item())\n",
    "        if early_stopping(loss_valid[-1], model):\n",
    "            print(f\"Stopping the training early because the validation loss has not improved in the last {early_stopping.patience} epochs\")\n",
    "            break\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"epoch {epoch}, train loss: {np.mean(loss_train[-20:]):.3g}, valid loss: {np.mean(loss_valid[-20:]):.3g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_train, label=\"train\")\n",
    "plt.plot(loss_valid, label=\"valid\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.grid(ls='--')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEpbFt3VK_Cb",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Po dokončení učenia načítame najlepší model späť z checkpointového súboru a spustíme vyhodnotenie. Výsledky už môžu byť o niečo lepšie – ale je tiež možné, že bude potrebná silnejšia regularizácia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"output/best_model.pt\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_valid_cpu = Y_valid.cpu()\n",
    "Y_train_cpu = Y_train.cpu()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_valid_cpu = model(X_valid).cpu()\n",
    "\n",
    "# we compute and display the MSE and the MAE\n",
    "mse = mean_squared_error(Y_valid_cpu, y_valid_cpu)\n",
    "print(\"MSE = {}\".format(mse))\n",
    "\n",
    "mae = mean_absolute_error(Y_valid_cpu, y_valid_cpu)\n",
    "print(\"MAE = {}\".format(mae))\n",
    "\n",
    "# we display the error histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_valid_cpu, y_valid_cpu, Y_fit_scaling=Y_train_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zJjRMrajK_Cu",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Metóda Dropout\n",
    "\n",
    "The other kind of regularization that we are going to explore in this notebook is called **dropout** . This method will turn off a portion of neurons in a layer randomly (during training, not at evaluation time). In PyTorch this can be done by placing `nn.Dropout` after a layer. Dropout tends to make the network more robust, improving generalization.\n",
    "\n",
    "The portion of neurons to be turned off is a hyperparameter. If we wanted to use 0.3, we could add dropout in the following way:\n",
    "\n",
    "Ďalší druh regularizácie, na ktorý sa pozrieme v tomto notebook-u, sa nazýva **dropout** . Táto metóda náhodne vypne časť neurónov vo vrstve (počas tréningu, nie v režime hodnotenia). V PyTorch-i to možno urobiť umiestnením operácie `nn.Dropout` za príslušnú vrstvu. Dropout má tendenciu robiť sieť robustnejšou, čím sa zlepšuje jej schopnosť zovšeobecňovať.\n",
    "\n",
    "Podiel neurónov, ktoré sa majú vypnúť, je hyperparameter. Ak by sme chceli použiť 0.3, mohli by sme pridať dropout nasledujúcim spôsobom:\n",
    "\n",
    "```\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        ...\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        ...\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        ...\n",
    "\n",
    "        y = torch.relu(y)\n",
    "        y = self.dropout(y)\n",
    "\n",
    "        ...\n",
    "```\n",
    "Dropout sa typicky nezaraďuje za výstupnú vrstvu (keďže sa z nej priamo odoberajú výstupy, nulovanie prvkov by spôsobilo chybu, ktorej by nevedela predísť ani akokoľvek robustná sieť).\n",
    "\n",
    "#### Dropout a kapacita modelu\n",
    "\n",
    "Ak sa použije agresívnejšia forma regularizácie, kapacitu modelu to môže znížiť podstatne. Je teda napríklad možné, že model silno využívajúci dropout bude potrebovať vrstvy s o niečo väčším počtom neurónov než model bez `Dropout` vrstiev.\n",
    "\n",
    "Netriviálna je aj interakcia medzi rôznymi metódami regularizácie: napríklad pri použití metódy dropout sa dá očakávať, že bude vo výsledkoch na validačnej množine väčší rozptyl (na zmeny váh vplývajú ďalšie stochastické faktory); preto môže byť v prípade s kombináciou so skorým ukončením učenia potrebné použiť podstatne vyššiu hodnotu `patience`.\n",
    "\n",
    "---\n",
    "### Úloha 3\n",
    "\n",
    "**Skúste do siete vložiť niekoľko `Dropout` vrstiev. Napríklad jednu `Dropout` vrstvu za každú `relu` vrstvu.** \n",
    "\n",
    "**Efektivitu regularizácie testujte počas ladenia parametrov len pomocou validačnej dátovej množiny. Testovacia dátová množina sa použije až nakoniec – len jeden raz!** \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BXtcSROsMA5N",
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "class DropoutNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        # -----\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mA-ABzKQK_Dd",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Pokúsme sa zopakovať tréning znovu s použitím našej novej siete. Aby sme si postup zjednodušili a nemuseli ladiť parameter `patience` (prinízka hodnota by mohla naše výsledky zhoršiť), v tomto behu nebudeme používať skoré ukončenie učenia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = X_train.shape[1]\n",
    "num_outputs = Y_train.shape[1]\n",
    "model = DropoutNet(num_inputs, num_outputs).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_train = []\n",
    "loss_valid = []\n",
    "\n",
    "for epoch in range(2000):\n",
    "    model.train()\n",
    "    y = model(X_train)\n",
    "\n",
    "    loss = criterion(y, Y_train)\n",
    "    loss_train.append(loss.detach().item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y = model(X_valid)\n",
    "        loss = criterion(y, Y_valid)\n",
    "        loss_valid.append(loss.item())\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"epoch {epoch}, train loss: {np.mean(loss_train[-20:]):.3g}, valid loss: {np.mean(loss_valid[-20:]):.3g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_train, label=\"train\")\n",
    "plt.plot(loss_valid, label=\"valid\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.grid(ls='--')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mA-ABzKQK_Dd",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Všimnite si, že sa naša validačná chyba už nezvyšuje. Všimnite si tiež, že chyby obsahujú viac šumu – je to, samozrejme, kvôli šumu, ktorý zavádza dropout.\n",
    "\n",
    "Chyby na tréningových a na validačných dátach by sa teraz nemali líšiť až tak výrazne.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_cpu = Y_train.cpu()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_train_cpu = model(X_train).cpu()\n",
    "\n",
    "# we compute and display the MSE and the MAE\n",
    "mse = mean_squared_error(Y_train_cpu, y_train_cpu)\n",
    "print(\"MSE = {}\".format(mse))\n",
    "\n",
    "mae = mean_absolute_error(Y_train_cpu, y_train_cpu)\n",
    "print(\"MAE = {}\".format(mae))\n",
    "\n",
    "# we display the error histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_train_cpu, y_train_cpu, Y_fit_scaling=Y_train_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_valid_cpu = Y_valid.cpu()\n",
    "Y_train_cpu = Y_train.cpu()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_valid_cpu = model(X_valid).cpu()\n",
    "\n",
    "# we compute and display the MSE and the MAE\n",
    "mse = mean_squared_error(Y_valid_cpu, y_valid_cpu)\n",
    "print(\"MSE = {}\".format(mse))\n",
    "\n",
    "mae = mean_absolute_error(Y_valid_cpu, y_valid_cpu)\n",
    "print(\"MAE = {}\".format(mae))\n",
    "\n",
    "# we display the error histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_valid_cpu, y_valid_cpu, Y_fit_scaling=Y_train_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VfTb-WBkMA5j",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Výsledky na testovacej množine\n",
    "\n",
    "Potom, ako sme sa dopracovali k finálnej verzii modelu, otestujeme jeho zovšeobecnenie nakoniec aj na testovacích dátach. \n",
    "\n",
    "Keďže sme v našom finálnom modeli nepoužili skoré ukončenie učenia, mohli by sme teraz pred testovaním zopakovať tréning ešte raz na tréningových + validačných dátach. To by mohlo ešte trochu zlepšiť výsledky nášho záverečného testu – ak chcete, môžete pridať potrebný kód.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "colab_type": "code",
    "id": "w2d6xYOZMA5n",
    "outputId": "112c0937-5ce2-44ae-89a8-e2900d8749d8"
   },
   "outputs": [],
   "source": [
    "Y_test_cpu = Y_test.cpu()\n",
    "Y_train_cpu = Y_train.cpu()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_cpu = model(X_test).cpu()\n",
    "\n",
    "# we compute and display the MSE and the MAE\n",
    "mse = mean_squared_error(Y_test_cpu, y_test_cpu)\n",
    "print(\"MSE = {}\".format(mse))\n",
    "\n",
    "mae = mean_absolute_error(Y_test_cpu, y_test_cpu)\n",
    "print(\"MAE = {}\".format(mae))\n",
    "\n",
    "# we display the error histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_test_cpu, y_test_cpu, Y_fit_scaling=Y_train_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zNEwVBA8K_D-",
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Regresia pomocou rozhodovacích stromov s gradientným boostingom\n",
    "\n",
    "Aby sme ukázali, že neurónové siete nemajú na štruktúrovaných dátach podstatnú výhodu a lepšie výsledky sa väčšinou dajú dosiahnuť inými metódami, porovnáme výsledky aj s metódou XGBoost založenou na komisii rozhodovacích stromov a gradientnom boosting-u. Je dobrá šanca, že výsledok bude lepší než sa nám podarilo dosiahnuť pomocou neurónovej siete: a učenie bude trvať podstatne kratší čas. Skutočné výhody neurónových sietí typicky vidno až pri náročnejších neštruktúrovaných dátach ako sú obraz, zvuk a pod.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "X_train_np = X_train.cpu().numpy()\n",
    "Y_train_np = Y_train.cpu().numpy()\n",
    "X_test_np = X_test.cpu().numpy()\n",
    "Y_test_np = Y_test.cpu().numpy()\n",
    "\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train_np, Y_train_np);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = model.predict(X_test_np)\n",
    "\n",
    "# we compute and display the MSE and the MAE\n",
    "mse = mean_squared_error(Y_test_np, y_test)\n",
    "print(\"MSE = {}\".format(mse))\n",
    "\n",
    "mae = mean_absolute_error(Y_test_np, y_test)\n",
    "print(\"MAE = {}\".format(mae))\n",
    "\n",
    "# we display the error histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_test_np, y_test, Y_fit_scaling=Y_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "4_regression_exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "a351393365bb1b108989afa08de3243f72f5e58927baf5d192f3cca79a41cbc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
