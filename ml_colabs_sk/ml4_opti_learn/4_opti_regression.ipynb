{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "**POZNÁMKA: Tento notebook je určený pre platformu Google Colab. Je však možné ho spustiť (možno s drobnými úpravami) aj ako štandardný Jupyter notebook.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install git+https://github.com/michalgregor/class_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "from sympy.utilities.lambdify import lambdify\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, KBinsDiscretizer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from class_utils import error_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Downloading Data -- { display-mode: \"form\" }\n",
    "from class_utils.download import download_file_maybe_extract\n",
    "download_file_maybe_extract(\"https://www.dropbox.com/s/p5q7gzupa2ndw55/sigmoid_regression_data.csv?dl=1\", directory=\"data\")\n",
    "\n",
    "# also create a directory for storing any outputs\n",
    "import os\n",
    "os.makedirs(\"output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "## Strojové učenie na báze optimalizácie\n",
    "\n",
    "Ako ďalší príklad si uvedieme veľmi jednoduchú aplikáciu optimalizácie v rámci strojového učenia. Naším cieľom bude vykonať regresiu: dostaneme vstupné a výstupné dáta a budeme sa snažiť nájsť funkciu, ktorá produkuje takú závislosť.\n",
    "\n",
    "Takúto úlohu je ľahké previesť na optimalizačný problém. Budeme predpokladať, že máme k dispozícii parametrickú funkciu $f_\\theta(\\mathbf{x})$, ktorej charakter je daný vektorom parametrov $\\theta$. Naším cieľom je nájsť také parametre, pri ktorých bude $f_\\theta(\\mathbf{x})$ na našej dátovej množine robiť čo najmenšie chyby.\n",
    "\n",
    "Dajme tomu, že dátová množina má vzorky v tvare $(\\mathbf{x_i}, \\mathbf{y_i})$, kde $\\mathbf{x_i}$ je vstup a $\\mathbf{y}_i$ je požadovaný výstup pre vzorku $i$. Potom sa dá náš cieľ opísať ako nasledujúci optimalizačný problém:\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta^* = \\underset{\\theta}{\\arg\\min} \\sum_{(\\mathbf{x}_i, \\mathbf{y}_i)} \\mathcal{L}(f_\\theta(\\mathbf{x}_i), \\mathbf{y}_i)\n",
    "\\end{equation}t.j. chceme nájsť taký vektor parametrov $\\theta^*$, ktorý bude minimalizovať rozdiel medzi skutočnými a požadovanými výstupmi na celej dátovej množine v zmysle nejakej chybovej funkcie: napríklad **kvadratickej chyby** .\n",
    "\n",
    "### Dátová množina\n",
    "\n",
    "Definíciu nášho regresného problému začneme načítaním dátovej množiny – ide o dáta zo zašumenej sigmoidnej krivky, ktoré budeme načítavať z CSV súboru. Keďže toto načítanie a predspracovanie sme už raz realizovali, nebudeme na tomto mieste celý postup opakovať a zdrojový kód nasledujúcej bunky je skrytý.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Data Loading and Preprocessing; X_train, Y_train, X_test, Y_test -- { display-mode: \"form\" }\n",
    "df = pd.read_csv(\"data/sigmoid_regression_data.csv\")\n",
    "\n",
    "# we create a discretized version of the y column\n",
    "# to allow for stratification\n",
    "kbins = KBinsDiscretizer(6, encode='ordinal')\n",
    "y_stratify = kbins.fit_transform(df[['y']])\n",
    "\n",
    "# we split the dataset into train and test\n",
    "df_train, df_test = train_test_split(df, stratify=y_stratify,\n",
    "                                 test_size=0.3, random_state=4)\n",
    "\n",
    "# we specify the inputs and the outputs\n",
    "categorical_inputs = []\n",
    "numeric_inputs = ['x']\n",
    "output = 'y'\n",
    "\n",
    "# we create the pipeline\n",
    "input_preproc = make_column_transformer(\n",
    "    (make_pipeline(\n",
    "        SimpleImputer(strategy=\"most_frequent\"),\n",
    "        OrdinalEncoder()),\n",
    "     categorical_inputs),\n",
    "    \n",
    "    (make_pipeline(\n",
    "        SimpleImputer(),\n",
    "        StandardScaler()),\n",
    "     numeric_inputs)\n",
    ")\n",
    "\n",
    "# we fit and apply the pipeline on the train set\n",
    "X_train = input_preproc.fit_transform(df_train[categorical_inputs+numeric_inputs]).reshape(-1)\n",
    "Y_train = df_train[output].values\n",
    "\n",
    "# we apply the same pipeline to the test set,\n",
    "# taking care to use transform and not fit_transform\n",
    "X_test = input_preproc.transform(df_test[categorical_inputs+numeric_inputs]).reshape(-1)\n",
    "Y_test = df_test[output].values\n",
    "\n",
    "# we plot the data for visual inspection\n",
    "plt.scatter(X_train, Y_train, marker='x', label=\"training data\")\n",
    "plt.scatter(X_test, Y_test, c='r', label=\"testing data\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(ls='--')\n",
    "plt.legend()\n",
    "plt.savefig(\"output/regression_data.pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "---\n",
    "### Úloha 1: Definícia regresnej funkcie\n",
    "\n",
    "Závislosť, ktorú sme si vyššie vizualizovali, sa tvarom nápadne podobá na sigmoidnú (logistickú) kriku, ktorá je definovaná nasledovne:\n",
    "\\begin{equation}\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}.\n",
    "\\end{equation}\n",
    "Zdá sa však, že je trochu posunutá v smere x-ovej osi a možno nemá rovnakú strmosť. Zostavme preto regresný model tak, že vstup sigmoidnej funkcie prejde najprv jednoducho lineárnou transformáciou, ktorej parametre $a$ a $c$ sa naučíme z dát. Celý regresný model potom bude vyzerať nasledovne:\n",
    "\\begin{align}\n",
    "u &= ax + c \\\n",
    "\\sigma(u) &= \\frac{1}{1 + e^{-u}}.\n",
    "\\end{align}\n",
    "\n",
    "Alebo v rámci jednej funkcie:\n",
    "\\begin{equation}\n",
    "\\mathrm{f}(x, a, c) = \\frac{1}{1 + e^{-ax - c}}\n",
    "\\end{equation}\n",
    "\n",
    "**Pomocou balíčka `sympy` symbolicky definujte náš regresný model ako funkciu $f(x, a, c)$.** \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "symx, syma, symc = sp.symbols('x a c')\n",
    "\n",
    "\n",
    "\n",
    "symf =      # ----\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f = lambdify([symx, syma, symc], symf, \"numpy\")\n",
    "\n",
    "symf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Regresnú funkciu `f(x, a, c)` si kvôli kontrole vizualizujeme:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Regression Function Visualization -- { display-mode: \"form\" }\n",
    "xx = np.linspace(-5, 5, 100)\n",
    "a = 1; c = 0\n",
    "yy = [f(x, a, c) for x in xx]\n",
    "\n",
    "plt.plot(xx, yy)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(ls='--')\n",
    "\n",
    "plt.savefig(\"output/sigmoid.pdf\", bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Účelová funkcia a jej gradient\n",
    "\n",
    "Ako sme už povedali vyššie, naším cieľom je minimalizovať chybu na dátovej množine, t.j.\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta^* = \\underset{\\theta}{\\arg\\min} \\sum_{(\\mathbf{x}_i, \\mathbf{y}_i)} \\mathcal{L}(f_\\theta(\\mathbf{x}_i), \\mathbf{y}_i)\n",
    "\\end{equation}\n",
    "Vonkajšej sume sa pri určovaní gradientu nemusíme venovať. Z linearity derivácie vyplýva, že \n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla \\sum_{(\\mathbf{x}_i, \\mathbf{y}_i)} \\mathcal{L}(f_\\theta(\\mathbf{x}_i), \\mathbf{y}_i) = \\sum_{(\\mathbf{x}_i, \\mathbf{y}_i)} \\nabla \\mathcal{L}(f_\\theta(\\mathbf{x}_i), \\mathbf{y}_i)\n",
    "\\end{equation}stačí nám teda riešiť vnútornú časť sumy a potom gradienty pre jednotlivé vzorky z dátovej množiny sčítať dokopy.\n",
    "\n",
    "Povedzme, že ako chybovú funkciu použijeme kvadratickú chybu, t.j.:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{L}(f_\\theta(\\mathbf{x}_i), \\mathbf{y}_i) = \\left(\n",
    "    f_\\theta(\\mathbf{x}_i) - \\mathbf{y}_i\n",
    "\\right)^2.\n",
    "\\end{equation}\n",
    "Zadefinujme si ju teraz symbolicky a určme gradient (len podľa parametrov $a$ a $c$ pretože tých optimálne hodnoty ideme hľadať):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symy = sp.symbols('y')\n",
    "symL = (symf - symy)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = lambdify((symx, symy, syma, symc), symL, \"numpy\")\n",
    "\n",
    "sym_grad_L = sp.Matrix([symL]).jacobian([syma, symc])\n",
    "grad_L_func = lambdify((symx, symy, syma, symc), sym_grad_L, \"numpy\")\n",
    "\n",
    "sym_grad_L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Pri takejto definícii do funkcie `grad_L` dosadíme za všetky potrebné argumenty ($x$, $y$, $a$, $c$), ale navracia sa len vektor s dvoma prvkami: parciálnou deriváciou podľa $a$ a podľa $c$. Napr.:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0; y = 1; a = 1; c = 0\n",
    "print(\"L:\\t\\t{}\".format(L(x, y, a, c)))\n",
    "print(\"grad_L:\\t\\t{}\".format(grad_L_func(x, y, a, c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Chyba a gradient pre všetky vzorky\n",
    "\n",
    "Ako už vieme, celkovú chybu dostaneme ako súčet chýb pre jednotlivé vzorky a rovnako aj celkový gradient bude súčtom všetkých jednotlivých gradientov. Zadefinujme si teda funkcie, ktoré nám pomôžu oba výsledky vyrátať:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumL(a, c, X, Y):\n",
    "    L_sum = 0\n",
    "    \n",
    "    for x, y in zip(X, Y):\n",
    "        L_sum += L(x, y, a, c)\n",
    "        \n",
    "    return L_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_sumL(a, c, X, Y):\n",
    "    grad_sum = np.zeros(2)\n",
    "    \n",
    "    for x, y in zip(X, Y):\n",
    "        grad_sum = grad_sum + grad_L_func(x, y, a, c)\n",
    "        \n",
    "    return grad_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Že všetko správne funguje môžeme otestovať na príklade: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sumL(a, c, X_train, Y_train))\n",
    "print(grad_sumL(a, c, X_train, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Minimalizácia účelovej funkcie\n",
    "\n",
    "Ďalej už len použijeme funkciu `minimize`, aby sme chybu minimalizovali a zobrazíme výslednú regresnú závislosť. Minimalizácia sa vykoná nasledovne:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(fun=lambda xx: sumL(*xx, X_train, Y_train),\n",
    "               x0=np.random.uniform(0, 1, 2),\n",
    "               method='L-BFGS-B',\n",
    "               jac=lambda xx: grad_sumL(*xx, X_train, Y_train)\n",
    "              )\n",
    "\n",
    "a, c = res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Testovanie regresného modelu\n",
    "\n",
    "Určíme výstupy výsledného regresného modelu na tréningových dátach a vypočítame chybové ukazovatele.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [f(x, a, c) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(Y_test, y_test)\n",
    "mae = mean_absolute_error(Y_test, y_test)\n",
    "\n",
    "print(\"MSE: {}\".format(mse))\n",
    "print(\"MAE: {}\".format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Tak ako v jednom z predchádzajúcich notebook-ov, aj tu si pre úplnejšiu predstavu môžeme zobraziť aj histogram chýb:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Histogram of Outputs and Errors -- { display-mode: \"form\" }\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_test, y_test, Y_fit_scaling=Y_train)\n",
    "plt.savefig(\"output/error_output_histogram.pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Ešte užitočnejšie bude vizualizovať si výslednú regresnú funkciu a pôvodné dáta – vzhľadom na to, že dáta sú len 2-rozmerné, je to možné urobiť a poskytne nám to silnú intuíciu o tom, či sa regresná závislosť správa korektne:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Regression Curve vs. Data -- { display-mode: \"form\" }\n",
    "x_min = min(np.min(X_train), np.min(X_test))\n",
    "x_max = max(np.max(X_train), np.max(X_test))\n",
    "\n",
    "xx = np.linspace(x_min, x_max, 250).reshape((-1, 1))\n",
    "yy = [f(x, a, c) for x in xx]\n",
    "\n",
    "plt.scatter(X_train, Y_train, marker='x', label=\"training data\")\n",
    "plt.scatter(X_test, Y_test, c='r', label=\"testing data\")\n",
    "\n",
    "plt.plot(xx, yy, label=\"regression curve\", c='k')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(ls='--')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"output/regression.pdf\", bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Jednoduchšia implementácia regresie pomocou `curve_fit`\n",
    "\n",
    "V praxi existujú samozrejme na realizáciu regresie aj jednoduchšie nástroje. Dobrým príkladom všeobecnej funkcie je `scipy.optimize.curve_fit`. Pri jej použítí stačí v predpísanej forme zadať regresnú funkciu (prípadne jej gradient) a nie je nutné zaoberať sa vecami ako je iterácia cez dátovú množinu a pod.\n",
    "\n",
    "Vyššie uvedený príklad by sme pomocou `scipy.optimize.curve_fit` vedeli zjednodušiť takto:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, a, c):\n",
    "    return 1 / (1 + np.exp(-a*x - c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt, _ = curve_fit(sigmoid, X_train.reshape(-1), Y_train.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "#### Vyhodnotenie na testovacích dátach\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = sigmoid(X_test, *popt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(Y_test, y_test)\n",
    "mae = mean_absolute_error(Y_test, y_test)\n",
    "\n",
    "print(\"MSE: {}\".format(mse))\n",
    "print(\"MAE: {}\".format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Regression Curve vs. Data -- { display-mode: \"form\" }\n",
    "x_min = min(np.min(X_train), np.min(X_test))\n",
    "x_max = max(np.max(X_train), np.max(X_test))\n",
    "\n",
    "xx = np.linspace(x_min, x_max, 250).reshape((-1, 1))\n",
    "yy = sigmoid(xx, *popt)\n",
    "\n",
    "plt.scatter(X_train, Y_train, marker='x', label=\"training data\")\n",
    "plt.scatter(X_test, Y_test, c='r', label=\"testing data\")\n",
    "\n",
    "plt.plot(xx, yy, label=\"regression curve\")\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(ls='--')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"output/regression2.pdf\", bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
