{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "**POZNÁMKA: Tento notebook je určený pre platformu Google Colab. Je však možné ho spustiť (možno s drobnými úpravami) aj ako štandardný Jupyter notebook.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install git+https://github.com/michalgregor/class_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, KBinsDiscretizer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from class_utils import error_histogram\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Downloading Data -- { display-mode: \"form\" }\n",
    "DATA_HOME = \"https://github.com/michalgregor/ml_notebooks/blob/main/data/{}?raw=1\"\n",
    "\n",
    "from class_utils.download import download_file_maybe_extract\n",
    "download_file_maybe_extract(DATA_HOME.format(\"sigmoid_regression_data.csv\"), directory=\"data\")\n",
    "\n",
    "# also create a directory for storing any outputs\n",
    "import os\n",
    "os.makedirs(\"output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "## Regresia a predspracovanie dát pre ňu\n",
    "\n",
    "Ako ďalší príklad ukážeme, ako sa dá realizovať jednoduchá regresná úloha. Ako regresnú metódu použijeme (rovnako ako v prípade klasifikácie) metódu $k$ najbližších susedov (angl. $k$ nearest neighbours; KNN). V prípade klasifikácie sa predikcia určila hlasovaním medzi $k$ najbližšími susedmi. V prípade regresie sa zase predikcia vyráta jednoducho ako priemer z hodnôt $k$ najbližších susedov.\n",
    "\n",
    "### Načítanie dátovej množiny\n",
    "\n",
    "Príklad začneme, ako obvykle, načítaním dátovej množiny, ktorá má znovu podobu CSV súboru: v tomto prípade len s dvoma stĺpcami. Prvý z nich, $x$, predstavuje vstup nášho modelu a druhý $y$, reprezentuje požadovaný výstup.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/sigmoid_regression_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Stratifikácia pri delení dátovej množiny\n",
    "\n",
    "Ďalším krokom je samozrejme rozdelenie dátovej množiny na tréningovú a testovaciu časť. Pripomeňme, že pri klasifikácii sme v rámci delenia dátovej množiny používali stratifikáciu podľa triedy – aby sme zabezpečili, že pomer tried v tréningovej aj v testovacej časti množiny zostane podobný ako bol v pôvodnej dátovej množine.\n",
    "\n",
    "V prípade regresie sa samozrejme nedá spraviť to isté – alebo aspoň nie tak priamočiaro ako pri klasifikácii – keďže výstupné hodnoty sú spojité. V niektorých prípadoch však môže byť stále žiaduce nejaký druh stratifikácie vykonať – najmä ak je dátová množina malá, ako je to aj v našom prípade. Inak sa môže stať, že tréningová a testovacia množina nebudú reprezentatívne.\n",
    "\n",
    "Ako by taký problém vyzeral sa dá ukázať ľahko: stačí našu dátovú množinu rozdeliť štandardne, bez použitia stratifikácie, a vizualizovať v tom istom grafe tréningové aj testovacie dáta:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.3, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_train['x'], df_train['y'], marker='x', label=\"tréningové dáta\")\n",
    "plt.scatter(df_test['x'], df_test['y'], c='r', label=\"testovacie dáta\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(ls='--')\n",
    "plt.legend()\n",
    "plt.savefig(\"output/regression_split_plain.pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Z grafu by malo byť vidno, že testovacie dáta ani zďaleka nepokrývajú celý priestor. Ako teda stratifikáciu aplikovať, aby sme takému problému zamedzili? Keďže stĺpec podľa ktorého stratifikujeme by mal obsahovať diskrétne hodnoty, najjednoduchšie je samozrejme náš spojitý stĺpec diskretizovať – napr. pomocou transformátora `KBinsDiscretizer` z balíčka `scikit-learn`. Samotná diskretizácia môže vyzerať napríklad nasledovne:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbins = KBinsDiscretizer(6, encode='ordinal')\n",
    "y_stratify = kbins.fit_transform(df[['y']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Podľa diskretizovaného stĺpca `y_stratify` už môžeme stratifikovať:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, stratify=y_stratify,\n",
    "                                 test_size=0.3, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Keď vizualizujeme výsledky takéhoto delenia, mali by sme vidieť, že body sú rozdelené medzi tréningovú a testovaciu množinu výrazne rovnomernejšie:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_train['x'], df_train['y'], marker='x', label=\"training data\")\n",
    "plt.scatter(df_test['x'], df_test['y'], c='r', label=\"testing data\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(ls='--')\n",
    "plt.legend()\n",
    "plt.savefig(\"output/regression_split_stratif.pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "---\n",
    "### Úloha 1: Zostavenie pipeline\n",
    "\n",
    "**Dalším krokom je, ako zvyčajne, zostavenie pipeline na predspracovanie dát. Najprv určte, ktoré vstupné stĺpce sú kategorické a ktoré numerické a následne vytvorte rovnaký pipeline objekt, aký sme používali v predchádzajúcich príkladoch.** \n",
    "\n",
    "POZN.: Výstupný stĺpec nebude potrebné predspracovať.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "categorical_inputs = [           ]  # ----\n",
    "\n",
    "numeric_inputs = [               ]  # ----\n",
    "\n",
    "output = 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "input_preproc = make_column_transformer(\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ----\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Predspracovanie dát\n",
    "\n",
    "Dáta predspracujeme tradičným spôsobom:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = input_preproc.fit_transform(df_train[categorical_inputs+numeric_inputs])\n",
    "Y_train = df_train[output].values\n",
    "\n",
    "X_test = input_preproc.transform(df_test[categorical_inputs+numeric_inputs])\n",
    "Y_test = df_test[output].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Tréning modelu\n",
    "\n",
    "Model sa trénuje pomocou unifikovaného rozhrania – zmení sa len jeho typ. Namiesto `KNeighborsClassifier` používame `KNeighborsRegressor`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsRegressor(n_neighbors=5)\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Testovanie modelu\n",
    "\n",
    "Nakoniec správanie sa modelu overíme na testovacích dátach. V prípade regresie sa samozrejme ako metrika úspešnosti nepoužíva správnosť – regresia má svoje vlastné ukazovatele. Medzi tie najčastejšie používané patria **stredná kvadratická chyba**  (angl. mean squared error; MSE):\n",
    "\\begin{equation}\n",
    "MSE = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2.\n",
    "\\end{equation}\n",
    "kde $y_i$ je požadovaný výstup a $\\hat{y}_i$ skutočný výstup modelu pre vzorku $i$ z dátovej množiny a $N$ je celkový počet vzoriek v dátovej množine.\n",
    "\n",
    "a **stredná absolútna chyba**  (angl. mean absolute error; MAE):\n",
    "\\begin{equation}\n",
    "MAE = \\frac{1}{N} \\sum_{i=1}^{N} |y_i - \\hat{y}_i|.\n",
    "\\end{equation}\n",
    "\n",
    "Stredná kvadratická chyba je citlivejšia na veľké chyby (kvôli druhej mocnine). Výhodou strednej absolútnej chyby je, že má rovnakú škálu ako dáta, takže je ju ľahšie interpretovať (ale aj stredná kvadratická chyba sa dá odmocniť). Existujú samozrejme aj ďalšie ukazovatele (napr. percentuálne chyby, koeficient determinácie a pod.), ale tým sa v tomto notebook-u venovať nebudeme.\n",
    "\n",
    "Použime teda vytvorený regresný model a vypočítajme predikcie na testovacích dátach.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Vypočítame a zobrazíme strednú kvadratickú a strednú absolútnu chybu. Pripomeňme, že výstupy sú približne z rozsahu od 0 po 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(Y_test, y_test)\n",
    "mae = mean_absolute_error(Y_test, y_test)\n",
    "\n",
    "print(\"MSE: {}\".format(mse))\n",
    "print(\"MAE: {}\".format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Pre plnšiu predstavu o tom, ako sú chyby rozdelené môžeme vizualizovať aj celé ich rozdelenie pomocou histogramu výstupov a chýb. Výstupy pre tento graf štandardizujeme, aby boli histogram výstupov a histogram chýb zarovnané. Rovnako aj strednú absolútnu chybu počítame znovu zo škálovaných dát, aby bola v tej istej mierke.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_test, y_test, Y_fit_scaling=Y_train)\n",
    "plt.savefig(\"output/error_output_histogram.pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "### Vizualizácia regresnej závislosti\n",
    "\n",
    "Keďže naša regresná závislosť je len 2-rozmerná, môžeme ju ľahko vizualizovať v grafe a zhodnotiť kvalitu výsledkov aj vizuálne.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = min(np.min(X_train), np.min(X_test))\n",
    "x_max = max(np.max(X_train), np.max(X_test))\n",
    "\n",
    "xx = np.linspace(x_min, x_max, 250).reshape((-1, 1))\n",
    "yy = model.predict(xx)\n",
    "\n",
    "plt.scatter(X_train, Y_train, marker='x', label=\"training data\")\n",
    "plt.scatter(X_test, Y_test, c='r', label=\"testing data\")\n",
    "\n",
    "plt.plot(xx, yy, label=\"regression curve\")\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(ls='--')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"output/knn_regression.pdf\", bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "sk"
    ]
   },
   "source": [
    "Jedna vlastnosť, ktorú by z grafu malo byť vidno, je, že regresná závislosť nie je hladká. Je to samozrejme preto, že existujú oblasti, kde všetky body majú tých istých najbližších susedov a výstup je preto v rámci nich necitlivý na zmenu vstupu. V neskorších notebook-och sa budeme venovať aj iným typom modelov, pomocou ktorých bude možné dosiahnuť lepšie výsledky.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
